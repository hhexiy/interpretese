Today , I 'd like to talk about example-based spoken dialog system . This is my title of the speech .
We are researching the spoken dialog interface . What we are trying to achieve is an interface that is easy to use , at the same time it is safe to use , for example , in a car .
And what is most important is to be able to recognize natural dialog or conversation and to be able to understand it . Then what dose spontaneous , natural dialog means ?
For example , in order to express is there a Chinese restaurant nearby ? You can have four or more different ways of speaking the same content .
So there are various ways to express the same things .
So without any constraints or restrictions if you can say anything in whatever way you want to , that is spontaneous conversation or natural dialog . It used to be the case that in those spoken dialog interface only a certain form of dialog or utterance is accepted .
For example , the phrase number one only is accepted and phrases two , three , four were not accepted .
So , we are trying to realize the spoken dialog interface that can understand spontaneous speech . In order to achieve the above-mentioned objective , we try to collect as many examples as possible and we try to use examples based on the assumption that people will say almost the same thing in the same situation .
This chart shows how information is searched between user and database and how the information is flowing between the user and information database . User says , I want to eat a Chinese cuisine .
Then operator uses a search tool and creates an argument or query and searches information from the data base . So , this diagram shows that the operator makes some sort of decision in the mind .
And this decision is based on the past experience or knowledge and this knowledge part will be replaced by machine that we are trying to achieve . In order to do that , we have asked two subjects in a car to have a spontaneous speech or dialog .
And based on that data we have formed a tool .
And from now on , I 'll talk about specific example , how a conversation or dialog is processed . I said that we try to collect as many examples as possible and this is how the spontaneous speech examples are accumulated .
So , the content of the speech , and an argument or query is added to the utterance itself . For example , when a user says , I want to eat a spaghetti or something , then the argument is put by the operator to make it easier for the operator to search .
And based on that data the dialog or speech is processed in the following way .
For example , when a person says , I want to go to a spaghetti shop , then the key words will be extracted from the speech . And based on the key words , among the examples we have accumulated we search the closest example .
And in this case , the first one , I want to go to a curry shop was the closest one chosen among the examples . And that goes on to the argument or query and this argument is modified to replace , in this case curry with spaghetti .
And we have made an assessment of that speech processing .
In this experiment we have used the data of eighteen people having conversation in a car and also we have used the data of transcripts of twenty-eight people having a conversation in a car .
And the next chart or graph shows the following facts . As the number of subjects increases the number or the percentage of correct answer goes up .
So , what we can say is that the more data we have , the more accurate the database is going to be .
You can see the increase as the graph shows , so if we add a number of data , it is expected that performance of this database is going to increase . And also we made an error error analysis . And seventy percent of the mistake were coming from the fact that data is lacking. There 's no match enough data . So based on the fact as well , there 's a further possibility of increasing performance by increasing the number of data , or example database .
So , to sum up , we have come up with a spoken dialog processing to cope with spontaneous speech .
And we are using examples based on the examples of spontaneous speech so that we can cope with a various ways of saying the same thing .
And I 'd say result of the assessment . Seventy percent of the conversations were successfully coped by the this database and there 's further possibility of increasing performance by increasing the data base itself .
Thank you .
Today , I 'd like to talk about the example-based dialogue research system . We are now studying on the interface for spoken dialogue .
What we are trying to achieve is that the very easy to use system . For example , when you are in the car , the system should be very safe .
And then the most importantly the system has to recognize spontaneous speech . Then what is the spontaneous speech ?
For example , is there any Chinese restaurant nearby ? To this sentence , there are other expressions expressions two to four .
There are four ways of the expressing the same contents .
So , system has to understand all ways of expressing . So , this is most important future that the system should have . Then we call this the spontaneous speech .
If you think about conventional system , they just recognize certain patterns of speeches .
For example , maybe expression one , Is there any Chinese restaurant nearby ? Could be understood but , expression two to four the system can not recognize .
The system has to understand this kind of spontaneous speech to realize that . We gather the spontaneous speech as much as possible .
And , if the situation is the same , the people may use similar expressions . Based upon this premise we gather the examples , and then come up with some pattern of speech .
So , two people speak each other , the user and operator , how the information needs searched . The user input dialogue such as I want to have some Chinese dish .
Then operator search information using system , and then get the result of this search .
In this diagram operator listen to the user 's request and operator make some judgment based upon the history of the examples . And then this operator could be replaced by system itself .
So , to achieve this system we ask two people to have some conversation and then gather this data . And then based upon this data we try to come up with some system .
Now I 'd like to talk about details of our research . What kind of process the data should but data base should have ?
The first of all , we try to collect as much as possible dialogue examples . If that in the car , someone said to the other party , and then we come up with some argument or variables .
Then this could be described. For example , if the user said that I 'd like to have some spaghetti and then operator comes up with argument or variables .
And this is also input into the system . And then using the collection of data , the system processes these data .
The first input speech , I want to go to spaghetti shop then the system extracts the key words . And then based upon extracted key words , the system search for the similar expression .
For example , curry shop I want to go to curry shop. This is a most likely expression . Then the system use the argument or variables to pick up this sentence , and then replace the input speech with this similar expression .
And using this process , we come up with the system and then evaluate it . We gather the dialogue which were conducted in the car .
So , using this kind of data , we evaluate them . And another data have the twenty-eight people 's conversation .
After the result of evaluation , we got something .
The conclusion is when you increase the number of data , you will come up with more accurate performance . The more the data number increase , the search works very well .
So , as you see the linear line increase , you will see , so if you increase the data number more than twenty-eight , you will expect more better performance . At the same time , We elaborate why the system fails . Sometime the because of the insufficient volume of data , the system does n't work . So , this is the seventy percent , cause of failure .
So , it means that if you have the more volume data , you will have better accuracy .
So , as the summary , the system has to handle the spontaneous speech and try to achieve that we use actual example of dialogue .
And based upon the accumulated dialogue , we try to control the dialogue .
So that system could work every kind of ways of expressions . Here is the validation result .
Seventy percent the system come up with accurate our result . And if you increase the volume data , you 'll have more accurate performance .
Today , I 'd like to discuss spoken dialogue system based on examples .
We are now trying to develop a spoken dialogue system based on speech and what we are trying to attain is that to develop something quite easy to use and also safe enough so that we can use it in the automobile , for example , and above all it is very important that it should recognize and understand the spontaneous speech .
And what do we mean by spontaneous speech ?
There is an example that goes like this Is there any Chinese restaurant nearby ? And in addition , we have other possibilities to say the same thing like two , three , and four .
And the system should be able to handle the variety of expressions without any limitation . That is the system which allows us to use the spontaneous speech .
But contrary to this , the spoken dialogue system in existence , usually accept only the fixed forms .
For example , it can recognize expression number one but it can not recognize expression number two through four .
And speech dialogue system which can recognize the spontaneous speech should be developed and in order to do so , we decided to collect as a lot of spontaneous speeches as possible . And our hypothesis is that if the situation is similar , then expression should also be similar , so based on the collected examples , the speech will be processed and utilized .
And here , we have the two people , one is the user and the other is the operator and when the information is searched , how the information close is shown in this chart . The user says to the operator that I want to eat Chinese food .
And then the operator uses the equipment and he searches the information and get the result .
And in such a framework , operator hears the demand of the user and the operator makes the decision in his mind and at that time , the past knowledge and the examples are supposed to be used and therefore this portion should be replaced totally with a machine. That is a basic concept .
And in order to do so , we asked a couple of persons to communicate in the automobile to collect data and using that data , we try to control the speech or the dialogue .
And now , I 'd like to discuss what is actually done for the control of the dialogue .
I said that we collected or we want to collect as many dialogue as possible and this is how it 's done . The content of the speech in the dialogue in the automobile and the search formula for the information search would be described like this .
For example , I want some spaghetti , that is the speech by the user . And towards such an expression , the operator forms the search formula like this . And then , , those are all recorded .
And using the accumulated data , the process is carried out like this .
First , input speech comes into the machine , Well , I want to go to a spaghetti restaurant and toward this , only the important words or key words would be extracted .
And based on those key words amongst the collected examples , the machine searches the closest example . And in this case , I want to go to a curry restaurant and if it is determined that this is the closest expression , then The search formula which is issued by the operator is extracted .
And that will be corrected to be closer to the actual input of the speech . Using such a scheme , we developed the dialogue system and we carried out the evaluation .
Here , we have collected the dialogue by eighteen people in the automobile . That is used as the evaluation data .
And as to the example data , we have transcribed the dialogue in the automobile of the twenty eight people .
And we carried out the evaluation test and the result is shown in the graph in this screen . And more the number of the examples , or the speakers of the examples , to what extent the correct search is carried out .
And the conclusion is that more the number of the speakers of the examples the higher the rate of the correct answers or correct searches .
So if we increase the number of the speakers of the example , then we can further raise the rate of the correct answers or correct searches . And if errors are made , then we carried out the research or the search of the cause of the error . The seventy percent of the errors are actually caused by the lack of the data base . From this it is probable that with the more number of data or larger number of data , we can further improve the performance of the system .
And this is the summary of my talk . We have sought up and made up the system to handle the speech dialogue which can handle the spontaneous speech .
And we have proposed the system to understand the speech using the accumulated dialogue examples .
And with the accumulated dialogue examples , the speech could be controlled or dialogue could be controlled and it can also handle the variety of expressions . And according to the result of the evaluation test , we can handle about seventy percent of the speeches without any speech history .
And by further increasing the number of the accumulated examples , it is highly probable that the performance could be further enhanced . Thank you very much for your attention .
Today , I would like to talk about the speech dialogue system using the dialogue examples .
The speech dialogue type interface is what we are studying and our objectives are to achieve the easy to use and in use in the automobiles and others , safe , the most importantly , it can recognize and understand the spontaneous speech. That kind of speech dialogue type interface is researched .
The spontaneous , speech means the following .
For instance , Is there a Chinese restaurant nearby ? For that expression , different variations as two , three , four different expressions can be employed to say the same thing .
And various expressions without limitation should be accommodated by the user . And that means to allow the spontaneous speech .
This is how we look at it . And however , let me think about the conventional speech dialogue type interface. We find that only predetermined speeches were accepted .
For instance , expression one can be recognized but when it comes to the expressions two , through four , many conventional ones could not recognize .
And to be able to recognize and understand the aforementioned spontaneous speech , to realize that we gathered many spontaneous dialogues for use .
The situation in which the speech has been expressed . In in the similar situation , the same kind of dialogues will be uttered .
And using various examples , we decided to cope with the situation. Here , the user and the operator , between the two people , the information search is conducted . And in that contexts , what is the flow of the information ?
The user says to the operator that he or she wishes to eat the Chinese dishes. Such a request is placed to the operator and then the operator using the search machine or tools get the information and the result of the search is obtained by the operator in this way .
This kind of diagram , the operator listens to the request of the user and makes some kind of judgment in his brain and the past knowledge and examples of the past are used . And that portion is to be entirely replaced by the machine. That is the basic concept .
For that purpose , in the cars , actually two people sat in the cars to be engaged in the dialogue for search of information and in this way , we gathered data .
And using such data , we sorted out the examples of the dialogues . And from now on , I would like to talk about what we are doing for the processing of the dialogues .
Firstly , the examples of the dialogues are to be gathered in a large number . This is what I said. And this is how we carry those .
And the contents of the speech in the dialogue and the information search formula for the contents are described in this way .
For instance , I wish to eat some spaghetti . That is a user 's speech . For that , this kind of search formula is formulated by the operator and that is recorded together .
And then , the stored data are utilized and in this way , the processing takes place .
Firstly , the input speech comes I wish to go to a spaghetti restaurant . When there is an input of such speech , the important keywords are extracted .
And then based on those keywords , out of the examples gathered in a large number , which is the one , which is the most similar to the speech will be expressed. And then , I wish to go to a curry restaurant . And that is the most similar example searched . And then the operator 's search formula as you saw in the example will be extracted .
And then it is to be replaced by the speech most closely similar to the speech input . And this is the modification of the formula and the evaluation was done for the processing result .
And eighteen people 's speeches in the car were utilized as the evaluation data .
And as the examples ' data , twenty -eight people 's transcriptions of the dialogues uttered in the car . And these examples are used to and the following shows the result of the evaluation .
This graph shows that as we increase the number of the examples how we can correctly come up with the correct search formula .
And as a graph shows , as we increase the number of the examples ' data , the better performance of the search formula are making can be achieved. And the graph is increasing further as we go to the right and as we increase this , we expect that we can achieve the better performance . And at the same time , the mistakes were looked at in the formerly cause of the mistakes . And the data inefficiency causing the mistake accounted for seventy percent of the mistakes we found .
And based upon this , we can further say that by the increase of the data , we will be able to improve the performance .
And this is the summary of what I have so far stated . The spontaneous speech can be dealt with by the speech dialogue method and that method was proposed .
And using the dialogue examples , I proposed the speech understanding method and based on the dialogue examples stored to the dialogue control is done and it can cope with the multifarious expressions .
And we did the evaluation experiments for seventy percent of the speeches. We could make the correct search formula . And by increasing the number of the examples , there is a possibility for the performance improvement .
This is our finding and thank you for your attention .
My topic today is parsing for natural language using finite state automaton .
First , speaking of background , there is an increasing importance in parsing spoken language . So , it is important to analyze on time , real time .
And the results of the parsing of natural spoken language is going to be used in the natural language processing system , such as voice dialog . First , let me talk about how to analyze natural language .
There 're three stages or phases of parsing . Let me briefly explain one of each .
First is morphological parsing . Morphological parsing means to separate sentence into words and put a part-of-speech .
And in syntactic parsing , we make a parsing tree by analyzing , rather structure of the sentence input . And we use CFG or RG to analyze natural language .
And third stage is semantic parsing . This is to analyze the meaning of words and meaning between words .
Let me focus today on syntactic parsing .
This shows an example of syntactic parsing . Let me talk about six elements of sentence .
Sentence comprises of noun phrase and verb phrase . So if there is a noun phrase and verb phrase , that will constitute a sentence .
And secondly , there is a determiner and noun . And if there is a determiner and a noun , it will constitute a noun phrase or NP .
And thirdly , if there is a verb , it will constitute a VP or verb phrase . And these are grammatical rules .
And in this example sentence , the boy runs , the is a determiner and boy is a noun and V , in this case runs .
So , let me cite an example of the analysis of a sentence , the boy runs .
First , the is a determiner and noun is the boy , and the verb is runs . So following the grammatical rules , the becomes determiner , boy becomes noun and runs becomes a verb .
And then determiner and the noun , namely the boy , constitute a noun phrase . And this V or runs constitutes a verb phrase .
So now we see a combination of NP and VP .
And there is a noun phrase and verb phrase , so this the boy runs constitutes a sentence or S . And this completes the parse tree .
Let me make a comparison between the analysis , between the ones that use finite state automaton and context free grammar .
If you use CFG or context free grammar to analyze , it has capacity to accurately analyze natural spoken language , but it takes time .
But if you use finite state automaton to analyze , it is high-speed processing . It 's a benefit of that . But a bad point is that it 's not always a case that all spoken language will be accurately analyzed , so there 're sometimes mistakes .
So we need to combine the good points of the two types of analyses , namely the accurate analysis ability to analyze natural spoken language and high-speed processing . And this is a process flow of FSA-based analysis .
First , from CFG , context free grammar it will be transformed to FSA , finite state automation . And using finite state automaton , input sentence is going to be parsed into a parse tree .
So by transforming CFG to FSA , this transformed FSA will have the same characteristics as CFG , so it is accurate processing and since it is FSA , it is fast-speed processing . So it has a good point of the both two types of parsing .
Let me cite a specific case study of parsing using FSA . Let me go back to CFG , context-free grammar .
And based on the context-free grammatical rules , it will be transformed to FSA . Then the transformed FSA is going to be used for parsing the sentence the boy runs .
If you use morphological parsing , you will see the sequence of part-of-speech , determiner forby noun , and noun forby verb . So you will see the sequence DET N V and you will be able to output the parse tree as follows .
Let me make a summary of my speech . I have talked about parsing using finite state automaton .
And it consists of two phases . First is a transformation from CFG to FSA .
Second phase is to parse the sentence using FSA . By using this two-phase method the capacity or accurate analysis is going to be close to CFG and it is high-speed processing and high-speed parsing .
That concludes my speech , thank you .
Today , I 'd like to talk about parsing for natural language using finite state automaton .
Let me explain the background . There currently there are a lot of increasing the importance of the parsing of the spoken language .
It should be real time because this is the dialogue . And then the same time , it should utilize syntactic parsing for the natural language processing system .
Next , I 'd like to talk about outline of the parsing of natural language . The natural language parsing involves morphological parsing , syntactic and then semantic parsing .
The first one , morphological parsing . First of all , the system has to divide the sentence into part of speech and then analyze it .
And next one is syntactic parsing . The first parsing , the structure of the input sentence and then output the parse tree .
In order to parse the natural language , we have to use CFG and then RG .
In the semantic parsing , the meaning of the words and then semantic relations between words are very important . So , the system parses those relations .
Here , I 'd like to talk about the syntactic parsing . Let me think about one example .
The first one is NP noun phrase and then VP verb phrase . When the sentence consists of NP and VP , the system recognizes it one sentence .
And next one is the determiner plus noun . In this case system recognizes it noun phase phrase .
And then the third one verb means verb phrase .
And this is the basic regulation or rule of grammar . And then the system is looking at what kind of part-of-speech this word is .
For example , the is the determiner and then boy noun and run verb .
So , using this grammar , the boy runs could be parsed .
First of all , the , this is determiner and then boy noun , runs is verb . So , this is immediately recognized those part-of-speech . So , again , the is determiner , boy noun , runs verb .
And next step the determiner and then noun side by side . So , it means the and boy makes the noun phrase . So , the runs means or should be the verb phrase .
So , the second step the system recognizes this is the NP plus VP .
Then finally , because of this result , the input sentence The boy runs means one sentence . So , this is parse tree .
And next let me compare with the parsing the CFG based one and FSA based .
The first one is the CFG based analysis . The system has to parse the natural language very correctly , but this system takes long time for processing .
On the other hand , FSA finite state automaton , the processing is very quick , but this parsing is not always correct or it sometimes lack of accuracy .
So , we try to achieve this a kind of hybrid type between CFG and FSA . This is our goal of our research .
So , this shows that flow of parsing using FSA . The first , the system using CFG and then convert it into FSA .
Using this FSA , the system parses the input sentence .
The conversion from CFG to FSA , by doing so , FSA should have the same ability as CFG 's ability . And by doing so , the system has a very speedy process . Now you could have the both advantage of two systems .
And next I 'd like to give you some example using FSA . First of all , let me talk about CF G and then convert it into FSA .
Using the converted FSA , the system tries to parse the input sentence that is The boy runs . If you divide it into part-of-speech , you will see determiner , noun and verb .
So , again determiner , noun and verb by following this sequence you will come up with the parse tree .
To summarize our research , I just explained how to parse the sentences using FSA .
This system has the , , sorry , two steps . The first one in the conversion from CFG to FSA and the second step is parsing the sentence using FSA .
By doing so , you will have the system with as accurate as CFG and then also you can achieve high speed processing .
The title of my presentation is parsing for natural language using finite state automaton .
Let me begin with the background explanation . The parsing of the spoken language is getting more important .
And since it is a parsing analysis of the spoken words , they should be analyzed or parsed in a real time manner . And moreover , such the parsing should be utilized for the natural language processing system for the spoken dialogue and so forth .
Let me now start talking about the parsing of the natural language . The parsing of natural language will be formed in three levels , the morphological parsing , syntactic parsing , and semantic parsing. Let me begin with the morphological parsing .
The input sentence will be segmented into each word and each word would be classified by part of speech .
And the syntactic parsing will analyze the structure of the input sentence and it will be output in the form of the parse tree , which shows the structure of the input language . And as to the grammar to analyze a parsed natural language , there 're things called like CFG or Context Free Grammar or the RG , and others .
And as to the semantic parsing , the meaning of the word or the relationship of the meaning amongst the would be analyzed so that the meaning of the sentence would be known through semantic parsing .
And in my discussion , I 'd like to just consider the , excuse me , syntactic parsing . Let me show you an example of the syntactic parsing .
Let 's think about these six lines of CFG , S or sentence can be separated into NP and VP . When there is alignment of NP and VP , then that would be regarded as a sentence or that will form a sentence .
And second of all determinant and noun are in a row , in such a case , then that would be regarded or expressed as NP , noun phrase . And third of all , verb , V forms the VP or verb phrase .
These are the grammatical rules and following three shows you the part of the speech of each word .
For example , the is the determinant and this word boy is a noun and runs is a verb as it shows .
And using these grammatical rules , we are now parsing this input sentence The boy runs .
The is the determinant , boy is a noun and runs is a verb . And that is known from the three grammatical rules in the bottom . And like this , The is the determinant , boy is a noun , and runs is a verb . And it is structured as such .
And here , we have a determinant and a noun in a row , so we can know that the boy is a noun phrase or NP and in addition , this runs is a V or verb , so from the third rule , from the top the runs also forms a VP or verb phrase .
And ultimately , if noun phrase and a verb phrase are in a row , then that will form a sentence so that we can conclude that The boy runs is a sentence and so that we can form a parse tree like this out of the sentence .
Let me now compare the parsing using the CFG versus the analysis or the parsing using FSA or finite state automaton . The CFG parsing has a capability to accurately parse the natural sentence .
However , it really takes a very long time for the processing .
That is the shortcomings . And on the other hand , if we parse , with the FSA , then it processes very quickly , but on the other hand , it can not always accurately parse the natural language sentences .
So it has the es ; strengths and also weaknesses . So the strength of the CFG which is the accurate parsing and the strength of the FSA parsing that is the quick processing should be combined so that we can have a way to parse a sentence in a good manner .
So let me now show you the flow of the parsing using FSA . From CFG , the transformation or the transform is performed to FSA and using the transformed FSA , input sentence is parsed and then it generates the parse tree .
By transforming CFG into FSA , FSA will have a capability just like CFG and by using FSA , the parsing would be completed in a very short span of time . So in here , we combined the strengths of two techniques .
And this is the actual example of the analysis or the parsing using FSA . Let 's consider CFG first .
And then that would be transformed into FSA , then that would be like this in the bottom of this screen .
Then using the transformed FSA , the input sentence The boy runs is going to be parsed . The boy runs will be converted or changed into the rule of the input parts of speech in a sequence of determinant , noun and verb in its order .
So like this , we can generate the output sentence like this by making a transition from the CFG or the way down to the FSA .
I have just described the method of the parsing using the finite state automaton . It has two phases of the process or two stages of the process . First there is a transformation from CFG to FSA .
And second the stage is the parsing using FSA the input sentence and with this method , it is possible to carry out the parsing in a very high speed and also with a capability of CFG .
I would like to talk about the syntactic parsing of the natural language , using finite state automaton .
Firstly , I would like to talk about the background . Today , the importance is growing for the parsing of the spoken language .
This would be parsing of the spoken language . Therefore , as soon as the input is made , in real time , parsing must be done .
Furthermore , this kind of parsing can be sufficiently utilized in the system of the natural language processing for the speech dialogues and others . Next , I would like to talk about the overview of the parsing of the natural language .
The natural language parsing consists of morphological parsing , syntactic parsing and semantic parsing . It consists of these three stages .
For each one of the parsing , I would like to explain more .
Firstly , starting with the morphological parsing . The input sentence is split into individual words and for each word , the part of speech is assigned .
Next , the syntactic parsing . In this syntactic parsing , the input sentence is parsed , and then , the parse tree is output .
The grammar for parsing of the natural language consists of the context free grammar which is CFG or regular grammar , RG and others .
Lastly , this is the semantic parsing . In this parsing , the parsing is done for the semantic relations between words as follows. The meaning of the words , and the meaning can be analyzed here .
But here , I 'd like to consider the syntactic parsing .
This is example of the syntactic parsing . And there 're six units for the grammar that I would like to address .
Firstly , NP , VP , noun phrase and verbal phrase , in arrangement of the sequence and in that case , it is to be recognized as a sentence , it is expressed like that way . The second is that determinant and N , noun are arranged. In that case , that is recognized as the noun phrase .
The third , shows that verb , V is representing the verbal phrase .
Up to this , the rules for the grammar have been shown and then the other three shows the correspondence of the part of the sentence to the specific words and determiner The noun boy and verb runs .
And using this grammar the input words the boy runs are to be parsed .
Firstly , the is the determiner , boy is noun , and runs is verb . And based on these three set of rules of the grammar below , we know that and therefore , like this , the is the determiner , boy is noun , and runs is the verb . This kind of structure is firstly made .
And here , next , the determiner and noun are arranged in the sequential way we know and therefore , the boy , these two represent the noun phrase . And furthermore , runs is V , and therefore , based on the third rule , this runs is representing the verbal phrase we know .
And based upon that , it becomes like this and ultimately , noun phrase and verbal phrases are arranged . And therefore , The boy runs is recognized as a sentence and this is the overall parsing done .
Next , the context free grammar and the finite state automaton based parsing will be compared .
Firstly , in case of the parsing using the context free grammar , the ability is equipped that enables the correct parsing of the natural language sentence. However , the shortfall of that is that it takes time for processing .
On the other hand , in case of the parsing using the finite state automaton , the advantage is that the processing speed is high . However , the shortfall is that it does not always allow the parsing in the correct way of the natural language sentence .
And therefore , the correct parsing ability of the natural language sentence and the speedy processing given respectively by the context free grammar and finite state automaton will be combined for parsing . And this shows the flow of the parsing using the finite state automaton .
And firstly , based on the context free grammar , the finite state automaton is obtained by way of transformation and then the transformed finite state automaton is utilized for the parsing of the input sentence to generate the parse tree and the transformation .
Context free grammar is transformed to the finite state automaton. As a result , finite state automaton is given the ability which is as good as that of this context free grammar and by doing the parsing of the finite state automaton , we can achieve the very high speed parsing. These two advantages of CFG and FSA are utilized for the parsing .
And this is the example of the state automaton based parsing . The context free grammar that we gave thought to will be firstly looked at and then it is to be transformed next to the finite state automaton to come up with these .
And then the transformed finite state automaton is utilized and the input sentence The boy runs is to be parsed .
And the input sentence is analyzed in terms of the sequence of the input parts of sentence and then be found that determiner noun and verb are there . So from the initial state , the determiner the noun and verb are arranged like this. And we can come up with this kind of output .
And this is the summary . And today , I explained about the method for the parsing using the finite state automaton .
And this parsing consists of two stage processing. The first stage is to do the transformation from the context free grammar to finite state automaton. The second is to do the parsing for the input sentence using finite state automaton .
And by this method , we can achieve the high speed parsing with the ability which is very close to that context free grammar .
And I 'm going talk about the multi- lingual on-line dialog rather support system . And as globalization proceeds it is expected that close linguistic communication or communication between different languages is going increase .
And in such communication the language difference is going to be a big challenge . So therefore , in order to overcome this language differences , various support systems are under development .
Some of the examples are the web page or e-mail translation system or keyboard conversation like Internet chats will be translated by a system . And there 's also a dialog translation system using natural language processing .
My presentation is today is going to focus on the on-line keyboard conversation or dialog .
The on-line keyboard dialog , today I 'm going to pickup the keyboard conversation type that one often see in system , such as UNIX 's talk system . Unlike Internet chats , what a user input is going to be projected onto the screen of the other user .
In case of Internet chats , until a user pushes the button it 's not going to be projected onto the screen of the other . So that 's a difference between Internet chatting and on-line keyboard conversation .
And since it 's an on-line keyboard conversation , it 's not written language . It is sort of broken language sometimes . Sometimes there 're sentences which are not grammatically correct .
So it 's like spoken language , and it is possible to proceed pretty smooth conversation . To cope with the on-line keyboard conversation between different languages , several keyboard conversation translation systems were developed , but these systems utilize a system where translation is done sentence by sentence , so the other user has to wait until user inputs one sentence and the sentence has been translated into another language .
So today , I 'd like to propose on-line dialog system between different languages . Unlike the examples that I mentioned this translation system is called simultaneous translation system .
With the use of simultaneous translation system , even in the middle of the sentence , the translation up until the middle of the sentence is going to be projected to the screen of the other user . So , if a user puts on a sentence , I love you so much , in the middle of the inputting I love , the corresponding Japanese is going to be projected words by words not sentence by sentence .
Therefore , it makes it possible for you to see what the other part wants to say and you can sort of interrupt the conversation sometimes .
In order to implement the system , I implemented a system called keyboard dialog system with the simultaneous translating function between English and Japanese . And there 're two terminals , English and Japanese .
And these two terminals are connected by the Internet . If an English- speaking user types in English , through the Internet the sentence will reach to the English-Japanese simultaneous translation system .
And it 's translated into Japanese and translated sentence is going to be projected onto the screen of the Japanese user .
At the same time the English sentence that English user typed in will also be projected onto the screen of the Japanese user , so that the Japanese user can see English and Japanese both .
And in this case the translation goes from English to Japanese only , so Japanese user also types in English .
And in this implementation , I have implemented the system into UNIX workstation and I have used the following three languages , C , GT K plus , and LISP .
And I have used a incremental translation method between English and Japanese . And this shows the actual screen . There 're three screens .
First , on top of the screen it shows what 's input by by an English user . And at the bottom you can see the sentence I like soccer and language .
And translation is projected on the second screen . And you can see that even in the middle of the sentence translation is being done .
And at the bottom the fourth screen , you input your sentence . So user can interrupt while the other user is inputting the sentence .
And this shows the English user 's screen . On the top frame it shows the sentence input by the English user .
And second screen shows what 's input by the English user , so the first screen is the translation of the Japanese user .
Today , I have proposed a multi-lingual on-line dialog system . And also I have talked about a implementation of the keyboard dialog with a simultaneous translation function between English and Japanese .
This concludes my speech , thank you .
Today , I 'd like to talk about multi-lingual on-line dialogue system .
Now we are in the midst of the globalization . And there are increasing chances in which we will communicate in different languages .
Under the circumstances , when we communicate between different languages , the language barrier is very critical . Therefore , in order to remove this language barrier , there are a lot of support systems have been developed .
For example , web page or e-mail could be translated in to different languages . Or chat which is a keyboard dialogue , there are some systems to help , people using this . And then there is also the dialogue translation system .
We thought different system system . We 'd like to talk about keyboard dialogue translation system . I 'd like to focus on the on-line keyboard dialogue , which is very similar to UNIX Talk System .
In Talk System , the people on the Internet unlike the chat environment , when the user input some messages , this message immediately appeared on the other party 's screen .
Usually , in a chat system , until the user push the button , this input could not be appeared on the other side . So , this is the different point from the chat system .
Another feature of this on-line keyboard dialogue is unlike the written language , sometimes people use nongrammatical language . So , this is informal environment .
So , on-line keyboard dialogue , the input sentence is sometimes similar to spoken dialogue or conversation .
Such on-line keyboard dialogue system we are now developing , but on the other hand , there are some conventional types of translation keyboard support system . But this conventional one just allows you to have the translation sentence by sentence . So , the system awaits the sentence input should be completed . So , the system processes sentence by sentence .
So , this time , we try to develop the multi-lingual on-line dialogue system . With this system , unlike the conventional type , the system processes simultaneously while the user inputs the sentence .
This simultaneous translation system allows you to jump in even though the other party in the midst of the inputting the sentence .
And you will see the simultaneous translation on the screen . If the user inputs I love you so much in the midst of inputting , you will see immediately the translation , such as I love you .
So , by doing so , even though the other party still in the midst of inputting , you can anticipate what the other party wants to say .
And you may jump in in the middle . In order to implement this system , we have to come up with keyboard dialogue system with English-Japanese simultaneous translation function .
This is a diagram of the system . There are two terminals , the English user side , Japanese user side .
And two parties will be connected on the Internet .
The English user inputs English sentence , then carried to the other , and through the simultaneous translation system . And Japanese user side will get a translation of the English sentence .
When this other party gets a translation , they at the same time got the original English sentence as well . This time , we 're just focusing on the Japanese-English dialogue .
So , the Japanese user also inputs Japanese sentence .
In this simultaneous translation system this is an incremental translation method . This system could be implemented on the UNIX workstation .
We use the C language and GTK and others . And this is actual screen that Japanese user side gets .
First window , you will see the original English sentence . I like a soccer and language , but in the midst of the word , language .
And then you will see the output of translation .
So , even though the other side in the midst of inputting the word language , you get the translation for the other part .
And when the Japanese user uses the English , this user also inputs the English sentence as well .
This is the English user side 's screen . Again the first window , you will see the original sentence input by Japanese user .
And next window shows the English user 's input screen . By doing so , you will have smoother conversation .
To summarize , I 've just talked about multi-lingual on-line dialogue support system .
This system uses the simultaneous translation functions for the keyboard dialogue system .
We have some prototype , we got some implementation of the translation system onto the keyboard dialogue .
Today , I would like to explain about the multilingual on-line dialogue support system . Nowadays , with the advanced the globalization , in the future , there will be more and more opportunities to carry out the communication amongst different languages .
As such a situation as a backdrop , when we carry out the communication amongst the different languages , then the differences amongst the language will always be a problem as I suppose .
Therefore , in order to eliminate such differences amongst the languages , there are a variety of support systems under development and also has been developed , such as we have the translation system for the web pages or e-mail , or there also exit the translation system for the keyboard dialogue like chatting , or there are other systems , which translate the spoken dialogue .
In my talk here , I 'd like to specifically focus on to the keyboard dialogue translation system .
Online keyboard dialogue or the system to support such a dialogue is now considered . And that is represented by , for example , the UNIX talk system .
Talk system is different from a so-called chatting over the Internet . The input of the user is instantly reflected upon the display of or the partner user .
In the normal situation , it wo n't be reflected until the user pushes the enter button , so this is different from the ordinary system . And another point of characteristics of the keyboard dialogue is that it 's different from the literary language , there are sometimes the expressions which are not always correct in grammar , but there are lots of colloquialism happening there .
So in doing the online keyboard dialogue , the dialogue is more like a spoken form and the smooth conversation is possible .
And to cope with such an online keyboard dialogue , there already exits the couple of the translation keyboard dialogue support system . However such system always utilizes the translation system with the single sentence at a minimum unit . So user , the partner user should wait until the speaking or transmitting user finishes to input a sentence . And this hampers the smooth conversation because you always have to wait .
Therefore , we would like to now propose the multilingual online dialogue support system .
Such a system has a capability which is quite different from the existing system . This allows you to carry out the simultaneous translation system instead of waiting until the single sentence is completed .
And with the simultaneous translation system , even though it is half way through of the input of a single sentence , the result of the input at that moment would be instantly translated and output to the screen of the other party . For example , the user , the originating party , or input the sentence like I love you so much even it 's in a half way through the inputs , it is immediately and instantly , reflected upon and translated to the screen of the receiving user .
Like this , even though the sending party is in the midst of the input , you can make a prediction of what the other party wants to say , and then if necessary , you can also cut in in half way through .
And in order to implement this in the system , we have devised something called the English-Japanese keyboard dialogue system with a simultaneous translation capability . Here we have two terminals , one is for the English user , the other is for a Japanese user .
And that is connected through the Internet .
And after the input via Internet it goes through the English-Japanese simultaneous translation system and with the translation here , it is output with the result of a Japanese translation and at the same time , the original English sentence input by the English user is also displayed on the Japanese user .
And like this , Japanese user can use the original English information in addition to the translation . And since this is the Japanese-English the bilingual system , so the Japanese user will also be allowed to input English sentences .
And in this simultaneous translation system , we incorporated the so-called English and Japanese incremental translation method and that is actually implemented onto the UNIX workstation .
And we used these three languages . And this is the actual execution screen on the Japanese side .
We have three parts of the screen or screen segments . On the top segment , we have a display of the input of the sending partner .
And it 's in the midst of the input of I like succor and language , and the result of the translation is output in the second segment .
And even though it 's still in the midst of the input , you can see that the translation is output .
And on the bottom segment , we see the input and actually the input is carried out in line-editor and the user can edit the sentence in the process of the input .
Next , let me show you the display of the English user side . And just like the former screen , on the top segment , you can see the input of the Japanese user in English .
And on the bottom as I said this is the input segment or input frame for the English user . And with the system implemented , the dialogue is carried out more smoothly .
This is the summary . I have described and I proposed the multilingual online dialogue support system .
And by introducing the simultaneous translation functionality to the keyboard dialogue system , the dialogue and a conversation will be carried out more smoothly And this is a pilot project or pilot equipment .
We have realized the keyboard dialogue system with the English and Japanese simultaneous translation functionality .
Today , I 'm going to make a presentation about the multilingual online dialogue support system . At present there is an increasing globalization in the society and the opportunities for the communication among the different languages is expected to increase .
In that kind of situation , the communication with the different languages , the difference of the languages is anticipated to become an issue . Therefore , the difference of the languages used to be eliminated and for that purpose , various support systems have been developed or under development .
For instance , web page , e-mail , the translation system for those or like chat , the keyboard based dialogue translation system . And the actual spoken language translation system that is the dialogue translation system , these systems exist .
In that kind of environment , in today 's presentation , I would like to highlight the keyboard based online dialogue system . The keyboard dialogue system , online keyboard dialogue , that is to say , the keyboard dialogue system that you 're thinking here is represented by the Unix talk system .
This talk system usually in the Internet , the chat is performed but it is not something like that . In this system , as soon as the user makes the input , that input is displayed on the screen of the other user .
In the conventional ordinary chat , until the user presses the button , the other user 's input is not reflected on the screen . In that area , the chat is different from this talk system .
And the other characteristic of the keyboard based dialogue is that unlike the written language , the very colloquial sentences which are not necessary correct from the view point of the grammar are input . And then therefore , in this kind of online keyboard dialogue there is a conversation with the characteristic similar to the spoken language .
This kind of online keyboard dialogue is compared here with the conventional translation keyboard dialogue support system which has been developed in various ways in the past . In this conventional system , the translation system with the unit of a sentence is utilized and until the user completes the input of the sentence the other user can not get the translation . In other words the other user will have to wait until the conclusion of the input of the full sentence and the various smooth conversation can not take place .
And therefore , here , I would like to propose the multilingual online dialogue support system . In this system , unlike the aforementioned , not in the unit of a sentence , instead of the translation system , based on the unit of a sentence , simultaneous translation system is employed .
By use of the simultaneous translation system , even in the mid course of the input of a sentence , the result of the input after that point is immediately displayed in the form of the translation on the screen of the other user . For instance , the user inputs the sentence of I love you so much and then I love have input and even in this kind of mid course of the input , the other user 's screen shows the display of I love , the result after that point is output on the screen .
And by this , the other party , even during the mid course of the input , will be able to predict the intention of the other user and with that interruption becomes possible that enables the very smooth flow of the conversation .
In the actual implementation of this other product , English-Japanese simultaneous translation function equipped keyboard dialogue system was achieved. And this is the system configuration of that . There 're two terminals and English language user and Japanese language user .
Each has the terminal . With the Internet , they 're interconnected .
The English language user inputs the English sentence and after that input , with the Internet , it is sent to the English-Japanese simultaneous translation system . It is translated here and then the result of the translation is output to the Japanese language user .
And the English sentence input by the English language user will be output on the screen of the Japanese language user in the original language. In other words , the Japanese language user will know the English original sentence , too .
But this is the translation system for English and Japanese alone , and the Japanese language user also does the input in this translation system , for the English and Japanese , we use the methodology called the English-Japanese incremental translation system and it is actually implemented on the Unix work station , these other languages are actually used .
And then this shows the actual screen of the Japanese language user .
There are three set of the screens . On top , the English user 's original English is shown .
And at present , I like succer I like language , language is now fully in put but nevertheless output is made and then the return of the translation is shown below .
Even in the mid course of the input of the sentence , output is made and then the bottom shows the input screen for the user .
And one edit is done for this particular sentence of the response from the user is possible .
Next , the English language user 's screen is shown in the way shown before . In the upper frame , the Japanese language input English sentences are displayed .
And then below as mentioned before , English language user 's input screen is shown .
And by the implementation , in this system , very smooth conversation can be achieved and this has been confirmed . This is the summary .
Today , I made a presentation concerning the multilingual online dialogue support system .
This is the result of the introduction of the Japanese-English simultaneous translation function to the keyboard dialogue system to achieve the smooth conversation and dialogues .
And we achieved the keyboard dialogue system with the function of the English-Japanese simultaneous translation function .
The simultaneous translation system of English lecture is going to be elaborated .
The spoken language translation is the first point in translating spoken language . When two persons converse with each other in different languages , this translation of spoken language will be very useful .
For example , she and he will converse together and through dialogue translation system between the two people . They can converse with each other .
For example , he when he speaks , system the system will translate what he utters into into the language she understands and she will understand what he is saying .
Conventionally , the dialogue translation system was developed in the past , but the systems thus developed so far usually do do translation based upon the unit of one sentence , one sentence by one sentence. So after he speaks , then the system will translate into other language .
And system will create speech . So , actually , the users and system will have to utter or speak alternatively alternatively .
Meanwhile , we talked about the dialogue in the previous side , but when it comes to monologue , what will be the possibility of translating one-way lecture ?
So in that situation , the system will support one-way communication . For example , in international conferences , actually there are a number of international conferences held recent days , and there will be a great demand for translating one-way lecture .
In case of translating one-way lecture or one-way communication , the lecturer talks , the lecture translation system will recognize and translate will translate it into the language . But in this case the lecturer will be continuously talking and also the lecturer will show some gestures that .
There will be some behavioral communication by the lecturer , so the translation has to be synchronized with the gestures or pose or behavioral expressions of the speaker .
And by combining all those elements , simultaneous interpretation system could be implemented . And what are the objectives of researchers ? Then first , we would like to implement the simultaneous machine translation system for lectures .
More specifically , the simultaneous machine translation from the English lecture to Japanese speech , the form is a speech in Japanese . And in terms of processing design , approach will be based upon the incremental spoken language processing .
There is experimental system called LINAS . And we have already implemented those experimental system called LINAS .
Through the performance of this system , LINAS , we would like to pursue the feasibility of translation or machine translation into the speech of the other language . Let me briefly explain what this LINAS is all about .
And outlines of the system , the features of the system are as follows . In case of two different languages with two different word orders , the system will be characterized by the accomplishment of the simultaneity between input and output of the two different languages with different word orders . This is the first point .
Second point , the system will have acquired the knowledge on the language and knowledge on the expert area including technical terms , such will be expected in lecture . This is what we will acquire language knowledge and expert knowledge related to the lecture . And a presentation sheet and resume , summary will be utilized for the system to acquired those knowledge in advance .
The third feature is to generate natural Japanese spoken language , so these are the features of the system . When it comes to the design of the system , actually the Sync Trans , which is the simultaneous written translation system of dialogue , is already there .
As so the system will utilize rather simple design based on the technology of think tank . I would like to elaborate on the system configuration of LINAS .
Basically , there will be two processing modules , first one for simultaneous analysis of English , and second , simultaneous generation of the Japanese . The English speech comes , that English speech will recognize , speech recognition will be made onto the spoken English .
And the simultaneous analysis of English is done and simultaneous generation of the corresponded language will be made and through speech synthesis translated Japanese will be transformed into the spoken language of Japan , so this will be how the translation speech translation is done .
And actually , we implemented the LINAS or Japanese-English simultaneous machine translation system . The system is implemented on UNIX workstation .
For the recognition of English speech , human will do on behalf of a machine , so an English speech will be recognized by people . For Japanese speech output , the output will be made through speech synthesis on Windows PC .
And also people will be involved in preparing language data from the lecture speech in advance . Thus the system utilizes already acquired grammar and other language related data .
And actually we confirm a test of performance of the system using at the English lecture speech input and we actually evaluate feasibility of the simultaneous machine translation of lecture . And we see relatively high feasibility of the system either way .
This is actually display of the results of speech simultaneous translation . The translated speech will be output to the audience and for the sake of enhancing audience understanding , we created this type of a window .
This export of the speech as English input is fed into the system . Correspondingly , Japanese translation will come up .
This lecture happens to be on the topic of the IT , Information Technology and the resultant display of the translated speech . And design and implementation of the LINAS , the simultaneous translation system of the English lecture was given .
Basically it consists of the analysis and synthesis and I 'm just trying to summarize what I mentioned , then the prepared language data based upon the lecture speech and system was implemented on a workstation to confirm the performance .
Still the system is on experimental basis . But in the future we trying to implement the simultaneous machine translation system in the scientific meetings with the minimum delay of ten minutes or so . This completes my lecture .
Thank you .
I would like to talk about simultaneous interpreting interpreting system for English monologue .
When we are to translate spoken language among or between different languages , it is quite helpful to translate a conversational dialogue between , for example , he and she in different languages . When they engage in dialogue , if there is a system to translate , the system which goes between , they are able to converse with each other even in different languages .
For example , when he speaks , the system translates what he speaks into another language for her to listen .
When look at the conventional system for the dialogue translation system , there are some kinds of system that have been invented . But when we look at these conventional systems , the system is depending on or is based on the translation sentence by sentence .
In other words , only after he finished his speaking , the result of that translation of that sentence is output verbally . So as a result , what happens is that the users and systems output alternatively , not at the same time .
On the other hand , in case of monologue such as lecture , the translation goes as follows because it is unilateral communication .
The system is to support the one-way communication . On occasions , such as international conferences , it could be used and we have increasing number of those occasions these days .
And we can think that we have a great demand for this type of system in case of interpreting as you can see on the screen , what he speaks to the audience , the system translates it into another language for the audience to listen . In this case , the speaker continuously speaks , in using some kind of physical message or gesture .
And in order to realize this kind of system for simultaneous translation , we have to think about various factors . First the objective of the research , we first focus on lectures to develop the simultaneous interpreting system .
For example , in case of English lecture , just to be translated into Japanese voice , the simultaneous translation has to be conducted and that has been picked up as one of the objective of the system . And the design should be based on incremental spoken language processing , that 's another objective of this research .
And we try to implement the experimental system called LINAS And through the operation of this system LINAS , we want it to examine the feasibility of simultaneous interpreting system . These are the objectives .
So let me move on to the brief explanation about the system LINAS .
First about its features . Between languages , but different word orders , such as English versus Japanese , input and output , such as input in English and output in Japanese could be conducted concurrently or simultaneously .
The second feature is that , when a lecture is to be translated simultaneously , the linguistic as well as technical knowledge including technical terms can be obtained in advance regarding that particular lecture . And such materials to be obtained in advance could be hard copy of the visual materials .
And the third feature is that the translation could be produced in a very natural spoken language .
Next is about the system design . Simultaneous translation system has been already developed , called Sync Trans .
And that is to be used as the basis to come up with hope of the simple design for this system . And this is the structure of the system , LINAS .
Basically , the English voice is analyzed , that 's one set of process . And another process integrated in the system is to output Japanese .
When English is heard by the system , the system recognizes that voice , in this case , English . And at the same time , analysis is made . And result of the analysis is used as the basis to produce the Japanese translation .
And the production analysis is used to synthesize voice in Japanese and these steps are conducted concurrently .
When English is to be translated simultaneously into Japanese , the LINAS is now made available to that end . LINAS is used or applied on the Unix Workstation .
And this for the features , as far as recognition is concerned , at this , for the time being , human being takes a role of recognizing English voice . And with respect to synthesis , from personal computers with Windows , the Japanese translation could be put out .
And respect to the material obtaining in advance from scripts of the lecture , for example the linguistic data are produced or prepared manually using dictionaries .
So English lecture voice is input in order to confirm its operation , through which we could see the feasibility of monologue simultaneous translation , which we put quite high expectation for .
This is an example of actual results of the interpreting using the system .
But , of course , the actual result of the system 's operation is verbal for the audience to listen . But for them to help understand what is heard , a such screen is helpful .
This is the English portion , the input portion , which comes out continuously , in accordance of which Japanese translation also comes out .
This is the results of the translation of the conference with the topic of Information Technology .
Let me summarize my talk . The LINAS , the system for simultaneous translation for English monologue and I have explained its design and implementation .
In terms of design , the system analyzes and synthesizes the data . And in order to implement the system , the data are produced based on the script and this is implemented on the workstation , this is still experimental basis .
But toward the future , we hope to use this system for a short period of the time , ten to fifteen minuets for simultaneous translation at any actual academic conference .
Thank you for your attention .
I 'd like to talk about simultaneous translation system for English lecture .
When spoken language is being translated different languages spoken by different parties , and this is good for that purpose . For instance , she and he are talking with each other , and that dialogue translation system can be put between them so that they can talk with each other .
In other words , he speaks something under this system will translate that so that she would listen to that . That is the structure of the system .
Traditionally , this kind of dialogue translation system has been developed before . But the previous systems have been based upon the , the translation of one sentence as a unit .
So when he speaks , the system will put out the result of the translation and the express of the translation with the voice . So he or she or users and the system will alternate in speaking .
On the other hand , the previous one was dialogue but we are able to think about monologue translation which is one way communication to be supported by this kind of translation system . For instance , at the time of the international conference , we see the increasing of this kind of international conference and this type of translation is in great demands .
In a case of translation or interpretation and the translator will express the generated the translation in the form of voice after going through the system . And in this case , the speaker will continuously speak and they say gesture by the speaker and we need to synchronize with the speaker 's gestures .
In order to realize this , we need to have a simultaneous translation system desirably and therefore we focused upon monologue type lecture . And we try to realize the simultaneous translation system for monologue type lectures .
To be more specific for English language lecture it is to be converted to Japanese language as simultaneous translation methods .
And the basic technology for this purpose is the incremental spoken language processing . And the design is based upon this approach of incremental spoken language processes .
This is the experimental system called LINAS . And we realize that this is the system .
Operation of the system will allow us to confirm the feasibility of the simultaneous translation system . So this system is the LINAS and I 'd like to explain the system very briefly .
First of all , the features of the system are as follows . First of all , between different languages with different word orders like between Japanese and English . The English input and the Japanese output can be done simultaneously .
And the secondly regarding the contents of the lecture , the language knowledge , and other expertise related to the lectures contained in the lecture and the before the translation those knowledge will be acquired . For instance , the resume or sheet and material for the lecture will be given .
And the thirdly , as much as possible natural Japanese spoken language will be generated . The actual design of the system is based upon the Sync Trance that is the dialogue simultaneous translation system .
And based upon this Sync Trance we we 'd like to make a simple design for the translation of one way lectures . And this is the system configuration of LINAS .
Basically this is for the analysis of English and the generation of Japanese . There are two modules for the analysis of English and the generation of Japanese .
Once English is input the voices are recognized and the result is in English . And simultaneously with the recognition of English it has been analyzed . And for their result of the analysis of English , Japanese will be generated .
And the result of the generation will go through the voices synthesis and output will be the Japanese voice . So each different component of the processing will be done simultaneously to realize a mechanism of simultaneous translation .
Now when English is translated into Japanese , we develop LINAS for the translation from English to Japanese .
This is the on the UNIX workstation computer which features includes the following points . First of all , the recognition of English voice is done by human beings .
When it comes to speaking , or voice generation synthesis Japanese voice will be output from computer .
And apply it to the translation on the text , for lecture will be given , and language data is generated manually before the lecture , and the manual will be useful for the actual translation . Operation , and , through the input of the voice of English lecture , we confirm whether the system can be operated , and whether it works well or not .
By doing so , we would see the feasibility of the simultaneous translation of one way lecture . And I see this is the promising technology .
Let me show you the actual result of the translation on the display .
The result of the translation operation is in the form of sound as output form . But for the understanding of the listeners and audience , these are the printouts .
This is the input in English and the input will increase on the English sides . And if you look at the Japanese side , you 'll see the output of the Japanese translation .
This lecture is on the topic of information technology . Finally , We and realize I talked about the design and realization of the simultaneous translation system of English lecture .
It is based upon the two components namely analysis and the synthesis and based upon the text of lecture language related data is already prepared . And the translation system is implemented on the workstation , and operation was confirmed .
And this moment , this is at the experimental level , but in a future we 'd like to expand application to ten minutes or fifteen minutes lecture at academic conferences and we 'd like to realize a simultaneous translation system for the lecture at academic conferences .
Now , I 'd like to talk on simultaneous interpreting system for English monologue .
The first issue is about translation of spoken language . In that case , it is a dialogue between two people who speak different language .
And the translation system will be useful to translate that dialogue . For example , when this lady and gentleman talk to each other by using dialogue translation system , they can communicate with each other .
That is what is spoken by gentleman will be translated by the translation system , and the lady can listen to that .
This type of dialogue translation system has been developed . Regarding the system developed so far , they make a translation based on the sentence .
That means a gentleman 's finished the sentence , the system will translate the whole sentence and which will be spoken language . As a result , the both speakers and the system will make a speech alternatively .
Meanwhile , in the case of translation of speech of a monologue , the translation is also possible .
In this case , this is the support for unilateral communication . In the case of international conference and the number of these cases has been increasing recently . And the demand for interpreter is increasing .
And in the case of this kind of interpretation when a speaker speaker make a speech , the system will translate it , and address it to the audience . In this case , the speaker makes a speech continuously with gesture .
So , to synchronize with the speaker 's gesture is important , too .
In that case simultaneous translation is needed . So we focused on the translation of speech or monologue .
Specifically , when the speech is made in English , we are trying to develop a system to translate this English into Japanese . For basis , we 'd like take approach to take incremental processing of spoken language .
And we have developed a system called LINAS already , and through this system simultaneous interpretation will be achieved . And we 'd like to study the feasibility of the system .
I 'd like to explain about the system LINAS briefly .
As the feature of the system , for example , several language has a different word order , for example , Japanese and English has a different word order . In this case , input of the language and output of the language should be implemented simultaneously .
And regarding the speech the linguistic knowledge or other special knowledge including technical terms and should be acquired in advance . For example , the sheet of the presentation or resume , from these materials these information should be acquired in advance .
And the to generate information in a natural spoken Japanese .
As a design of the system , we are adopting the technology called Sync Trans . Using this system , we are developing a system for translating monologue in speech .
I 'd like to explain about the system of LINAS .
This LINAS , it will process the two procedures , one is analysis of English and the other is generation of Japanese . When the system recognizes the spoken English speech , it will start to analysis , and to the result of the analysis , Japanese Japanese will be generated .
And through the speech synthesis or spoken Japanese will be implemented . All these system will be implemented at the same time .
When actually , to translate English into Japanese , we have developed the system called LINAS , and it 'll be implemented on the UNIX workstation .
Regarding the spoken spoken language , the human being is carrying out recognition of English speech . And regarding the or speech synthesis , the Japanese speech will be produced by Windows PC .
And the necessary linguistic data will be made in advance from the script or other materials . In a case to actually input the English speech , we we made a confirmation of gesture , too .
And we 've studied the feasibility of simultaneous interpretation of monologue . And I think it is highly possible .
This is the example of the actual translation .
The result of the translation will be delivered to audience in the form of sound . To help the understanding of the audience , we are making this type of print , too .
When English is input , the information will be accumulated into their upper part , and the Japanese translation will be displayed in the lower part .
This is a lecture on information technology . In conclusion , we 've been trying to develop a simultaneous interpretation system named LINAS .
This is for English speech . And it is consisting of analysis of the spoken language and generation of the other language . And this result will be implemented over the workstation . And after that the actual gesture will be confirmed .
All this system is in a experimental level , but in near future , we 'd like to use it in the , for example , academic lecture , such as ten or twenty minutes length lectures . Thank you very much .
Today , Japanese processing based on derivation of grammar and its application is a theme of by lecture , I 'd like to report research in this area .
First , Japanese processing by computer is the first topic . In general , when the computer processes the human spoken language , first , the input sentence will be going through morphological analysis followed by parsing and further semantical analysis and contextual analysis .
And this is a series of analysis to process the human spoken language . First comes to morphological analysis , this is the first process the input will go through. So if the analysis is not done correctly at this first stage , the ensuing processes also will fail .
Therefore this morphological analysis is a greater important as the first step of a series of processing in Japanese , everything comes in the sentence without interval , without instant distinctions of words unlike English .
I guess English , there were spaces between different words , but Japanese , the computer ca n't tell where is the partition between the two words. So computer has to divide the sentence into words .
And also they have to really identify which categories each word belongs to. For example , in case of the hanseibun or regret statement is a noun and wo is the prepositional particle .
And kaka is the verb so each category has to be tag to a word . So each word have to be with the tag indicating which category each word belongs to .
So in this morphological analysis , in terms of the verb , although this slide shows have rather over-simplified morphology , in real situation , the verb is more complicated than , because it 's written . This issue was programmers you might have learned in elementary school and junior high school .
In school grammar , the verb kaku , to write will have six level conjugation like like kakanai kaki kaku kaku kake kake .
And each conjugation is called first imperfect form , continuative form , concluding form , attributive form , prepositional form and imperative form . So , there are different types of conjugation like five stage , conjugation and kami-ichidan conjugation .
And on the top of those conjugations , seru is is the auxiliary verb . Those auxiliary verb , seru actually only comes after imperfect form of a verb .
For example , rareru , this is to show the passive form . also this rare only follows the imperfect form of a verb and ta , to mean completion and conjugation is very irregular and there is no imperative and comparative form usage of this auxiliary verb .
So such there are very complicated the conjugation and there is conjunction roles . In order to do kakasareta , then we have the computer which could have process capability of complicated rules of relating verb with the auxiliary verb .
So for particularly Japanese language , the system needs the process capability o f complicated conjugation. But as long as Japanese language have conjugation , you may think that a processing have to deal with conjugation .
Having said that , there has been a proposal grammar , a certain that Japanese does not conjugate .
So other than the grammar we are familiar in school , there is another grammar for , of Japanese language That is called , which I am going to explain to you , derivational grammar .
And this grammar focus upon the alternative language property of the Japanese in Japanese , Korean , Turkey languages , actually these three languages are very similar . And these three languages have the same property , are called agglutinative character .
And derivational grammar really focuses , focused on this common property of agglutination . in this grammar , conjugation of verb , is considered to be stem plus suffix .
For example , let 's take a look at conjugation of kaku , the verb . And school grammar conjugation is written in the central column . Let 's take a look here , kakanai kakimasu , we see the conjugations of the verb . Because they are changed , that 's why called conjugation .
But when it comes to the phonological approach , hiragana is the written alphabets here , based upon phonological approach . So in this grammar , you see consonant ke and this part , in yellow part , does not change. That means this part corresponding to the stem of the word .
And white part of the right is suffix . Therefore , the derivational grammar , in comparison with conventional school grammar , is a grammar rather simple and systematic .
So when rely on computer for Japanese processing , derivational grammar seems more befitting to processing of Japanese language than the school grammar is . Then we developed martial the morphological analytical system .
This has mush simpler grammar in it and analysis is much simpler even the otherwise .
Analysis accuracy based on experimental results accounts to ninety eight percent in case of Japanese sentence , into words accuracy and right category tags or attached word . And Japanese is analyzed as such as in the blue part .
As apply researchers using Majo , we tackle with the translation between Japanese and Uigur . the language called Uigur might be unfamiliar to you. But this is a the language spoken by the people living in the Uigur area of Republic of China .
As Japanese the word order is almost the same as Japanese. And as Japanese , it 's agglutinative language . And after the morphological analysis they going through the syntactical analysis and which is very a good similarity with Japanese .
Look at the input sentence , it was divided into here and after the morphological analysis each element could be translated to Uigur rather easily This is a summary . We focused on derivational grammar , different from the conventional school grammar , to do Japanese spoken language analysis .
This enables us to do much simpler analysis than before .
And also in application area , machine translation form Japan used to Uigur has been doing by taking an advantage of similarity of the two languages . And right now , translation verbs have become possible and we are working on the translation the category other than verb .
Today I would like to talk about derivational grammar approach to Japanese processing aid and its application , which is our research theme .
First about the Japanese processing using computers . Generally speaking , when the computer processes human spoken language , first the input sentences enter into morphological analysis and then move onto syntactical analysis , move onto semantic and then context analysis. These are the processes that input sentences go through .
The first process is morphological analysis . What morphological analysis is or what it does is it analyzes a sentences and as this is the first step of entire process , it will has to be correct otherwise it will be affecting the rest of the flow .
This order more therefore important to make sure that this is done correctly .
When we look at a Japanese sentence , it is not written in this way with all these words set aparts , which is actually in the case of English .
So it is quite easy in the case of English to see all the nouns and verbs . But in the case of Japanese , computer find it very difficult to identify each word in a Japanese sentence , so we need to put them into this form of writing .
Addition , for example , for this sentence , this hanseibun , this part is a noun and following one wo is a post-position particle , which is followed by a verb and then three auxiliary verbs .
So each word needs to be tagged to show what part of the speech it represents . So two types of work involved in morphological analysis in Japanese spoken language , first divides one sentence into words and put a tag to each part .
So the real sentences are not as simple as this is , such as this . I 'm sure you are familiar , when you remember back in your primary or junior high school days , this is a typical school grammar .
For example , for the verb kaku , which means writing , it conjugates kaka , kaki , kaku , kaku , kake , kake . That is the conjugation of verbs .
So different forms are evolved , imperfect , continuative , conclusive , attributive , provisional , imperative . So , the five steps and different types of conjugation , I remember that we all had to learn and study .
And in the case of auxiliary verb , seru , it also inflects . However , this se only can be connected to the imperfect form of a verb .
This rareru , which means a passive tense , this can only go with the imperfect form of a verb . And this is the set of no , inflection , which means the perfection , so this can not get along with the two forms , continuative and imperative .
It can only connect to the provisional collection , continuative form .
So these are the very complex way of connections of each words as well as conjugation . So in order to analyze , for example kakase rare ta , the computer has to all these complex data rules build in .
So that is the one challenge in processing Japanese language . It is necessary to be able to process such complicated conjugations .
But we can also come up with another unique assumption for a different grammar . In other words , Japanese language does not conjugate .
You may think that there is only the one school grammar of the Japanese but just not true .
There is another type of grammar that is called derivational grammar . Derivational grammar is that , what it means is that we first focus on the ness ; agglutination of Japanese or some other languages .
And this derivational grammar pre-supposes no conjugation .
And with respect to paradigm of a conjugation of a verb , I will show you some examples , it can divide into the stem and suffix . For example , in the case of the verb kaku , writing it conjugates as follows , kakanai kakimasu .
And this portion does conjugate , that is why this is called conjugation , but this is based on the school grammar .
But when we on the derivational grammar , each part of the word is divided into consonant and vowel . And you can see that part which remains unchanged always ends up with the consonant called k in this case . And this portion does not change at all .
And it is followed by suffix , such as these and that part represents the conjugation .
So , compared with the school grammar , this derivational grammar is quite simple and systematic . And it is a lot more appropriate to use this type of grammar for the purpose of developing the system that we are talking about .
So , we decided to develop the morphological analysis system based on this derivational grammar , which has a very simple design .
And as a result of our study , the accuracy of analysis of Japanese sentences is ninety eight percent . Like in the case of kakase rare ta , this can be analyzed in this way .
when it is translated into Uighur , and as one of the application , we are also studying machine translation between Japanese and Uighur . Uighur , this may not be familiar to all of you , but Uighur is language spoken in the Uighur district , that is the part of China .
It is quite similar to Japanese in terms of the sequence or word order . So , when a sentence is analyzed by morpheme , it becomes rather easy to translate using the machine between these two languages because of that reason .
This is one example . This is the input sentence , kakase rare ta , it is to be translated into Uighur , this slide shows how it is processed to get to the translation .
So , we are doing Japanese analysis based on derivational grammar , which is different from school grammar , which enables us to analyze in simple way .
And as a result , one of the applications we are now working on is machine translation between Japanese and Uighur . And the reason behind that application is the similarity between the two languages and word for word translation of the verbs and some other phrases as well .
Thank you .
Today , I 'd like to talk about the Japanese language processing based upon derivational grammar and its application. I 'd like to talk about the result of our research .
First of all Japanese language processing by computer . Generally speaking , when a computer processes human languages first of all , the input of the sentences will be divided with a morphological analysis followed by parsing , followed by semantic analysis and context analysis .
And the finally through these processes human spoken words will be analyzed. First one is the morphological analysis that is first process to be done . If there should be any mistakes at this step , the later analysis and the process will be wrong .
And therefore , this process is critical . In addition , language of Japanese They are not divided in writing .
In a case of English , there are space between words , and therefore , you can identify which one is one word . But in a case of Japanese language it is a continuous , therefore the computer can not see the separation of different words .
And therefore , it 's necessary to divide into pieces of words . And the each word should be identified .
For instance this one the self examination report is a noun , this is the postpositional particle , this is verb , ka is a verb and then followed by auxiliary verb .
And therefore , each one should be with a part of speech tag . So it has to be divided into different parts of the speech and we need to put the part of speech tag to each component of the words . That is a morphological analysis .
This is a simplified expression of the structure of the Japanese sentence , but this is not that simple . Actually , this is a little bit more complex. I think that 's a elementary school or junior high school I think you have learned a school grammar .
And this is the kaku . There is inflection of verbs kaku kaku kaku toki kake ba and so forth , imperfect continuative , conclusive , attributive , provisional imperative are the names for each different types of inflection .
For instance , five stages and also the upper one stage the inflection , there are different types of conjugation of Japanese verbs .
And the seru is an auxiliary verb , that is to make somebody do something . And in addition to these conjugations seru is the connected only to imperfects form of a verb .
This is rareru. This is a passive form , and this is connected only to imperfect form of a verb . And this is ta which means perfects , but it has a irregular inflections , and there is no imperative nor continuative form and the only connected to continuative form of the previous word .
Therefore , this is a highly complex inflexion and also the rules for the connection between words . Therefore , when kakase rare ta is analyzed , you have to go through the processes which require this very complex inflections .
Therefore , for the analysis of Japanese language , the process of very complex conjugations is needed .
As far as the Japanese language has a conjugation , you need to have the processing of conjugation for Japanese language , but you can assume that Japanese language does not have any inflexion , and that is one of theories in addition to school grammar actually there another type of grammar to describe Japanese language , which is the derivational of grammar .
Derivational grammar focus upon the agglutinative character of Japanese language .
Japanese and the Korean and Turkish languages are similar with each other . And agglutinative character is common to these .
And derivational grammar focused upon this feature and the conjugation of verbs that is inflection that I talked about , is made up of a stem of the verb and the suffix .
Let me give you an example . Earlier , I talked about the kaku which means write , in a case of school grammar , this is the type of a conjugation for the particular verb , this parts kaka nai , kaki masu do n't write , write and there are the different forms depending upon the conjugation .
But , if you look at a phonemes , for instance , this is written in Roman characters for hiragana expression . this part kaku to write is with the consonant k , it does n't change which means a this part constitute a stem of the word , and then this is connected with a suffix to show the different types of the conjugation forms .
Compared with the derivational grammar is simplified and more systematic . So if you want to use computer for the processing of Japanese language derivational grammar is much more suitable in comparison with the school grammar .
And therefore we decided to make a morphological analysis system based upon derivational and grammar and analysis are much more simplified and analyses are procession is as high as ninety eight percent .
putting into different components of the word of Japanese and the analysis is as precise as ninety eight percent , this is the result of the analysis of the phrase .
kakase rare ta and based upon this kind of theory we perform the study of the translation between Japanese and Uighur . Uighur is a language spoken at the Shangjan Uighur and people living in a Shangjan Uighur area of China .
Although you may not aware of that , but these two language is very similar and word orders are similar between Japanese and Uighur . Therefore after morphological analysis by just replacing by respective words , it is possible to make a translation .
Let me give you the previous example of kakase rare ta I was made write . And after morphological analysis you can replace by Uighur words , and you can get a translation in Uighur .
In summary , we used derivational grammar rather than traditional school grammar for Japanese language analysis which enabled us simpler analysis .
And for the application of this technology , we are conducting translation between Japanese and Uigjur .
We make a full use of the similarity between Japanese and Uighur . And translation of the verbal phrases as well as the translation of a sentences from Japanese to Uighur .
On this occasion , I 'd like to talk about derivational grammar approach to Japanese processing and its application , which is theme of our study .
the first of all , I 'd like to explain about the Japanese processing by computer . When you try to translate Japanese by computer , first you input the sentence and analyze it in a morphological approach and other process of parsing , semantic analysis , and context analysis .
The first process is the morphological analysis . This is the first processing to the speech , so if if a mistake will be made at this stage a lot of processing will not be accurate .
So the processing at this stage is really important .
And in addition to this , Japanese language is not a divided into several words . In case of English the words are written in a divided form , while Japanese is written as a whole sentence , so we have to divide the sentence into several parts so that the computer recognize each parts .
And we have to add function of the words to each parts .
For example , hanseibun this part is a noun , this part is a auxiliary verbs . And the sentence will be divided into like this , nouns , postpositional particle , verb , auxiliary verbs .
This is the process of morphological analysis . It looks very simple , but actually it is very complicated process . Will you please see the next slide ?
This is the school grammar you might learn this at school . for example , in the school grammar , the word write kaku will be explained like this .
It has a several forms including imperfect form , tintinuative ; continuative form , conclusive form , attributive form like this from the top to bottom . And there are many complex form form of conjugation .
And along with the conjugation this cell is a auxiliary verb which means the stimulation . And this auxiliary verb conjugate not only conjugate like this but it has a rule it will be attached to imperfect form alone .
And if you see this part rareru it will be attached to continuative form alone . And ta this part means conclusion of the action but conjugation imperfect because it does n't have a continuative form and a imperative form .
And will not be it will be attached to continuative form alone .
Like this , it has such a complex conjugation rule and the forms . So in order to analyze a verb or sentence I was forced to write .
You need this kind of complex processing . So first problem of morphological analysis of Japanese is the processing of conjugation of a verb .
But Japanese has a conjugation form . Everybody might think like this way .
But , we made assumption that the Japanese does n't conjugate . This approach is now proposed .
I 'd like explain to explain about this approach .
It is called derivational grammar . It takes advantage of agglutinative feature of Japanese .
Japanese or Korean language or Turkish a has a similar characteristic with each other . We paid attention to this point .
And the derivational grammar is based on this point . And regarding the conjugation of the verb , It has a stem attached with the suffix .
It will be explained in this manner . For example , we will look take a look at the conjugation of the verb write , to write . In the school grammar , in the imperial form and continuative form they 'll make a conjugation .
That 's a reason why this school grammar is called conjugation .
But in a rational ; derivational grammar , the word will be explained as follows . It consists of the kaku or this part , and part will not make any change and to this part other grammatical forms being attached .
So this derivational grammar is much easier and simpler compared with the traditional school grammar . So in processing by computer this derivational grammar approach will be more adequate .
So we have developed a morpheme analysis system Majo . It has a more simple grammar and more simpler analysis .
Its analysis accuracy was ninety-eight percent .
I t analyzed Japanese correctly and if you use this Majo system to analyze the word kakase rareta , I was forced to write will be explained on this chart . And we made application to the translation between Japanese and Uighur .
You might not have knowledge about Uighur . But it is a language people of the Shinkyo Uighur region among Mongolia .
Because the both of them have a similar word order . So the syntactical similarity is a very high .
So by replacing each word from Japanese into Uighur , the translation to certain extent is possible . And on this chart , you can see the translation between Japanese and Uighur .
In conclusion , instead of traditional school grammar 's analysis , we are adopting derivational analysis system which enables the translation more simpler .
And as application , we are developing the translation between Japanese and Uighur based on the similarity of these two languages . The translation of verb phrase has been developed already .
Talk on the topic of simultaneous translation by computers .
The researches for computer translation have been done for a long time , this is called machine translation .
There are basic researches for machine translation . The research basis first is the research to do the translation of written language that is called text translation .
And the other basic research area is spoken language translation , in which the people spoken language is translated by a computer .
And we are now trying to do the research of simultaneous interpretation .
And in this area , the spoken language will be translated , but in case of spoken language translation , translation is done one sentence by one sentence .
That means after person finishes one sentence , then the machine will translate , whereas in simultaneous translation the translation is simultaneously as people speak .
But there are various difficulties involved in simultaneous translation .
First , without knowing what the sentence would be in its entirety , translation has to be started . In other words , You have to start translating without knowing exactly what would be the entire sentence or sentence would end .
And also between Japanese and English , unlike German versus English or French versus English , the word order is significantly different between Japanese and English . In those two languages with different word order , simultaneous translation becomes much harder than the otherwise .
And far difficulty is the speed . The translator has to catch up with the speaker 's speed .
So , actually , the simultaneous interpretation is quite tough job , but actually , there are simultaneous translators doing this performance all the time . Then how the human simultaneous translations do translation ?
First they consider circumstances and context and they do somewhat prediction what speaker would have to say next . And even in the middle of sentence , they will do rather flexible translations so that whatever comes next , the translation would follow what comes next .
And the thirdly , the people simultaneous translators do not translate everything . When he or she considers the incoming information is not really that necessary , she would n't translate. So there is a selection process of information in the minds of interpreters .
So , various wide variety of techniques as I mentioned , people simultaneous translators are doing the translation simultaneously . For the computer , we have to teach those techniques for computers to do translation simultaneously .
In order to teach computers the human translators ' technique , we really have to know definitively what are the techniques of those human translators .
Under that recognition , we are building up the simultaneous interpreters ' database . In the database , we accumulate the data on actual simultaneous translators ' translations .
And using those data , we analyze the human simultaneous interpreter 's techniques . And by repetitive excises of those analysis , how to translate or what makes the better simultaneous translations be pursued .
Then , next , how database is being prepared ? That is topic I would like to explain to you .
First is a recording process . We ask native speakers , for example , Japanese speaking Japanese language or foreign people speaking their own language .
Or those , native speakers will be employed and simultaneous interpreters will translate simultaneously those voices and that will be followed by transcription .
And we put the voice translation into alphabets and we added some information as necessary . And the top table shows the original speakers ' speech and the lower table shows the interpreters ' performance .
First , Hello , hello is this Hilton ? And the speakers ask for Hilton Hotel as shown in red and this shows when the utterance starts and ends .
The information on time is indicated and you see there are signals with the necessary information and that we create the data after transcribed . And looking at those data , we analyze how human will translate the original speech simultaneously .
Let me show you some examples , what are the techniques utilized by the interpreters . This is the Japanese input , software engineering is the experimental field and the translator actually says English as such written at the bottom .
But after this Japanese sentence , there is additional phrases called to iu iikata mo dekiru de shou , what original speaker says . And in comparison with the original Japanese , the translator 's output is not perfectly matching .
In a simple way there is some rephrasing . In other word , the first translated sentence is not perfect , so the human interpreter will retranslate every sentence to make the translation mush closer to the original sentence .
So interpreters have to add some additional words .
Then what was it actual interpreters did ? So far I explained about theoretical things , but let me turn eyes to what actually interpreters did . She or he added you may be able to say that .
By adding that sentence , that actually corresponds to the original speech . So simultaneous translator do n't have to retranslate or paraphrase she whatever already said in advance .
That 's what actual translators did , I suppose , what theoretically people might think as I said in the first half .
This is the summary .
For computer simultaneous interpreting , we have to teach a computer the technique of human translators and the database has to be prepared and export the techniques of interpreters. And the last we 've shown the example of the techniques used by the human interpreters. We 'd like to continue with the analysis in the future as well .
I would like talk about or make a presentation on simultaneous machine interpretation . The studies regarding machine interpretation have long been carried out .
We called kikai honyaku which means machine translation .
The basic type is text translation . Text translation is the basis of machine translation or interpretation. The text translation is a study on the written translation .
And another study is about spoken language .
In other words , study to translate human spoken language . And we are currently trying to let machine interpret simultaneously .
This is also again human spoken language translation . But in the case of spoken language translation , the translation goes sentence by sentence .
In other words , only after one sentence is spoken completely , translation starts . While in the case of simultaneous interpretation , translation starts almost concurrently or simultaneously .
But the input of spoken language and there are a lot of challenges or difficulties involved simultaneous interpretation . First , you have to start interpreting without fully understanding the meaning of the entire sentence .
Before you understand the enter sentence meaning , you have to very start translating that sentence . Another challenge is related to the different word orders as compare to a combination of two languages , such as English and French , Japanese and English do have such remarkably different word orders and that gives another difficulty to simultaneous interpretation .
Also simultaneous interpretation forces you to follow or keep up with the speed of a speaker . That 's another difficulty .
So now you see how difficult it is . But actually the human simultaneous interpreters are actually doing this task .
So , how they are getting around ?
They anticipates the situations , they anticipate what a speaker is going to talk about based on the surroundings , situation and contexts . And with respect to the requirement of interpreting without fully understanding the entire sentence , they are quite flexible in accommodating various types of sentences .
And if you are to translate every word a speaker says , it will be very difficult . If not necessary , they select or sort out the information from speakers ' sentences .
So these are some of the techniques that human simultaneous interpreters are using .
So if we want the machine to do the same job , we need to teach these techniques to the computer . In order to teach computer these human interpreters ' techniques , first we need to know in detail about those techniques .
To that aim , we are building the simultaneous interpretation database . The database is the compilation of actual cases of the interpreters .
And from the database , we learn or study the actual techniques that are used by the interpreters and how to interpret simultaneously , how better you can interpret simultaneously could be analyzed .
So let us look at the procedures how those database are built .
We first , of course , do recording , native speaker , the Japanese speaking Japanese or English native speaking English , is involved . That voice is recorded and that is simultaneously interpreted by human simultaneous interpreter from English to Japanese or vise versa .
And after the recording , it is put into writing and for further analysis , necessary information is added to that writing. I will show you one example of such written-up data .
This is what 's speaker says and this is the script what interpreter said . moshi moshi Hilton san desuka is the sentence that is spoken by the speaker .
And this portion indicates English translation by the interpreter together with the time and second when that is recorded . So this is one of the example of the written-up data and added necessary information .
So using these data we are analyzing what kind of techniques are actually used by the interpreters . I will show you an example of the technique that is actually used .
This is the Japanese sentence input , sofutouea kougaku to iu mono ha jikkentekina bunya da . When an interpreter listened to this sentence , he or she translates it into English such as this .
However , actually , after this sentence , toiu iikata mo dekirudehsou followed .
However , the English translation is already completed , which is not actually appropriate translation for the entire Japanese sentence . So , in such a situation , how they come around ?
The simple way or measure to come around in the situation is simply just restating , starts all over again .
Figuring out it is not appropriate translation , then he or she can just restate the entire translation from the very beginning of the sentence . However when you use this technique , it become redundant. And when you have to say unnecessary words or say the words twice .
So here is the actual technique used by the interpreter . After this sentence , you may be able to say that way . He or she said this .
So together with this and that , that could perfectly corresponded to the rational Japanese sentence .
So this is how he or she got around without restating once again . Summary for simultaneous machine interpretation , we need to teach the machine the human interpreters ' techniques .
And we are producing database to study or analyze the techniques .
And I 'll show some examples of the actual techniques used by the interpreters during this presentation and we are going to continue this study or analysis .
Thank you for your attention .
Now , I 'd like to talk about a simultaneous translation by computers . I 'd like to start my presentation .
The translation by computer has been studied since the past . This is called machine translation .
The most important basis for machine translation is the translation of text as part of research activities which is the translation of written language , written by human beings .
On the other hand , spoken language translation is also performed which means that human beings speak and that language is the translated .
And the in addition to these , we are thinking of simultaneous translation by computers .
But in a case of simultaneous translation , that is translation by spoken language by humans . In a case of a spoken language translation , that was done by each sentence .
In that ways , a human speaks one sentence , and then after the sentence completed , the translation processing starts . But in a case of simultaneous translation , translation is in parallel with the inputs or they are simultaneous .
And there are many difficulties in simultaneous translation , and the thinking about what they are . First of all , we do not understand the whole of translation , but still you have to start translating .
In other words , the meaning of the sentence as a whole is not yet known. But they have to start to translate anyway .
And that is a difficulty of simultaneous translation . And if you think of the combination between Japanese and English in comparison with the Germany and English and the French and English , there are major difference in word orders between Japanese and English . And if that is the case simultaneous translation is more difficult .
In simultaneous translation , the translation has to keep up with the speed of the speaker . That is another difficulty .
So translation simultaneously is difficult , but there are simultaneous translators , they are actually doing it translating simultaneously .
Then , how they realize the simultaneous translation . First of all , they they think about circumstances and the contexts to anticipate what the speaker would say .
And anticipating what would come next , they are translating as well . And the regarding the outputs , their translation is fixable enough to respond to different sentence possibilities after the phrase .
And not all of the spoken words are translated . If some of the words are deemed unnecessary , the part will be eliminated from output of translation . Therefore information is to be sorted out .
So simultaneous translators apply different techniques for the work over a simultaneous translation .
And therefore , for the computer simultaneous translation we believe that we have to teach computers these techniques for simultaneous translation . The technique of a simultaneous translation should be taught to computers , but in order to do that , you need to know in detail what are the techniques of simultaneous interpreters .
So , we made a database for simultaneous translation which is made up of large amount of examples of simultaneous translation by simultaneous interpreters .
And by analyzing the result of simultaneous translation , we analyze techniques of translators by repeating this process How we can do the simultaneous translation , how differently we can do to make simultaneous translation better are being studied .
So first of all , I 'd like to explain the process of developing database of simultaneous translation .
Native speaker Japanese speaking Japanese or English speaking person speaking English . That is recorded and simultaneous translator translate from Japanese to English and vice versa , and voice will be recorded .
And listening to the recording , we will write them out and thinking about what kind of information may be necessary for the data analysis process . We will add some more information .
Let me give you example , this is the words in writing , and this is the word by translators hello , is that a Hilton hotel ? . That is the situation that when somebody is making a reservation at Hilton hotel .
And the red shows when the speech starts and when the speech ends . And you can see some other symbols on this chart .
But by different pieces of information we write down what is spoken . By looking at these written data we can see how translators doing their work .
And we analyze how they do it . First of all , then I 'd like to give you some examples of techniques which are stored in the database .
Sofuto uea kougaku to iu mono wa jikkentekina bunya da , that is a Japanese sentence. And this is a translation into English , The software engineering is the experimental field . And actually , it went on and the speaker says to iu iikata mo dekiru deshou .
And if that is the case the English translation is not appropriate for the Japanese sentence , with that addition and how to cope with that . One of the simplest solution for that is , , saying it again as this translation is not very appropriate for the original .
Therefore , the translation will be redone to modify the meaning of the translation , but if that is the case , you have to say some additional words which is somewhat a wasteful .
But actually simultaneous translator continue to say , You may be able to say that way . By combining these two sentences , it 'll be the meaning of the original Japanese sentence .
By taking this method , translator does n't have to reword the translation and does not have to repeat translation over again . For the computer simultaneous translation we need to teach computer the technique of simultaneous translators .
In order to explored the technique of simultaneous translator , we developed a database .
And actually we gave you one of the examples of the technique of a simultaneous translator . And we 'd like to continue this kind of analysis into the future .
Thank you very much .
Now I 'd like to talk about the simultaneous machine interpretation .
The effort to make computer translate languages has a long history and which is called machine translation .
The basis of this machine translation is a text translation . This is spoken language to study the written language .
On the other hand , spoken language translation has been studied . This is a study to translate spoken language .
And we are trying to do simultaneous interpretation by a computer . In this case and this is translation spoken language translation .
In the case of spoken language translation , the spoken language will be translated sentence by sentence . That means , if a person speaks and the sentence is concluded the sentence will be started to be translated .
To this simultaneous translation has a characteristic that input and the translation will be implemented at the same time . But simultaneous translation has some difficulties .
One of them is the interpreter have to start translation before they understand a whole sentence . That means before a speaker conclude the sentence , the interpreter have to start translation .
And the second point is that some languages which are very different in word order. For example between Japanese and French or Japanese and English . The translation between the language which is widely different in word order is really hard .
And the interpreter have to keep up with the speed of the speaker .
All these are difficult point in implementing simultaneous translation . But actually simultaneous interpreters are doing this interpretation actually .
First , interpreter is making a guess according to a situation in a context about the direction of the speech . And they are doing flexible translation so that they can the new information handle the situation in which a new information will be added to at the end of the sentence .
If there is unnecessary information , the interpreter would n't translate it . In this way , simultaneous interpreters are using a variety of techniques to implement simultaneous interpretation .
Considering this , it 's necessary to teach these techniques to computer , if we try to achieve simultaneous translation by computer . To teach these techniques to computer , we have to analyze the technique and study the technique of simultaneous interpreters .
So , we are developing or accumulating the simultaneous database . This is accumulation of translation example by simultaneous interpreters .
And by analyzing these databases we are analyzing their techniques . And by repeating this process , we are studying how a good translation will be achieved and what technique is necessary to achieve that .
Now I 'd like to explain about the process of making database .
The first stage is the recording . In this stage , we record the spoken language by native speaker or like Japanese speaks Japanese or American speaks English .
And in the stage , we record the simultaneous translation , too . And at the next stage , we 'll dictate the recorded speech to analyze this information .
We in the process of analysis we add necessary information . This is the example of the dictated data .
The top square contains speaker 's speech . The speaker is trying to make a reservation at a hotel .
He is telling moshimoshi Hilton san desuka . And the bottom square displays the speech translated by interpreter .
And there are another information including the time added to this examples . And by analyzing these data , we try to find out the technique translator is using in translation .
Now I 'd like to explain about a actual technique used by the interpreters . This is a Japanese sentence and it means the software engineering is the experimental field .
But actually , the Japanese speaker added a new information to iu iikata mo dekiru deshou which means you may be able to say that way . So , the original translation is not appropriate .
One simple answer might be to rephrase the whole sentence from the beginning . Because the original sentence is not adequate one , so interpreter might rephrase whole the sentence from the beginning .
But in this case interpreter have to repeat unnecessary phrases again . In the actual case the interpreter just added a sentence you may be able to say that way .
And combine the initial sentence and this added sentence , the translation of the Japanese sentence was achieved . And this avoid the rephrasing the sentence from the beginning .
So in conclusion , to achieve the simultaneous interpretation by computer , it is necessary to teach techniques used by simultaneous interpreters to to computer . To study this technique , we are making a database .
And we are studying the actual example and I showed one of them to you . Now , and we 'd like continue this analysis .
Thank you very much .
Today , I would like to talk about the design of a multi domain conversational system .
First , the background . Recently , we 're seeing studies of conversational systems being done very actively .
And thanks to these , regarding practical systems that respond to specific task domains , we are starting to see some practical systems .
Examples of these are , first of all , Jupiter . This is a system that uses the telephone , it 's a conversational system and gives you weather information .
Others are TOSBURG-2 . This is another system . And this system is used at first food stores and in place of employees . It takes orders , hamburger orders .
And lastly , there is the Sync Mail system . And this is being done at our research lab . And this mail takes Japanese spoken language , understands it , and it helps you do e-mail management .
So , , , no , each system can only handle one task domain each . For example , with Jupiter , it can only handle weather information , with TOSBURG , it can only take hamburger orders .
And Sync Mail can only do e-mail management . So , one system is unable to handle a multiple number of task domains .
And regarding the handling of a multiple number of task domains , with the type of systems that I just explained , there 're problems . For example , with conversational systems within a car , I 'd like to take that as an example , inside of the car , the conversational systems would be like car navigation systems , car audios , the air conditioner being used at the same time using voice .
So , if you take the current conversational systems and you want to operate the car navigation , car air condition , car audio , then you need one microphone for the car navigation , one microphone for the air conditioner , and one microphone for the car audio . That 's going to be the situation . So , the number of task domains decides the number of microphones or the audio input . That 's the problem .
So , in order to try to do something about the situation , we have been trying to study one audio input to handle various domains . Can we not come up with the conversational system that can handle multiple domains ?
This kind of system as is called a multi domain conversational system , that 's what we call this . So , first of all , a multi domain system , what 's sort of characteristics does it has to have ?
That 's all we 've given thought to . And the results , or the conclusion that we 've reached , the characteristics that are necessary . We came up with the following conclusions , the following three conditions , or characteristics are necessary .
And regarding each , I would like to give you an explanation . First of all , expandability .
To explain what expandability means , a multi domains system needs to be able to be expandable into a multiple number of domains And also new task domains need to be easily added . This needs to be possible .
Next , scalability .
So , expandability , which means several domains need to be able to be added . That 's good . But if you add too many domains , the system itself , its processing speed may drop and that will be a problem .
So , even if it handles a large number of domains , it 's still needs to be able to do its processing at an appropriate speed . That is scalability .
There 's an expandability , there 's a scalability , even if the system fulfils the above two conditions , for the user , it needs to be easy to use . So , even when handling a specific domain , it needs to be able to be used as it is handling only one domain .
And we talked about these three characteristics , in order to fulfill these , how should the multi domain system be designed . That 's what we next gave thought to . And this is the structure or design policy that we came up with .
So , first of all , a multi domain conversational system , this should be an independent single domain , or this should be a collection of conversational system that can process independent single domains . And under this way of thinking , we need to be able to combine conversational system that process single domains to build a multi domain conversational system .
Under this policy , the addition or removal of conversational systems becomes easy , which means this leads to expandability . That 's the first condition that we talked about earlier on .
And also , if the system is able to separate out the input conversation into the appropriate systems , this leads to usability . And if we can build the system in a hierarchical way , then this is going to provide scalability .
So , this is the architecture that we wish to propose . A multi domain conversational system , how should we build this , design this ?
First of all , the manager , and work module . This is how it needs to be at system needs to be built hierarchically .
And the data that goes into here , it 's called fragments . The input fragments and out put fragments , these are going to flow with in the interior of the system and make it function .
And the work module and the manager , regarding these , I 'd like to give you more explanations . The manager takes the input fragment , I 'll explain about this later , and it allocates this to work modules . And the output fragments from the work modules are integrated and controlled by the manager .
And a work module is something that processes that 's the processing for each domain . So , I 'd give you the example of car earlier on , it will handle the car navigation , this one module for that . And there will be one work module that is handling the air conditioner and so on .
At this chart shows the architecture that I proposed earlier on and it 's a simple system example . To give you a brief explanation , there 's the manager in the center here , and this manager will control to work modules that are its function .
So , to explain the movements briefly , there is the voice recognition engine . The manager will get the data there in the form of input fragments and it will give this out of work modules .
And each of the work modules are independent . And will independently analyze the inputs and results of the analysis will be sent back to the manager .
And the manager , regarding these two work modules , will take the output fragments and the results through gets from the work modules and decide which work module is going to allocate the task to and give the commands . And that 's how the system functions .
So to summarize , a multi domain conversational system 's architecture , we have made a proposal regarding this .
And issues to the future are we 've just proposed the architecture , so , we need to implement a system based on this architecture . And we also need to evaluate this system .
That 's end of my presentation .
Today we would like to talk about the design of a framework for the multi-domain conversational systems .
First of all , let me start with background explanation . In Recent years , the conversational system has been actively researched .
As a result , we came up with some fruitful result . To the specific task domain , practical system has been realized already .
Let me quote those examples . First of all , Jupiter .
In this system of Jupiter , phoned conversational system is incorporated so people can get the weather climate information .
Other examples are , for example , TOSBURG-2 . In this system , on behalf of the store staff of the fast food , for example , this system can take orders from the customers for hamburgers , for example .
And the last example , the Sync Mail . In our research laboratory we have been doing the research and this mail system can understand the spoken language of Japanese so this system can manage the e-mail in the system .
So all these examples of the conversational systems can deal with only one task domain .
For example , in the case of Jupiter , only the weather climate information alone , and in the TOSBURG-2 , taking orders of the hamburger , and the Sync Mail can manage only e-mail .
Therefore , in one system the multiple-task domains can not be managed .
Now , one other problem to handle the multiple-task domains In the previous example , as I said there is a limit of the problem . For example , this is the conversational system inside an automobile. Let 's think about this example .
Inside a car , probably car navigation or car audio or air conditioning all those can be handled by the voice conversation .
That 's a possibility . But in the today 's system , if we are to realize these three systems to be incorporated into one , one microphone to car navigation , and microphone to car air conditioning , and again , one microphone to car audio function so these will be the situation . So the voice input required with the number of that task domains . That means that the very complicated situation for user 's perspective .
Therefore , how can we overcome this barrier ? We , in our research group , wanted to develop the system which can deal with the multi-domains by having only one voice input .
And we call it multi -domain conversational system . That 's what we call for this new system .
Now , what are the requirements of the characteristics to be attained by the multi-domain system ?
Let us think of these requirements first . And conclusion in our group will be as follows . What are the characteristics for the multi-domain system to have . As you can see , these three conditions should be met .
That 's how we came up with the thought. Let me explain on each of the feature . First of all , extendibility .
Extendibility , let me explain what it means . In the multi-domain system there are several domains . So system should be extended into several domains .
And if we have a new task domain required , it should be easily added . That 's better to have this function .
Next one is scalability . We have the extendibility , then we can easily add the new domains in several numbers. That 's a happy news. However , if we have add too much new domains , process speed might be getting much slower .
That 's the problem . Therefore , even with the case of dealing with the many domains , reasonable speed of the process should be guaranteed. So that 's the scalability .
Extendibility given , scalability met , but even with these two requirements met , user-friendliness should be required . Therefore , even if the user can deal with a specific domain , from the user 's point of view , it looks as if users are always handling just one single domain .
So these are the three requirements . I know that to meet these requirements how should we design a framework for multi-domain conversational system ? So , this is the design policy we came up with .
First of all , what was the concept ? This is the multi-domain conversational system . I think this is the collection of the conversational systems which process the single domains which is independent .
Therefore , conversational system which can deal with and process the single domain should be assembled together so that we can build up the multi-domain conversational system .
Having this method then , it 's easy to add or delete the conversational systems . Therefore it 's easy that means extendibility , the first condition of the previous three , will be met .
And also , the input conversation can be distributed to the appropriate system . Then user-friendliness , or usability , will be attained .
And a system should be designed in a hierarchy way . Then , scalability will be achieved .
Now , what is our proposal on the architecture ? Let us explain on our proposal .
Our framework for the multi-domain conversational system how should we build it up ? First of all , manager and work module . Those are the components and in hierarchy manner we will build the system .
And within this system the data will flow , we use the word fragment , there are two , input fragments and output fragments , these two fragments will flow inside the system so that system can operate work module and manager .
For these two , let me explain more . First of all , as to the manager , this is the device to distribute the input fragment to work module . And also it will integrate the output fragment from each work module. So that 's the manager 's function .
And what 's the work module ? , each work module will do the process of each domain . Therefore , in the example of the automobile , car navigation will be handled by one work module , and the car air conditioner will be done by the work module of that purpose , for example . So those are the function of the work module for each domain .
This picture is the schematic picture based on the architecture that we proposed , so this is very simple .
Let me explain on this simple system . Manager here in central position , there is one manager , this manager will manage the two work modules respectively . Let me explain the flow briefly .
From the speech recognition engine , then the input will be received by manager , and then , in a form of the input fragment it will be distributed to the work module . And each work module are independently analyzing the input and result will be sent back to the manager in the flow of the output fragments .
Therefore , the manager will receive the output fragments from two work modules . Then manager will decide to which work module the task should be given . The judgment will be made and the system will start to run .
Now let me summarize report . This time we made a report for the architecture for the multi-domain conversational system .
Now future challenges are as follows . We proposed architecture. Therefore based on the architecture we want to do the implementation .
Or the implemented system should be verified or the function should be evaluated. Thank you for listening .
Today , I would like to make a presentation of a framework for multi-domain conversational systems .
First of all , I would like to talk about the background of this development . In these years , various kinds of development for conversational systems have been carried out .
And thanks to the result , for the specific task domain practical system has been realized . The example of this is Jupiter .
The Jupiter system is the conversational system by telephone . And this system gives the metrological information .
And other example is TOSBURG-2 . In this system , instead of the employee staff of the fast-food restaurants , this system received a order from the customer of the order of the hamburgers .
The last example is Sync Mail . And this Sync Mail has been developed in a laboratory . This system understands the speech of Japanese and controls the e-mails .
So , this is one of the examples of the conversational systems . These conversational systems can respond to one task domain .
For example , Jupiter can only deal with the metrological information , and the TOSBURG-2 can deal with the taking order of hamburger , and Sync Mail deals with the e-mail control .
And they can not deal with the multiple numbers of task domains . There are some problems in dealing with several numbers of task domains . Those systems mentioned before have several problems . One example is the conversational system in a vehicle .
In a vehicle , there are several conversational systems like car navigation system , car audio system and air conditioner system . Those are dealt with speech at the same time .
Under the current conversational system and when the car navigation , car air conditioner and car audio are installed , microphone is needed for car navigation system and another microphone is needed for car air conditioner and another one is needed for car audio . So , the number of microphone responses to the number of task domains . It means that it is cumbersome to the users .
Therefore , in order to solve these situations , we developed the system to deal with multiple domains with one single conversational system .
We call this system as multi-domain conversational systems . We first thought that the idea of characteristics of this multi-domain systems .
These are the results of our thinking as for the idea of characteristics of these multi-domain systems . First , these three characteristics should be held by multi-domain systems .
First is the expandability . The meaning of expandability is as follows . This system should be expanded to several numbers of domains .
And also , the new domain should be added with quite ease . Next characteristics is scalability .
With expandability , several domains can be added . However , if we put too much domains , the processing speed of a system , as a whole , will fall . That will create another problem .
Therefore , in dealing with multi -domains , it 's better for us to process at an appropriate speed .
After expandability and scalability are fulfilled , the most important feature for user is that the system is quite friendly to use . So , in dealing with a specific domain , the user should fill that they are just dealing with a single domain .
These characteristics should be fulfilled . And in order to do this , how should we make a framework of multi-domain system . These are the frameworks of developing this system .
Multi-domain conversational systems are a collection of conversational systems to deal with independent single domain . On this premise , we try to combine the several conversational system to deal with single domain and construct multi-domain conversational systems .
If we can do that , adding and deletion of conversational system can be easily done . That leads to the increased expandability and we can fulfill the expandability .
And voice data can be if we can divide input data in an appropriate way , we can have a better usability . And if we can construct the system in a multi layer type , the scalability is expected to be increased .
And next I would like talk about the architecture which we are proposing in this time . How to construct the multi-domain conversational systems .
First , manager and work module should formulate this system in a multi layer type . And the data which are running in the system should be divided into input fragment and output fragment .
And these two fragments operate the system . And there is a manager and work module and I 'd like to evaluate these systems . Manager is to allocate the input fragment into work module and also to integrate ; integrate the output fragment from work module .
And for work module , this deals with each domain . I mentioned example of a vehicle. For example , there is a work module to deal with car navigation system and another work module to deal with car air conditioning .
This chart is based upon the architecture which I have mentioned before .
I would like to explain about the system . Manager is in the middle of this chart .
And manager controls to work modules Simply put , manager receives the data from speech recognition engine and sends to speech synthesizer . And work modules are independent and they analyze the data independently and the analyzed data are sent back to managers .
And managers receive data from work modules and decide are what module should operate . Then , the system , as a whole , works .
This time , I have proposed the architecture for the multi-domain conversational systems . I have proposed the architecture , and based upon this architecture we would like to implement .
And also we would like to evaluate the system . That 's the end of my presentation .
Today , I 'd like to give a presentation under the title of a framework for multi-domain conversation systems .
First of all , background . In recent years , conversation systems have been widely studied .
As the result , for particular task domains , practical system has been developed .
Among the examples , the first , Jupiter . This system is a telephone conversation system which gives information about weather .
Among others , TOSBURG-2 . This system replaces the clerk at the fast -food store and receives orders of hamburgers .
Finally , Sync Mail . We are making study of it . This system e-mail management by comprehending the Japanese language .
These are conversation systems . And this case , one system can not process more than one task domain .
Jupiter only deals with weather information. TOSBURG-2 only deals with receive receive orders of hamburgers. And Sync Mail only deals with electric mail .
Then , if one wants to processor more than one task domains , there would be a problem . For example , please think of a conversation system in a car .
For example , global positioning system , audio system , air conditioning systems will be processed in a car simultaneously .
However , if the conversational system is used in this case , global positioning system must have one microphone , car audio system has one microphone , and air conditioning system has one microphone . Therefore , if there are three task domains , there must be three inputs . Therefore , it is very cumbersome for the users .
Therefore , we propose solutions to this . For example , one input domain various domains .
And we call this system , multi-domain conversation systems . Let me explain about the characteristics the multi-domain system should possess .
Our conclusions are . First of all , this system has three conditions .
First , expandability . Multi-domain system can be expanded to several domains .
And it can add new domain easily . Next , scalability .
Expandability to ensure adding several domains . But , with many domains , system works very slow . That will be a problem .
Therefore , when processing main domains , it must process them at appropriate speed .
It 's called scalability . Finally , usability . If the expandability , scalability are available , it must be user friendly .
Therefore , when using a particular domain , it must use it as if it were single domain .
It 's desirable . Three conditions , we came up the policies of the designing system .
First , multi-domain conversation system must be in an assembly of independent , single domain systems , order conversation system to deal with independent , single domain . And we came up with the way to construct to do that .
As the result , it will be easy to add and delete conversation system . The expandability will be satisfied in this case .
Then , input will be distributed into appropriate system . Then , usability will be satisfied .
Then , the system will be constructed with multiple layers . Then , the scalability will be realized .
Then , let 's me explain about the architecture we propose . How to construct designing system .
Manager and work module to construct .
We construct them with multi layer . And in put fragment and output fragment flow inside the system .
Then , let 's me explain about manager and work module in more details . Manager , I 'll talk about it later . Distribute input fragment into work module .
Work module processes each domain . Let 's me take an example of a car . Car navigation has a work module . Car air conditioning has a work module .
That 's the example . This is a chart based on the architecture we proposed .
Let 's me explain about that. First , this is manager that is located in the center . This manager manages each work module controls .
Speech recognition engines send the results to the manager . And the manager distributes the work modules , two of them .
And each work module individually analyzes the results and sends back the results to the manager .
And the manager based on the results from the two work modules and determines which work module should work on it . Then , the system itself works , as a whole , works .
We proposed architecture of the multi-domain conversation systems and there are problems to be solved . We propose architecture .
Therefore , we construct the system based on that . And we will implement evaluation of it as well .
Today , I would like to talk about a method for incremental dependency analysis for Japanese .
Recently , we have been seeing spoken language being used . For a real time conversational processing system , there is a big demand for this .
And because this is spoken language , as much as possible , in response to the input , the output needs to come as quick as possible . So , a real time conversational system is what 's desired .
Out of this , real time , in order to bring this about the natural language , an incremental interpretation of this , this kind of method is necessary .
This means that as the words are input , the input parts of the sentence need to be interpreted . For example , in the store , I met his friend . In response to this kind of sentence , first of all , in the store or at the store , that phrase or unit comes in , then regarding this part , this system does an interpretation . And this is followed by his , this comes in , as in input , and between at the store and his , the input is interpreted .
Regarding Japanese and interpretation Japanese dependency interpretation is often used . As you can see in this chart , each part , At the store , I met his friend , regarding each of these phrasal units , the dependency relationship between each phrase is decided. That 's how interpretation is done .
For example , at the store , his friend , I met if you take the sentence , at the store I met his friend , his modifies friend and friend , modifies met .
So , there 're two phrasal units here . Each of them modify or are modified by each other . This is the relationship . Regarding this sentence , that is how the structure is determined .
Why is this sort of analysis being used ? To explain the reason is , a characteristic of Japanese is , regarding the order of words , there are not very strict restrictions .
For example , this part that says at that store and this part that says his friend , these two parts , can be interchanged . Even if the order changes , the whole sentence still means the same thing .
And in Japanese , compared to English , what 's different is , the subject is often omitted .
For example , with this example here , you should really have the subject I , I met his friend at the store , but here , people assume that you understand that you 're talking about yourself . So , I does not really exist , so the Japanese says met his friends at the store .
So , sorry . Regarding the dependency relationship and the analysis , you look at the dependency relationship between two phrasal units and decide . That is the objective of the analysis .
However , in this case , with the dependency analysis , regarding the dependent , the unit awaits the input off the head , to give you the former example , oh , sorry , a certain phrasal unit will modify the last phrasal unit in that example .
So , unit awaits for the input of the last part of the sentence , which means that if this is to be a real time processing system , then , unfortunately , the incrementality , this condition is not satisfied . So , this time , what we are doing is , we 're thinking of an incremental dependency analysis for Japanese. That 's what we are suggesting .
What this does is , regarding the dependency analysis for an input , even when the head still does not exist , the head , we make an assumption about this and we use the assumed phrasal unit to create a dependency relationship . So , I 'd like to explain about the dependency structure .
The dependency structure is created from what 's called the dependency grammar .
And this considers the probability of the dependency between two phrasal units and also there 're limitations to this dependency structure . These are the three limitations . The first is , regarding dependency , there 's no intersection .
In other words , dependency relationships should not intersect each other .
The second limitation is the head is unique . In other words , for one phrase , one head , and only one head needs to exist .
And lastly , the dependency modifies the latter part of the sentence. In the case of the Japanese , you modify from the front to the back . You consider only that relationship in the case of Japanese .
So these are the three limitations . And we need to fulfill those three limitations in creating dependency structure .
And here , I would like to look at incremental dependency analysis and give you an outline . And incremental dependency analysis , so this means that regarding an input dependent , the head has still not been input and it still needs to look for a dependency relationship .
So therefore , the dependency grammar is used to try to make an assumption about the category of the head . And , , the assumed phrasal unit is used to look at the input up to there , and create the dependency structure .
For example , at the store this phrasal unit , let 's say this is followed by a book , so , both at the store and a book , both of these are probably modify a verb . And they probably modify the same verb . Once that information comes in , then , at the store and a book , these two modify the same verb. You can set up the structure to make it that way .
This sort of structure , the creation of such a structure , by doing this , these two phrasal units , even before the head is input for these two phrasal units , regarding these two phrasal units , we can create a dependency structure . And because of this , even before everything is input , we can still to a certain extent , create the structure of the sentence .
So to summarize , this time , we 've looked at the incremental dependency analysis for Japanese , and proposed a method for this . I explained about this method .
And what we do is we use dependency structures and we use an assumed phrasal unit . We use the grammar to assume a phrasal unit and create a dependency structure .
And using this assumed phrasal structure to create the dependency structure , by doing this , we can we do n't have to wait for the head to be input . We can create the dependent structure even before the head has been input .
This method will be on Unix to work stations . We 'll be using GNU common list to implement .
That 's what we 've been doing .
Today we would like to make a report on a method of incremental dependency analysis for Japanese . In recent years , using the spoken language of the Japanese is to be used for the real-time dialogue system .
Especially , since this is the spoken language of natural way of speaking , therefore , as words are inputted , then the output should be immediately made , so therefore real-time is the very important requirement . So this factor of real-time process , this is request to be realized , then what is required is the incremental interpretation of the natural spoken language .
For example , at store , I met with his friend . If there 's this kind of Japanese sentence , then at store comes first in Japanese. That 's the phrasal unit . At store then , analysis should be done first and then his comes as a second input . Then , at store and also his those inputs should be interpreted by the system .
Now For Japanese analysis , we have to have the specific factor . That is the Japanese dependency analysis .
As you can see here in Japanese a grammatical structure , at store , his friend , met so these are the each phrasal units of Japanese . But in Japanese language interpretation , we have to determine the dependency relationship between the prologue numbers of the phrasal units. For example , at store , his friends , I met That means I met his friend at store , and it means that at store , that should have the head of the I met and the his should go towards friend , and then friend , that is the object of I met .
So these phrasal units have the relationship of the modification , or being modified so there is a dependency relationship .
And determining the relationship of the phrasal units dependency , then , we can have the correct interpretation. Why is it really necessary ? Because in the Japanese language , we have very loose constraint for the order of the words .
At store or his friends actually There are two modifying phrasal units , but we can reverse these orders and still we have the same interpretation . Different from English language , quite often in Japanese we can have the missing subject .
For example , in the truly strict manner , I met should be the case . But in this sentence , already the subject of I is obvious to everybody . Therefore I is now eliminated in the sentence .
Therefore , excuse me So dependency analysis is required as I mentioned before if there are two phrasal units , what are the dependency relationship should be determined in the analysis. That 's the main objective of this analysis .
But in this case , in this dependency analysis for the phrasal units , the head which receives the dependency phrase should be waited for the units of the input .
That means that there is one particular phrasal unit , but that is actually modifying the last phrasal unit , then the interpretation should wait for the last phrasal unit which is ahead . Then , in order to realize a real-time dialogue system , the feature of the incremental interpretation can not be achieved .
Therefore , what we are proposing today is the Japanese language dependency analysis method in incremental manner . That means that there are certain input of the phrasal units of the dependency , and then even though there is no head appeared , there is a presumption of the head of the phrasal units. So therefore , in advance , the dependence relationship will be built up .
Now let me explain about the dependency structure . There is a dependency grammar , that 's the basis , so if there are two phrasal units , the possibility of the dependency between depending words and heads will be interpreted .
And there are some constraints . There are three . One is the non-crossability of the dependency relationship .
That means that these heads and depending phrase should not be crossed over . And always the head is the single , therefore always there are requirement of having one single head to receive the depending phrasal units .
And the last one is the head can be appearing much after the dependent phrase . That means that if we look at the dependency relationship , the head might appear much later .
So these are the constraints or the conditions specific for Japanese language . Therefore , based on these conditions , we have to build the system of the incremental dependency analysis for Japanese. Let me explain with this schematic picture .
Incremental dependency analysis is on still waiting for the actual category which should be the head .
So therefore , dependency grammar will be used . So there is a presumption or assumption of the category of the possible head . So the structure should be presumed first . Based on this assumed structure , up to the input made so far , dependency relationship should be simulated .
For example , at store comes first , and then book comes second , and then the at store should be the dependent phrasal unit to the verb , and the book will have the verb later . Then , as shown on the right , at store and book , those are the dependent phrases or phrasal units which have the head as a verb in the end .
Therefore , for these two phrasal units , the head comes later . But before having that input , already the dependency relationship for at store and book will be simulated or assumed. Therefore , before waiting for the final head appearing as input , we can assume the structure of the dependency .
This time we proposed the method of incremental dependency analysis for Japanese . That means that we will use the assumption of the phrasal units relationship to analyze the dependency structure .
Therefore , this method will lead us to the earlier interpretation of the dependency structure before determining what head comes at last . Therefore this method will be used in a GNU common list on the work stations , so implementation was realized .
Thank you .
Today , I would like to talk about a method of incremental dependency analysis for Japanese . In recent years , by using this spoken language of Japanese , dialogue process system is expected to be created .
And this demand is increasing . It 's a spoken language , so the in put should be dealt with spontaneously .
And that 's the idea or situation that users are looking for . In order to achieve this spontaneous reaction , analysis of natural language is needed .
For example , at the shop , his , I met his friend . First , the phrase at the shop comes . And after that , responding to this phrase analysis is done . And next , the phrase his comes .
For the analysis of Japanese , there is a dependency analysis of Japanese is widely used .
As this chart shows , each phrase , for example at the shop his friend met for each phrase , dependency relations are decided For example , at the shop his friends met at the shop is depended upon the phrase met and the phrase his responds to the phrase the friends , and the phrase friend relates to the phrase the met .
So , each phrase is in a relation like modifier and modified . And the structure for each phrase and dependency relations are decided .
This kind of analysis is used because of the characteristics of Japanese . In Japanese , restriction for word order is relatively loose .
For example , if exchange the phrase of at the shop and his , the meaning of the whole sentences is same . And also , for Japanese , sometimes , subject is omitted .
For example , by using this example , in the sentence I should be included .
However , I is omitted because I is understood by the speaker and the receiver of the speech for Japanese . Dependency analysis is to decide the dependency relations between two phrases .
And this is the purpose of this analysis method . In this case , in this dependency relation , the head phrase input should be waited .
For example , one phrase is dependent upon the last phrase . In this case , we had to wait for the input of the last phrase of the sentence . Under this these circumstances incrementality of speech or dialogue can not be fulfilled .
Therefore , this time , we have proposed the incremental dependency analysis method for Japanese . This is is to assume the head phrase , even though there is no head phrase appears , and to make the dependency structure .
First of all , I would like to talk about dependency structure .
Dependency structure is formed by dependency grammar . That means the possibility of dependency relations between two phrases .
There are three restrictions . First is the unclosing nature of dependency. This means that dependent should not be closed .
The second is that head part should be only one . This means that one dependent needs one head phrase .
The last one is the later modification of the dependent . In case of Japanese , dependency relations from the former phrase to the last phrase should be considered .
And dependency structure should be in structure to fulfill . So , these restrictions should be constructed .
And I would like to talk about now about incremental dependency analysis . For input dependent analysis should be carried out even though the head phrase does not appear .
For this purpose , dependency grammar should be utilized in order to assume the head phrase and the category of the head phrase . And by using the assumed phrase , the previously input data should be analyzed .
For example , this phrase at the shop and this one is book . And both of these are dependent upon the verb , the same verb . If we can get this kind of information as the right picture shows , at the shop and book these two phrases are dependent upon the same verb .
And we can formulate this structure . By making this kind of formulation , we can construct the dependency relations even though the head phrase appears . Before the whole data is input , we can assume the whole structure of a whole sentence .
Lastly , I would like to make a summary of my presentation .
This time , I have talked about the proposal of incremental dependency analysis for Japanese . This method is to use the assumed phrase and to formulate the dependency structure .
By using this assumed phrase , the dependency structure should be formed . By doing this analysis , even before the head phrase appears , we can create the dependency structure .
We are now using the Unix workstation , GNU Common Lips , to implement . And thank you very much .
Today , I 'd like to give a presentation under the title of a method of incremental dependency analysis for Japanese . In recent years , there is a growing demand for the dialogue system using a spoken language .
Among them , quickest response to the user 's input is expected , which means real-time dialogue system .
To realize real-time , incremental interpretation of a natural language is needed , in which the system interprets input sentences when a group of words appears . For example , at the store , his , his friend , I met . First , the system interprets the group of at the store and his .
Then , explain about dependency analysis for Japanese .
The dependency analysis is widely used for this purpose as shown in this chart . At the store , I met , his friend . And the system determines the dependency relationship to phrasal units .
For example , at the store modifies met .
And his modifies friend . And friend modifies met .
Therefore , each two phrasal unit serves as a modifier and modified .
Why is this kind of analysis helpful ? Because in Japanese , word order is very loose .
For example , exchange at the store and his in Japanese the sentence means the same thing . And in Japanese , subject words are often submitted unlike English .
For example , I is actually omitted in this sentence . However , everyone , Japanese speakers assumed that I is omitted .
Therefore , it is omitted . The next purpose as I said earlier about the dependency relationship , it it determines the relationship between the two phrasal verbs .
However , in this case , in this system , the system has to wait until head phrasal unit is input .
Modified Modified words are input . Therefore , real-time dialogue system or the incrementality is needed .
Therefore , we propose incremental dependency analysis in which , if there is some modified in a Japanese sentence , the system in first dependency relationships , in first relationships . Then , let 's me explain about dependency structure .
It is based on the dependency grammar . It expose the possibility of dependency of the two phrasal units .
However , there are some conditions on dependency . First , dependency relationship is one only one , not more than one .
Last , dependent modifies the head appearing afterwards . This is unique characteristic of the Japanese language .
To satisfy the conditions , we can infer the dependency relationship . Then , their let 's me explain their outline of the relation and dependency analysis .
First , we must use the grammar to infer the modified category , group of us . Then , we construct the dependency relationship. For example , at the store then book .
At the store modifies the verb . Book modifies verbs . Therefore , the two groups of words modify verb then verb . Therefore , at the store and book modify the same verb. We assume this this relationship .
Therefore , modified group of words before modified words input , we can assume assume that . We can construct relationship .
Conclusion .
We propose the method of incremental dependency analysis for Japanese . This system way uses grammar based on the presumed , the modified words .
Before the modified words are input , we can the determine the dependency relationship on the Unix workstation . We implemented GNU GNU Common Lisp .
Thank you very much .
Today , a spoken dialog mail tool based on incremental processing and that is the title of my presentation today . In recent years , many people who in the past , have never had the opportunity or much opportunity to use computers like elderly people , children , even such people have more opportunities to use the computer .
So , in such cases , like in the past , mouse a mouse or a keyboard , these conventional input interfaces in addition to these , we need more user-friendly interfaces . That is the situation today .
So under these conditions , because of this situation right now , using spoken language as an input method inputting into computers . That 's research , that 's currently being conducted .
So , spoken language for human beings is one of the most general ways of getting your intent communicated to others . And as an input tool for computers this will make it possible to instinctively get your intent across to the computer .
Conventional research , regarding conventional spoken dialog systems with those someone has to stop speaking and finish speaking before there was a response from the system , and then the system would give us response and after the computer 's response was finished , then the user would start speaking . So this would be the order . The order was very clearly decided . So this is like a transceiver , a transceiver type conversation .
This was the general situation . However , when human beings normally converse , what happens is they do not necessarily wait for the other person to finish speaking . The other person may still be speaking and they would butt in or they would nod , they would agree and that 's how the conversation would proceed .
So , a more easy to use , kind of interface between computers and human beings , that 's what we want to bring about . And in considering this , as I mentioned earlier on , even when someone is still speaking , the computer should be able to respond . That 's the sort of structure that is needed .
So , even while a person is still speaking , the system will respond . That 's what we call incremental processing of spoken language . This is what 's needed .
By bringing this about , even when the contents of what 's being spoken changes in the middle , the amount of time you have to wait for the system to respond is decreased . And this should make it possible to realize smooth conversations . And this should also influence the stress and anxiety that user feels , and decrease this . And this should also improve work efficiency .
So , based on this kind of way of thinking , we have been looking at mail retrieval and a mail tool called sync mail . This is what we have been developing so far .
Sync mail as I mentioned before , is an incremental spoken dialog process toll . So , the input spoken language , once the necessary information is available , it will start the retrieval .
For example , the title could be wedding , and the sender could be Kimura and you could ask the computer to search for that kind of mail . If the user asks this of the computer , the title is wedding . At this stage , once the input has been done up to here , it will do one search .
So the first search is looking for mail that has wedding as the title . And then this exactly will be followed by the sender is Kimura , once the input comes this far , then , the computer system is going to look for Kimura as the sender .
And it 's going to search for that kind of mail . So , in this way , in stages , it will conduct different searches . And for example , even when the user is still speaking , it will continue to narrow down the range , which means that it will be able to retrieve the necessary mail , 0r when the results of the search , if it narrows down to zero , then it can go back and start searching again . And this will improve work efficiency that 's what we look forward to .
So , to be more specific , how does the system respond while the user is still speaking ? The retrieval , what items is the search going to be based on , and what do those items contain ? By combining these two , that 's what retrieval is made up of . So , with the progress of the spoken sentence , if we can do this simultaneously , even when the user is still speaking , we will be able to start the search .
For example , with the title of wedding and the sender of Kimura , please look for this kind of mail and response to that kind of spoken order , once title is input , then the attribute , what is the search going to use as attribute ? So , the computer will be able to tell that we are going to use the attribute the title .
And then , once the user inputs up to wedding , then you 'll be able to tell that the value is going to be wedding and you will be able to fill in the value . And once the attribute and the value , once both of those are fulfilled , once that 's the situation , then the search can start .
And the latter half , the sender being Kimura , regarding that part as well , in the same way , as one and two the same thing will be done for three and four and even in the middle of the process , it will be possible to conduct the search .
So compared to conventional systems , you had to wait all the entry end before the search started . So compare to conventional systems , at an earlier stage the process will start .
So , even during the process , this means that , the user is going to be under less stress . So , by actually using this system , we held an evaluation test , we looked at the work efficiency and evaluated this and the test showed that in a certain set time , you were able to attain a larger number of successful results when responding during the order And regarding ease of use we held a questionnaire survey , we ask people to evaluate this on a scale of one to five and people who tell , told that the system that we proposed responding even during the order with easier to use. That 's for the results .
So , lastly , to summarize , in my presentation , I talked about the user still being in the middle of his order , and the system responding that is the method we are proposing And also evaluation test shows that the proposed method is efficient and effective .
So , our issues for the future are , these are human beings , they 're talking various ways , so we need to be able to respond not just simple orders but to more complicated orders . That 's my presentation .
Today , I would like to talk on a spoken dialogue mailtool based on incremental processing. So this is the title of my talk today .
In recent years , more and more people are using the computers . So far , older people did n't use computers or small children did n't use computers in the past , but in recent years , for those older people or the smaller children , there is an increase of the users of computer .
Then mouse and for keyboard , those interface should have the requirement to become more user-friendly .
This is the current situation . Under such circumstances , I am speaking spoken dialogue . Therefore , if we can use just a casual spoken dialogue as an input means for the computer , that would be very much user-friendly. Therefore , those research activities have been commenced .
Because the spoken dialogue is the very very general means of the communication to other partners for human beings , and also as an input for the computer , it is possible to operate the computers intuitively . That is easier way to convey the message .
So therefore , lets look at the conventional conversational dialogue system . Usually the computer should wait up until the conclusion of the spoken dialogue . And then , some response will be made from the system . And then , if system response given , and then again user are requested to speak .
So always there is a sort of the computer type of the clear-cut , in-series communication . But this is between machine and human beings . If we imagine the human beings ' dialogue , people do n't necessary have to wait up until the conclusion of the spoken language of the other partners . They can respond in the middle of the sentence , they can nod , and affirming the agreement to the speakers .
So therefore , for the sake of increasing the user-friendliness and familiarity , maybe we can research the better- spoken dialogue interface system between human beings and machine . If we think on that possibility as I said before , even while in the process of the spoken language of the people , system should be capable of sending some response .
Therefore , even in the middle of the spoken dialogue , system should respond . What we call the incremental processing of the spoken dialogue . That 's the title that we named. So this kind of system is required .
In order to realize this one and if we are successful developing those , then it is possible to change in the middle the contents of the spoken dialogue . And also , we can shorten the response waiting time from the system . Then , much smoother dialogue will be realized , and the stress or anxiety on the side of the user will be reduced , and also the operation efficiency by itself will be enhanced . So those are the possible benefits in our minds .
Therefore , now we named this kind of concept Sync Mail for the mail retrieval task . So this is a mailtool . So as I said before , the title is Sync Mail , and we have been developing this Sync Mail so far .
As I already mentioned , the incremental processing of the spoken dialogue is the basis for this Sync Mail , so spoken dialogue will be the input , and then if the necessary portions are sufficiently given , then at that time , , immediately the retrieval should be started. For example , the input says that with the title of wedding ceremony with the senders of the name of Kimura , please search the mail . The title of wedding and then , the retrieval should start to search for the title which has the wedding ceremony .
So therefore , the retrieval , number one is the task to retrieve the mail , which has the title of the wedding ceremony .
And the next input is that the sender 's name , Kimura . Then the input is coming in , then the next task will be immediately started .
That means that based on the first retrieval , there will be further focusing on the mail which has the name of the sender of Kimura . So therefore , on a stage-by-stage basis , not on series , we can make the sort of the incremental processing . Even in the middle of the spoken language of the users , the response will be started . So some categories of the mails will be shown . And if there is no mail existing for those inputs , then the answer of zero should be popped up. So therefore , efficiency should be very much accelerated .
More specifically speaking , how can we make in the middle process of type of response ? , For which attributes the retrieval should be started and what values are included in the retrieval ? I think that the attributes and the values are the two important components for the retrieval . Therefore , the spoken language will be proceeding words .
So therefore , with the combination with those , the attributes , values , should be determined , and then the retrieval can be started even in the middle of the spoken language . The same example . With the title of wedding ceremony with the name of sender , Kimura , please search those mails . If this is the spoken language or dialogue , then if title , wedding input first , and then with which attributes retrievals should be started ?
So the attributes are title and wedding ceremony. That 's the value. So therefore , if we have this input , then into the value this wedding ceremony will be given . Therefore , we have the two terms filled .
Then , according to this attribute and this value , then retrieval should be implemented .
Now the latter part of the sentence , the sender 's name , Kimura again the same thing like the previous one. So one and two , now three and four will have the repetition one and two . That means that based on the attribute and the value , the retrieval will be implemented .
In the conventional ways , we have to wait up until the last sentence of this example . Then the operation should be started. So therefore , this new method is faster and response will be given even in the middle of the spoken language. Therefore , I think that the human beings ' stress level can be alleviated or reduced .
Now we experimented the feasibility or the evaluation experiments having the twenty four subjects for the efficiency evaluation . In a certain fixed time if there is a response even in the middle of the spoken language , efficiency increased so , as you can see , evaluation was higher . And also the questionnaire was given to the users , which is user-friendly or which did you feel easier to use , and then again the response given even in the middle of the spoken dialogue had the higher scores .
Lastly , this is the summary chart .
In this presentation , we made a proposal for the method that the response can be given even in the middle of the spoken dialogue of the users , and the results of the evaluation of the users confirmed the effectiveness of our proposal .
the , we are currently experimenting with the simple context of the phrase , but human beings usually speak the complex structure. Therefore , another challenge is to challenge the more complicated spoken dialogue .
I would like to make a presentation under the tile of a spoken dialogue mailtool based on incremental processing .
In recent years , more and more people have begun to use computers . Even the people who did not have a chance to use computers like elderly people and children and now have many chances to use computers .
Under these circumstances , the previous equipment like mouse and keyboards , those input interfaces should be renovated to an interface which are more friendly to use for users .
So , and in order to response to this trend , we are going to use the spoken language as an input data for computers .
Spoken dialogue is the most common tool of communication . If we use this to a computer , it may be easier for the users to send his or her own message more easily .
Conventional spoken dialogue method should wait the ending of the one person 's speech . Then , the response from the system comes back . And afterwards , the system operates . And after that , the speaker resumes the dialogue of the speech once again .
However , in the conversation between human beings , it 's not always that the person waits the ending of another person 's speech . Even though the conversation is in the middle , the person interrupts the conversation or makes a speech or makes a nod . Then , the conversation goes on .
Therefore , my friendly to use communication interface between computers and human beings would be realized . For this purpose , computer should respond even though the person is still making a speech .
In the middle of speech , the system makes a respond . We call this as an incremental processing system .
By realizing this , the user can change the contents of speech . And we can reduce the response time from the system . Thanks to these , we can create more smooth conversation or we can reduce the stress or anxiety . It leads to the improvement of the work efficiency of the operation .
With this , theory , we have developed the mailtool to deal with the mail conversational dialogue mailtool . The name is Sync Mail .
Sync Mail is based upon the incremental processing of spoken dialogue . When the necessary information is put in place , retrieval of data starts .
For example , the title is wedding ceremony and the sender is Kimura . Please search this kind of mail . And the title is wedding ceremony . When the data of this part is input , the retrieval starts .
Then , the computer searches for the mail whose title is wedding ceremony . Afterwards , sender is . When the user input this data , the computer responds and starts retrieving the mail whose sender is Kimura .
In the middle of the speech of a user , Even though the speaker is making a speech , the results can be found . Sometimes , the results are disappeared . For that case , the computer makes a retrieval once again from the start . And this results in the increased ratio of the work efficiency .
How to respond the result in the middle of the spoken dialogue is as follows . The retrieval is constructed from two things which which are the attributes and which are values . Along with the progress of s peech , that combination should be decided . If we can do that , the retrieval of data can start .
The last example is to search the mail whose title is wedding ceremony and sender is Kimura . When the data of title is input , its attribute is decided that its attribute is title .
And afterwards , the information of at the wedding ceremony is input . The computer knows that the value part responses to the wedding ceremony .
And if attributes and values are fulfilled , the retrieval starts .
And for the later part , sender is Kimura , the similar process is carried out for three and four of this chart , and the retrieval is carried out . In the conventional type once , when this the speaker makes the direction of the number four part , then the computer starts retrieving .
In this new system , the user can reduce the anxiety because of the shorten time of response .
We made an evaluation evaluation experiment . For the evaluation of work efficiency , we could have a better result for the achievement number . Then , the result was a better for the case that res ponse was made in between in the middle of the speech . And also for the evaluation of the easiness to use , the higher result was gained , for the case that the user can receive the answer in the middle of the speech .
Lastly , I would like to move on to the summary of my presentation .
I have proposed the method to make responses even when the users are speaking . And also , I have made an evaluation experiment and confirm the efficiency of this proposed method .
The future task would be that we should consider the response to the flexible flexible response to the more complicated speech patterns . Thank you very much .
I 'd like to give a presentation under the title of a spoken dialogue mailtool based on incremental processing . In recent years , people who have not many opportunities to use computers like elderly and children are using computers .
Computer users are increasing in number . In this case , interfaces , such as mouse and keyboard are expected to be more familiar with computer users .
Considering the situation , using a spoken language as an input , we are trying to construct as system .
A spoken language is very most common communication method for humans . And it is possible to communicate better , manipulate computer more intuitively this case .
Conventional dialogue spoken dialogue system in this system , the system must wait until the user stops speaking , then , answers back . Therefore , it is a kind of transceiver type dialogue . This has been common .
However , considering a human conversation , one does not necessarily wait until the other is finished . One interrupts the conversation whether or not to keep the conversation going . It 's quite common .
Therefore , more user-friendly and more familiar interface , a tool between the computer and humans in order to realize that , while the user is speaking , system must answer back . And we call this system spoken dialogue on incremental processing .
By realizing these , the user can change the contents of the speech or the time to wait for the system to answer back is reduced . Therefore , this system ensures the smooth dialogue . And that makes users less stressful , less uneasy and efficiency of the work improves .
Based on this concept , we constructed Sync Mail as a mailtool .
Sync Mail is based upon the incremental processing spoken dialogue . Retrieval is implemented as soon as necessary information is input .
For example , the title is wedding ceremony and the sender is looking for Kimura 's e-mail . In this case , the title is wedding . These words are input , then the retrieval is in putted , reduce the number of the e-mail one is looking for .
Then , the sender , Mr. Kimura 's , then the retrieval is im plemented again .
In this way , incrementally the retrieval is implemented . While the user is speaking , a lot of e-mail will be reduced and one can find the e-mail they look for or they can do it again on the way . Therefore , I believe that efficiency improves .
in a concrete manner . Let me explain about how to comprehend the speech . In the case of retrieval , attribute and value consist the retrieval . And as speech continues , if the combination is determined , the retrieval can be implemented on the way .
For example , the title is wedding ceremony . If the title this group of words is input , then attribute , title , it is determined . Then at the wedding ceremony is input .
Then , the value , in the item of value wedding ceremony is input . Therefore , the retrieval will be implemented .
Then the sender , Kimura , in the same way , the same process will be conducted . Then before finishing the sentence , the retrieval will be implemented .
In the conventional way , inputting one sentence , only after inputting one sentence , retrieval will be possible . Therefore , this system I believe that makes users less stressful .
Then now the evaluation . In terms of efficiency work efficiency , in a certain amount of time , when the system answers back before the end of the speech , efficiency improved . And in terms of the user-friendliness , when the system answers back before the end of the speech , three point six out of five , higher score was recorded .
Now , conclusion .
We propose the method of the system to answer back before the user finishes the speech . And by evaluation , we confirm the effectiveness of the method .
And as to the problems to be solved , more complicated dialogue we we have to come up with how to process more complicated dialogue. Thank you very much .
Today , I would like to talk about how the output timing is determined in the incremental parsing . First of all , I would like to briefly describe incremental parsing .
Incremental parsing is the framework to capture syntactic relations in the middle of the input of a sentence .
For example , I saw her aunt in the park is the sentence and after we heard the word of saw , we would capture the syntactic relations that the noun I is the subject of a verb saw .
This framework is used to realize the real time dialogue processing system such as simultaneous translation systems .
In the incremental parsing , it is important to determine output timing because it is not clear when the syntactic relations are determined .
For example , a sentence goes I saw her , we find that word her , her can be an object to the verb saw or her can be a possessive pronoun . So , syntactic relations can not be determined at the time her is input . The possessive pronoun of her can be determined when her is followed by a noun .
For example , if we hear the sentence , I saw her aunt , where aunt follows her , we can eliminate the possibility that her is an object of a verb saw , and here , her is determined as a possessive noun . So the syntactic relations of her is determined only after aunt is output .
It is important to determine output timing in the incremental parsing and I would like to make a proposal on the techniques of the output timing determination . We have to determine output timing in a dynamical manner .
We have to delay the output timing as much as possible . This is one way to determine the output timing .
And within that delay , we have to output as earliest possible . This is the outline of the technique .
We have the incremental parsing and output control . These are the two important parameters .
We can produce syntactical structures based upon the incremental parsing .
And based upon the result of the analysis , we can determine how far the syntactic structure is determined and we will print out the syntactical structure thus determined . We can tell what part of the syntactic relations are determined or definitive and what parts are not .
This is an example . I would like to use an example to detail this process .
There is a sentence I saw her aunt in the park . In this sentence , we see the word her , if we do incremental parsing , her can be an object of the verb saw .
And incremental parsing tries to pick up as many possible syntactic relations possible . So another possibility is that her is the possessive pronouns .
And there is an output control here . And here we do n't know the exact answers to this question .
Then , there is an input of aunt . And when aunt aunt is input in the incremental parsing structures , we can learn that aunt is noun .
And this message is sent to the output control . Her is determined as the object to the verb or her can be determined as a possessive pronouns and her aunt is the object of the sentence .
Thus we can control the output and when the incremental parsing is determined to the fullest extent , we can make an output of translation . This time , we 're trying to propose a technique to determine the output timing in a dynamical manner in the incremental parsing analysis .
And we have mounted the system on the computers and we tested it and we confirmed that the sentence structure can be incrementally output .
That 's all for myself .
The title of my presentation is determining output timing in incremental parsing .
Let me begin with the definition of incremental parsing . Just in brief .
What is incremental parsing ? It is a framework to grasp the syntactic structure of a sentence in half way through the input of a sentence .
For example , here we have a sentence like I saw her aunt in the park . And after the input of word saw , the parsing will start and at that stage , the incremental parsing says that the I , the pronoun is the subject of the verb saw .
That 's a framework . And for what purpose are we going to use such a framework ? It is necessary for the real time dialogue processing system . For example , to develop the simultaneous translation or interpretation systems .
When we consider such an incremental parsing , it is very important to consider the output timing . Because it is not very clear that what at what stage the syntactic relation is determined .
Let 's think about input like this . At this stage , the word her can be the object of the verb saw or her also can be the possessive pronoun , with the following noun afterwards . So we have the number of possibilities .
Therefore at this stage , it ca n't be determined that which syntactic relation it has and then after the word her , if the word aunt follows , then , the her now can not be the object of the word saw , and rather it is a possession and which predicates the word aunt . And after the input of aunt , we can determine the syntactic relations for the first time .
And like this , in the incremental parsing , it is very important to determine the output timing . And now we would like to propose a method to determine it .
What is characteristic with this method . I 'd like to propose is that it is quite dynamic to determine the output timing .
How is it determined ? To determine the syntactic structure , the output timing should be delayed as much as possible or as late as possible .
And in that framework , the input should be provided as early as possible .
And this is the outline of the method I 'd like to propose and now I 'd like to describe this method briefly . First , we we generate the possible syntactic structure with the incremental parsing .
In the incremental parsing , is carried out with the input words . And the syntactic structure of the word input so far would be considered and then the couple of possibilities are generated .
And as the result of the parsing , and that syntactic structure is formed or possibilities of the syntactic structures are formed and that is passed into the output control . And using that information , in the framework of that syntactic structure , what is determined and what is not determined are all judged . And the part in which the syntactic structures are determined is now output .
And let 's consider this process with the example sentence .
For example , in the sentence , when the her is input , the word her goes through the incremental parsing , and with this input , the incremental parsing will input the possible syntactic structures .
One is , the her could be the object of the verb saw , or her also could be the possessive pronoun .
And in the output control , Two possible relations are accepted . And at this stage , it is too premature to make any judgment , which is the appropriate or correct relations .
And next , the at this stage of the input of the word aunt . First of all , the aunt is input to the incremental parsing , Then as the result of the parsing , aunt is understood as a noun and this information is provided into or provided to output control .
And with this information it is now determined that her her is the possessive and it it can no longer be the object ; object of the verb saw and now we know that her is the possessive pronoun , so at the output control , this is output .
Like this , with such a control of the output , syntactic structure is determined and at the stage of the decision , that decided or determined portion could be output .
And in my presentation , I proposed the incremental parsing , and the dynamically determining output with the incremental parsing technique and this is actually mounted on the computer and we tested , we tried it out , and we have confirmed that we can output the syntactic structure incrementally .
Thank you very much .
Determining Output-Timing in Incremental Parsing , this is a subject of my speech today .
First , I will like to give you the explanation about what is a framework of incremental parsing . An incremental parsing is a framework to figure out syntactic relation in course of input of sentences .
For example , as the sample sentence goes I saw her aunt in the park , kouen de obasan wo mikake ta , when the English term , saw is input , incremental parsing is executed . In a way that the noun I is a subject for the English verb saw .
Such a syntactic structure is figured out by this incremental parsing . And why this kind of framework is needed is to realize the real time dialogue processing system , such as the simultaneous interpretation system .
This incremental parsing can be considered from the point of view that the importance of output-timing concerning incremental parsing . It 's because it is not clear that a point syntactic relation is determined .
For example , the input , I saw her is done and at this point there are two possibilities . The one possibility is the word , her is an object of the verb saw . On the other hand , the her is not an object of the verb saw because her is followed by a noun so that term her is a possessive pronoun . So we can not determine at this point that the input of the word , her is done .
And when this sample goes with the word , aunt after her , this aunt is an object of the verb , that was the one of the possibility , but this possibility is gone now . And her is a possessive pronoun . And at this point , it can be determined of that term , aunt for the first time .
In this way , we determine the output-timing using incremental parsing . And now I would like to propose a method to realize this output-timing determination .
The feature of this output- timing determination is that we can determine output-timing dynamically .
And let me explain how it goes . First , in order to determine syntactic structure , we delay output-timing as long as it needs .
And then we output as as early stage as possible , just a framework I made . , sorry , then let me explain an outline of this method .
This method consist ; consists of incremental parsing and output control . There 're two modules in this method .
At the incremental pursing , when the word is input , looking at possible syntactic structure of the word which are earlier input and we , then , analyze it . Then the result of its parsing is transferred to the next stage that is output control .
And this output control using syntactic structure processed by incremental parsing then determine what part is done or what part is not done using syntactic structure . Then , concerning the part , syntactic relation is determined , then the output control outputs that part . That is the function of these two modules .
And let me give you an example .
The previous sentence , which I mentioned earlier , this is the same as the previous one . And the sentence , when I saw her was input , the word , her is input in the incremental parsing module .
Then incremental parsing output the possible syntactic relation . And there 're two possibilities that the word , her is an object of the verb , saw and the other possibility is the word , her is a possessive pronoun .
And these two possibilities are output to the next module . And the output control module , it ca n't decide what the syntactic relations are , so it maintains the word , her .
Then it moves to the next stage that the aunt is input . When the word aunt is input on the incremental parsing module , then the result of the parsing is that the information which is the word , aunt is a noun .
And its result is transferred to the output control . Then the possibility that the word , her is an object of the verb saw is erased .
Then the word , her is a possessive pronoun . Thus it is determined . Then the output control outputs that information .
Thus , by controlling the output this way , when the syntactic structure is determined , it is possible to output those information . This time , I made a proposal on a method of dynamically determining output timing in incremental parsing .
And I installed this software order program on the computer , then I conducted an experiment to confirm incremental output of syntactic structure is possible . This is the end of my speech .
Thank you very much .
Incremental parsing , or determining output-timing in incremental parsing , this is my topic of presentation today .
First of all , what is incremental parsing ? I like to briefly talk about the definition of incremental parsing .
Using incremental parsing , we analyze sentence structure . While sentence is being input , we determine the syntactic relation .
For example , I give you this example sentence I saw her aunt in the park. This is an example sentence . For example , when the word saw is is input , according to incremental parsing , the noun , , is the subject of verb saw .
This is the result determined by incremental parsing .
This is the framework . Why this framework is necessary ? We need this framework for real time dialogue processing system , such as simultaneous interpretation system . We need this type of framework to implement , or to realize real time dialogue processing system , such as simultaneous interpretation .
What 's important for incremental parsing is the output control , or output timing is quite significant for incremental parsing because we do n't know when syntactic relation is determined , or at what stage syntactic relation is determined. For example , I give you this sentence example .
When I saw her was input , there is a possibility that , her is object of verb saw or there is another possibility that her is a possessive pronoun when is followed noun follows her . So , excuse me , at this point we ca n't determine the syntactic relation .
And next , when aunt the word , aunt is input , the possibility of her being the object of verb saw is canceled . So her is determined to be possessive pronoun for aunt . So when aunt is input , structure can be determined .
So very important to determine output timing for incremental parsing . So now allow me to propose methods to determine output timing for incremental parsing .
Today I 'd like to introduce the method with the characteristic of a dynamic determination of output timing . In order to determine syntactic relation , we delay output timing as necessary .
Output is made at an early stage within the range , output is made as early as possible . And then I 'd like to move on the outline of this method .
The method consists of two modules , incremental parsing and output control . For incremental parsing , words are input and syntactic relation can be related .
A possible syntactic relation can be generated according to incremental parsing and the result will be transferred to the control output control . And syntactic structure transferred to output control , we 'll determine which point is determined in terms of syntactic structure .
And the determining portion will be output and that is the framework .
Now I 'd like to give you an example . This is an example , the same example as I gave you previously . For example , for this sentence , the her was input .
Let 's think about the stage when her is entered .
When her is input into the module of incremental parsing and possible syntactic structure will be determined and output . So there there are two possibilities , her being an object of verb saw and her being possessive pronoun for her .
These are two possible syntactic structures . And output control receive those two relations , but at this point it can not determine which one is correct . So output control saves these two information .
And now that at the next stage , aunt is input into incremental parsing . After analyzing that information , information that aunt is a noun can be entered into output control .
So according to this information , her being object of verb saw is cancelled . So as a result her turns out to be possessive pronoun .
So this is how output is controlled and as a result when syntactic structure , or relation is determined , output is made . At this time , I proposed the method to determine output timing dynamically for syntactic analysis .
And this program is packaged onto the computer and we carried out experiment. As the result , the experiment allowed us to confirm a possibility of incremental output of syntactic structure .
Now I want to make presentation on the aligning of sentences in parallel corpora for extraction of translation patterns .
This is the background of the development . Internet has become more popular and more people are on the overseas travel , so there 're more opportunities for people to communicate with people speaking different languages .
And also in the overseas trip , They want to have the simultaneous interpretation with little time lag . And in the conversation , they want to have a simultaneous translation with little time lag .
Now we would like to study and analyze simultaneous interpretation system . In simultaneous interpretation , the translation result is not output .
Only after the input is completed , output is made in the middle of the input . In order to output accurate translation , they have to have a very complicated processing of syntactic analysis .
We used an example of translation by the simultaneous interpreters and we tried to see how the interpreters translate . We tried to use their skills and know-hows to develop the system ourselves .
The sentences written in certain language and text data of the translated sentence is called bilingual corpus and there have been a lot of studies on this . We try to extract the parallel expression effective for simultaneous interpretation .
In order to extract the parallel expressions , we have to think of the three main stages . First is the matching of the translation corpus sentences .
For example , if I say ohayo gozaimasu , it would match with an English sentence of good morning . The second is tadaima go shoukai itadaki mashi ta Suzuki de gozai masu . This matches with two and three thank you for your kind introduction. My name is Suzuki .
Then , we have to try to look at smaller units , for example , the phrases . And we try to identify the tadaima goshoukai itadakimashita Suzuki desu with two English sentences of thank you for your kind introduction , my name is Suzuki .
We also have to align phrases and we have to extract the bilingual expressions . This is how the sentence is aligned .
There are two methods of alignment . First is the statistical method . The second is the bilingual dictionary is used .
An example of an analytical system is the system using the ratio of sentence length . Another example of the dictionary , we can have a system where matching is easy .
We have to correspond the sentence and the structures depending upon the length of the sentences . Here is one assumption . The Japanese sentences are as long as English sentences .
We have the example of ohayo gozaimasu . ohayo gozaimasu can be translated as good morning . So ohayo gozaimasu equals good morning . tadaima go shoukai shite itadaki mashi ta Suzuki de gozai masu can be thank you for your kind introduction , my name is Suzuki .
Now we have to align with matching of the vocabraries . We use a dictionary to convert Japanese words into English .
And we are trying to use the parallel relationships assume the , , respond to assume the responds from the sentence . Here is an example of ohayo gozaimasu or tadaima go shokai itadaki mashi ta Suzuki de gozai masu .
thank you very much for your kind introduction. I 'm Suzuki . So these two sentences should be matched to English .
Then you have to consider good morning , you reply to ohayo gozaimasu . So the number one of good morning and the sentence good morning are matching or fit .
And also the second sentence we can find such words as presently introduction , Suzuki and presently introduction is that thank you very much for your kind introduction now and Suzuki is my name is Suzuki .
And therefore we have to extract an effective bilingual expression for simultaneous interpretation and also we have to align the parallel corpus to the sentences . And we have to mount this into the simultaneous interpretation kit . In order to extract effective bilingual corpus for the simultaneous interpretations , we have to identify those corpora . We have to place the bilingual corpus from the viewpoint of the rate of sentence length and the vocabulary matching .
And that 's all .
Now let me speak about aligning sentences in parallel corpora for extraction of translation patterns .
This is the background of my talk . Quite recently with the advancement of Internet and the more frequent opportunity to travel overseas , there 're more and more opportunities to communicate with a person with different language background and especially in the travel overseas , it is desired to have a system which can translate the spoken languages .
And at the dialogue , it is more desirable to have a simultaneous translation or interpretation with less time lag . And thus , we consider something like the simultaneous interpretation system .
With this system , rather than the outputting the translation result when the input is over , the translation is provided in halfway through the input . And in order to output the correct result of translation in halfway through , then we need a very complicated process such as parsing .
Therefore , we utilized the actual translation examples by the simultaneous interpreters by learning from the know-hows and the knowledges of the simultaneous interpreters and so that we can incorporate that into the system .
There is something called bilingual corpus which is the text data of sentence written in one language and the translation into another . And that is studied and from this or from such bilingual corpus , we can extract the translation patterns which is effective for the simultaneous interpretations so that we can incorporate this into our system .
In order to extract translation patterns , we 've carried out the processes in three stages or three phases . First of all , we need to align the sentences in the bilingual corpus .
Please look at this example . The ohayo gozaimasu will be aligned with good morning and tadaima go shookai itadaki mashi ta Suzuki de gozai masu or number two will align with the English sentence two and three , Thank you for your kind introduction. My name is Suzuki .
This is what we start with in this translation patterns extraction and second of all , amongst those aligned sentences , we 'd like to find out the smaller functions such as tadaima go shokai itadaki mashi ta in number two can be aligned with the English sentence number two thank you for your kind introduction and once the phrases are aligned , then , those translation patterns will be extracted , which could be useful for the simultaneous interpretation system .
Here , in my presentation , I 'd like to consider the alignment of the sentences , which is the beginning or the first stage of the extraction of the translation patterns .
There are two main major methods of the alignment of the sentences . One is the statistical method . And the other is the using the bilingual dictionaries .
As an example of the statistical method , we can utilize the rate of the length of the sentences into languages or another example for the bilingual dictionary uses is that we can use lexical matching . And I 'd like to explain these two examples in more detail .
And let me begin with the alignment with the rate of the length of the sentences . Here , we first hypothesize that there is a constant rate between the length of the Japanese sentence and an English counterpart .
Let 's come back to the first example ohayo gozaimasu . And to which sentence does it align in English ? Then when we consider that , and it will be aligned with the good morning . And we consider the alignment of the Japanese sentence two and English sentences two and three , then there is some rate of the sentences , the Japanese sentence and its English counterpart .
And this is the alignment by the lexical matching . In this case , we convert a Japanese word into an English counterpart with the bilingual dictionary and utilizing the alignment relationship between those words and then we will surmise the alignment of the sentence .
Towards the word ohayo gozaimasu , we can dictionary and then the dictionary tells you the translation is good morning . Tadaima go shokai itadaki mashi ta Suzuki de gozai masu and toward these words , the translation will be Presently introduction and Suzuki , and these Japanese words will be converted into English counterparts and then when we want to align these translated words into English sentences , then we utilize the alignment or relationship between the words .
Towards the ohayo gozaimasu , good mornig is aligned . Therefore , the Japanese sentence number one will be aligned to English sentence number one .
And when we look at the second Japanese sentence , the word introduction and the word Suzuki appears in the second and the third sentences in English . Therefore the sen tence number two in Japanese will be aligned to the sentences number two and three of the English counterparts .
This is the summary . We can extract a translation pattern which is effective to the simultaneous interpretation through the bilingual corpus and sentential alignment can be done with the two techniques. One is the statistical method , utilizing the rate of the sentences and we can also align the sentences with the bilingual dictionary by utilizing lexical matching. This has been my talk. Thank you for your attention .
Now , I would like to talk about the subject of aligning sentences in parallel corpora for extraction on translation patterns .
As a backdrop , with the prevalence of the Internet and increase of the opportunities of traveling abroad , thus the communication among different languages has increased . And , in traveling abroad , it is expected that the system to translate a spoken language should be designed .
As for a communication or a dialogue , the simultaneous interpretation is also desirable because of the less time lag . So , now take a look at the simultaneous interpretation system .
At simultaneous interpretation , it is not to output the interpretation results before the sentence is ended . But it outputs translation results in the course of the sentence input .
In order to output the correct interpretation result , to structure analysis is needed . Therefore , using the translation samples processed by simultaneous interpreters , we would like to know know-how or the knowledge , how the simultaneous interpreters are translating those sentences .
A sentence written in a certain language and the text data of that corresponding translation are theme of the many researches nowadays . That is called parallel corpora . And from that parallel corpora , we would like to extract the translation patterns , so that we can introduce it to the simultaneous interpretation system .
And when we extract translation pattern , we need three stages to follow . First , alignment of sentences using bilingual corpus .
For example , the first sentence , ohayou gozaimasu is translated or responds to the phrase , Good morning . And the second phrase , tadaima go shoukai itadaki mashi ta Suzuki de gozai masu , responds to the second line , Thank you for your kind introduction , then the next third line , My name is Suzuki . This is the sample of alignment of sentences .
Secondary , among those sentences aligned , we pick up smaller part , such as phrase . For instance , tadaima go shoukai itadaki mashi ta part can be res ponded to Thank you for your kind introduction . This is a sample of alignment of phrases .
Thirdly , from the phrases aligned , we extract all translation patterns which is useful for simultaneous interpretation . And now we take up sentence 's alignment .
As for alignment of sentences , basically there are two methods . One of them is statistical methods . The second is lexical measures .
As for statistical measures , we compare the length of sentences . And the second measure , as for lexical measures , we use lexical matching . And we would like to touch on these in details .
Now , in the sentence 's alignment using the length of sentences , the length of the Japanese sentences and the English sentences have the same ratio , that is the assumption we make .
For instance , the first sentence ohayou gozaimasu where can it be responded to . we think of the case , it responds to good morning , or another case , it responds to good morning , thank you for your kind introduction . At this point , we think of the length of the sentences , and so the sentence , ohayou gozaimasu responds to Good morning that is the assumption we make .
Next , about lexical matching for alignment of sentences , in this method , we use parallel corpora , so that we can convert Japanese words into English ones . and using those relationships of converted words , we can assume the sentence 's response .
For instance , ohayou gozaimasu can respond to Good morning . And the word , go shoukai or Suzuki can respond to introduction and Suzuki as well .
And these two sentences should be aligned in the way that Japanese sentence ohayou gozaimasu is to Good morning . And in the first English sentence , it includes the word Good morning .
So we assume that ohayou gozaimasu responds to this Good morning . And the second sentence of Japanese includes the words , introduction and Suzuki . And those two words are included in the second line , also in the third line as well . Thus we assume that the second Japanese sentence responds to the second and third sentences of English version .
In conclusion , extraction of translation patterns which is effective as well as the alignment of sentences using bilingual corpus can be incorporated into the system . In that case , we take up alignment of sentences using statistical method that is the ratio of the sentence length as well as lexical measures which uses lexical matching .
This is the end of my my speech .
From now on , I 'd like talk about aligning sentences in parallel copra for extraction of translation patterns . This is my presentation today .
I 'd like to touch upon the background . Recently , the Internet and traveling overseas have become very popular and we have many opportunities to communicate with people speaking different languages .
we need , when traveling overseas , the system to translate spoken language is desirable . And for conversation , the limited time lag in simultaneous translation is also desirable .
Now , I 'd like to move onto a simultaneous interpretation system .
In simultaneous interpretation system , translation output is not made after input is completed . In the middle of the input , result is , excuse me , output translation result is made .
So for correct translation , structure analysis and other very complicated processing among others are required . Now , I 'd like to introduce translation examples made by simultaneous interpreters and show you how simultaneous interpreters are actually translating , show you knowledge and approaches and , referring to those , we are thinking about incorporating those into our system .
Data parallel corpus is the text data consisting of sentences written in a certain language and translation its translation . And we extract effective translation patterns for simultaneous interpretation and we 're thinking about possibility of incorporating those into simultaneous interpretation system .
Extracting translation patterns , in order to do that , we need three steps for processing . First one is aligning sentences in parallel corpora or corpus .
For example , number one , ohayou gozaimasu can be aligned with good morning in English . And the second sentence , tadaima go shoukai itadaki mashi ta Suzuki de gozai masu in Japanese can be aligned with second sentence , thank you for your kind introduction and third sentence my name is Suzuki .
And this is what we do in the first step . And the second step , after sentences aligned , we take a close look at a smaller unit . For example , tadaima go shoukai ni itadaki mashi ta can be aligned with thank you for your kind introduction , so it ' s aligning phrases .
And the third step is to extract translation patterns useful for simultaneous interpretation . And here we talk about I 'd like to talk about aligning sentences or sentence alignment .
Sentence alignment has two methods . First one is a statistical method . The second one is a method using bilingual dictionary .
Statistical method has an example of using sentence length ratio . And the second method has an example of lexical matching . And I 'd like to go into details of those two examples .
First of all , alignment by sentences ' length . The Japanese sentence length and English sentence length are assumed to be very similar .
For example , ohayou gozaimasu we need to think which English sentence can be aligned with ohayou gozaimasu in Japanese . So there is another possibility is thank you for your kind introduction in English . So when you think about the sentence length ratio , we can assume that ohayou gozaimasu in Japanese can be aligned with good morning in English .
And next one is about alignment by lexical matching . Using bilingual dictionary , and translate Japanese words into English words using predicted sentence , excuse me , predicted sentence alignment based on word alignment .
For example , ohayou gozaimasu in English can be aligned with good morning using bilingual dictionary . The second example , tadaima go shoukai itadaki mashi ta Suzuki in Japanese can be aligned with presently introduction Suzuki using bilingual dictionary .
Those two sentences need to be aligned with English sentences , we use word alignment .
And for ohayou gozaimasu , we we align with Good morning . So number one , good morning in English can be aligned with first Japanese sentence , ohayou gozaimasu .
The second sentence , the word , introduction and the word , Suzuki can be aligned with second English sentence and third English sentence because second English sentence has the word , introduction and the third English sentence has the word , Suzuki .
Therefore , second Japanese sentence can be aligned with number two and number three English sentences . So extracting translation patterns useful for simultaneous interpretation and we 're thinking about possibly incorporating those into simultaneous interpretation . And in order to do that , we are thinking about aligning sentences in parallel corpus .
And two methods for that , one is statistical method using ratio of sentence length and the second method is using bilingual dictionary , using lexical matching .
Today , I would like to talk about the realization of spoken dialogue MP3 player and its evaluation .
This slide shows the background of us . Internet has become more popular in recent years , and There 're large capacity MP3 files available .
MP3 files is a kind of file to use CD on the computers . There 're , tens of thousands of MP3 files available .
And at the same time , the Walkman and other devices are made smaller with a greater capacity .
And the large capacity MP3 files can be used in those hardwares . The purpose of this study is to retrieve a large amount of MP3 files and the key operations which are difficult on the Walkman .
On the other hand , we have to retrieve MP3 files , we have to make complicated retrievals , and we have to find an easier interface to give instruction , too . So , the voice input can be used as a means of retrieval of information .
That 's why we realized the voice dialogue MP3 players . The user can operate , using the voice dialogue and they can retrieve information with voice dialogue .
This is how they realize the system .
First of all , the spoken dialogue is processed , taking the MP3 device operation and user 's verbal output , we analyzed with key words and we tried to use these words to process spoken language .
We have registered eighty-two words as key words . For example , the replay , fast forward , a little , they are key words for this analysis .
And also based upon these key words , we set 108 types of patterns of the dialogue .
For example , the examples of the patterns are Can I listen to such and such ? , will you please fast forward a bit ? , these are the patterns of dialogue . Then , we have to process based upon the key word analysis .
For example , this is an input dialogue , will you please retrieve Beatles ? We have to find keywords .
Keywords here are beatles and to retrieve . We try to detect those keywords and those keywords are converted into commands .
The commands to the beatles is artist and the command for the retrieve is search , and this is the line of keywords , or a series of keywords .
And we have established 108 keywords .
And after generating this , we would define actions . For example , one is the artist search an d we would generate responses to the retrieval .
Based upon the analysis , we have realized the system . The operation system we used is Windows 98 .
The language we used is Visual C Plus Plus .
As I mentioned before , the number of keywords are eighty-two and the keywords are clusters of t ; 108 .
This is the evaluation of experiment .
The purpose of this evaluation is to evaluate the user friendliness of this system and the experimental methods , the subject of twenty university students .
And we compared the spoken dialogue system of this equipment and the conventional system . And also we tried to let them perform the tasks within a certain limited time .
What are the tasks ?
First of all , Will you please replay ? Thus For this task , we have to find the names of the songs to replay .
And also will you please tell me the name of a title of a song which starts with pure white ? . This is the result of this experiment .
This is the comparison of this spoken dialogue system and the conventional systems .
And if we compare the diversity , we can find that this system allows users to perform the tasks more than the conventional system .
An d you can see that this system increases the task completion and by using the speech sounds in operating and retrieving information , we can improve the operability of operation efficiency .
This is the second experiment . This is the comparison of the speech dialogue spoken language system and conventional system .
This is the questionnaire survey . And this is the evaluation using the scale of zero to five .
Looking at this bar chart , Six for five , four , , ten for four , three for three , and two for one and one for one . This is a conventional system .
And we have one five , and eight fours , and eight threes and three twos . And you can find the better result for the system .
The average is listed here in terms of the voice sounds . The average is 4.05 while the conventional system has a score of 3.35 in average .
Today , I talked about the realization of voice responding MP3 players and in this player , we try to use the keyword analysis for processing and in evaluating the experiment we confirmed the voice operation and voice search and their effectiveness .
Today , I 'd like to discuss under the title of implementation and evaluation of a spoken dialogue MP3 player .
This is the background of my talk with the advancement and penetration of the Internet recently . The huge amount of MP3 files are quite available universally .
And MP3 file is something like a file which enables us to utilize CD on a PC .
And currently , there 're tens of thousands of MP3 files quite readily available . And in addition , such an equipment like Walkman and the equipments are miniaturized in size , but on the other hand , , they are maximizing in terms of the capacity .
Therefore , the huge amount of MP3 files are usable with such an equipment .
And in order to search the huge amount of MP3 file or the operation with a key board is very difficult to carry out especially with the equipment like Walkman , and on the other hand to carry out search for the huge amount of information or complicated search , the voice input is quite suitable and also the voice input is gathering attention because it is an interface which is quite easy to handle .
And therefore , we would like to realize the spoken dialogue MP3 player . And we have realized the operation with the spoken dialogue and operation search , excuse me , with the spoken dialogue .
And let me begin with the process of the spoken language .
First , in considering MP3 equipment operation and utterance of the user , we determined key words . And utilizing such key words , the spoken language would be processed .
And our attempt , we registered eighty-two languages , excuse me , eighty-two words as the key word . They include the replay , fast forward , a little , and so forth .
And based on such a key word , we have generated the patterns of the utterances or uttered sentences . We have analyzed such patterns and finally we have come up with 108 patterns .
And for example , let me show you an example of a pattern . Play the title of the song , or little fast forward , meaning fast forward with a certain degree .
Then how do we carry out the process based on the key word analysis ?
For example , this is the input utterance , , please search Beetles , and then it searches a key word out of the utterance and here the , Keywords are Beetles and search .
And these found key words were converted into commands . And here the command for the Beetles is artist and , command for the search is a search .
And if we align these key words , then we can extract the role of the key words and we have 108 key word role patterns found out .
And after the key word role is generated , then , the motion or action will be defined for the key word . And towards the key word role like artist and search , the required motion is that to search the name of the artist , and then secondly , the response to the search should be generated .
And based on that analysis , we have realized the system .
The operating system is Windows 98 . And the language is Visual C Plus Plus .
And as I said , the number of the key word is eighty-two at this moment , and as to the roles of the key words , we have 108 patterns registered and defined .
And this is the test for the evaluation . The goal of this test is the evaluation of the user friendliness of this system .
We had twenty university student subjects . And this is the comparative test between the voice the spoken dialogue system versus the conventional system .
And as many tasks as possible could be or should be repeated at the given time . And what is the task given ?
This is the example of the task . For example , replay the title of the song and in this case , this song will be searched and played .
Or another example is that what is the title of the song that starts with pure white by artist such and such ? . And this is the result of the test .
This is the comparison between the spoken language system versus the conventional system . And this is average number of the tasks completed on the ordinate we have the number of the tasks completed ; completed and on the we have the average .
And purple or blue is the system and green is the conventional system and as you can see the number of the tasks completed increased with the implementation of the system and as a result we concluded that the spoken language system improved the efficiency of the operation and search .
And this is the questionnaire survey in terms of the user friendliness comparison between the system and the conventional system . And the questionnaire asks the subjects to rate the user friendliness in five rank scales , five is the best and one is the worst .
And according to this scale , six rated five , and ten rated four , three rated three and one rated it as two , and as to the conventional system , eight rated five , eight rated four , three rated it three and one rated as one .
So , with this the spoken language system , it is rated higher than the conventional system and the average is point is 4.05 for the spoken language system versus 3.35 for the conventional system .
Today , I talked about the realization of the MP3 player with the spoken language system and with the key word analysis process . And we have also confirmed that the effectiveness of the voice operation and search in our evaluational test .
Thank you .
Now , the speech today is implementation and evaluation of a spoken dialogue MP3 player . As a backdrop , with the prevalence of the Internet , there exist MP3 files in large volume .
Talking about MP3 files , it the file when you need to handle CDs on your computer . These days , MP3 files are now available in thousands or even hundreds of thousands .
And with downsizing of the hardware , such as a Walkman alone and many songs are input on the hardware . Therefore , we can use MP3 files in large volume .
Under this situation , a search for a large volume of MP3 files or the operation on a small device such as Walkman , it is difficult to operate . At the same time , a search for MP3 files in large volume or complicated search , it is found that the voice input is very useful .
In addition , interface which makes it easier to give instruction in voice input is very useful again .
Therefore , we realize the MP3 player operated by dialogue spoken dialogue . On this MP3 player , a spoken dialogue operation as well as a spoken dialogue operation is realized .
Now , talk about the realization of the system . First , the spoken dialogue processing .
This processing is considering the operation of MP3 as well as the speech of the users , we take up key word analysis . Using this key word analysis , we can process spoken languages .
This time , we picked up eighty-two words as key words and we registered them . For instance , play forward , a little bit are among them .
And based on those key words , we also registered dialogue patterns , with eight ; 108 patterns .
For example , Let me hear the title of the songs or have it a little bit fast forward , these as the patterns among those registered ones . Then how to process based on these key word analyses .
First , the speech for input goes please give me a search for the Beatles .
And this time , the key word is the Beatles and search . And when those key words are found , they 're converted into commands .
The command for the Beatles is artist and a command for a search is search .
We call it these lines of key words as key word lines and we have 108 patterns so far .
After ting ; generating those key word lines , we define those key words . In this example , we make a search for the name of the singers , then we generate our response to the research .
Based on these analyses , we realized the system . At the operating system we installed in Windows 98 .
And the language is Visual C Plus Plus .
As I mentioned earlier , the number of key words is eighty two . As for the key word lines , 108 patterns .
We also conducted an evaluation test and the object of the test is to evaluate whether the system is user-friendly or not .
And the test process is to pick up testees . This time we picked up twenty college students .
And we also conducted comparison test between the spoken dia logue system and existing system .
And we gave the task that the testee excise as many as possible task in given time . Now let me give you the details of the task .
For example , Please play a certain song is the one of the tasks . At this task , the system plays the given title .
And another example is Please find out the title of the song , which starts with the Japanese lyrics masshirona , white in English .
And the test result one is shown here . It 's the comparison between the existing system and the spoken dialogue system .
And we take up the accomplished tasks in numbers . And this vertical axis represents the attained tasks and also blue part shows this spoken system and green part shows the existing system .
And from this dialogue , you can tell that the tasks accomplished has increased . And we also saw the efficiency improved by voice operation and by research .
Now the test result two . We also run a questionnaire for which testtees is to rank the easiness of the operation of this machine .
And , or rank five is the highest level of this evaluation test . And this spoken dialogue system gained six people ranking five , ten people marked four , three people marked one , one person marked two .
As for existing system , one person marked five , eight people four , eight people three , three people one . So , as for the result of the comparison , this spoken dialogue system ranked higher than the existing system .
And on average , the spoken dialogue system gained 4.05 , the existing system 3.35 . Then the spoken dialogue system got higher marks .
Now the conclusion . Today my speech was about the implementation of spoken dialogue MP3 player .
We also conducted an evaluation test , so that we confirm the efficiency of voice operation and voice research . This is the end of my speech .
Today 's topic is implementation and evaluation of a spoken dialogue MP3 player .
I 'd like to talk about background first . Popularization of the Internet , now we can obtain large quantities of MP3 file .
Here MP3 file means the file required to handle compact disc on computer and thousands of MP3 file can be obtained these days .
In addition , equipment , such as Walkman , this hardware compact hardware is now available with large capacity , meaning large number of songs . So we can use large quantities of MP3 file .
So under these circumstances , we search large quantities of MP3 file , or as was previously introduced like with Walkman , it 's very hard to operate with keys . On the other hand , retrieve large quantities of information and complicated retrieval for these purpose , voice input is very effective .
And voice input is attracting attention for interface with easy instruction . Therefore , we implemented spoken dialogue MP3 player .
And in the system , we implemented spoken dialogue operation and spoken dialogue retrieval . How did we achieve or implement this ? Now I 'd like to talk about processing spoken language , or spoken language processing .
And considering MP3 equipment control and user 's speech , and we determined keywords. And using these keywords , are we are trying to process spoken dialogue .
And for keyword , this time , we actually entered eighty-two words . examples of those keywords are example , replay or forward .
In addition , we divide keywords by speech patterns . And as a result , we got 108 speech patterns .
Examples of patterns are like , let me listen something or forward , a little . Those are the examples of speech patterns .
Now I 'd like to talk about how we can analyze based on keyword .
First of all , input speech , for the search Beatles we use keyword analysis .
So Beatles and search are keywords in this case . And these keywords will be converted into commands .
The command for Beatles is artist and the command for kensaku is search .
And the words aligned are called keyword sequence and currently we have eighty ; 180 108 patterns .
And after these have been generated and we defined operation for each command . For the keyword sequence of artist search , we retrieve artist 's name and , excuse me , respond , excuse me , we generate response for retrieval .
So based on the analysis , we implemented this system we use Windows 98 for operation system and we use the language , excuse me , we use Visual C Plus Plus as language .
And keyword number , currently we defined eighty-two words .
And for keyword sequence , we defined 108 systems or patterns . And we carried out evaluation system .
The purpose of which is to evaluate operability of the system . The method for evaluation , we employed twenty collage students as subjects .
And we compare this spoken dialogue system with conventional system . At same time , and we have our subjects execute tasks as much as possible within the given time .
And I 'd like to talk about the task that we gave .
The examples of tasks are as follows , like replay , a certain song and this is exactly to replay a certain song . What is the title of the song , which starts with a very white ? .
And this is the result of experiment .
Number one , we compared the task achieved on average between that system and conventional system . The task achieved is shown on a white axis .
And, excuse me , blue is showing this system and green is showing conventional system . And this system shows the higher number of tasks achieved compared with the conventional system .
So voice operation and search improved work efficiency .
And this is the second result of our experiment . And we carried out survey to find out to compare operability between the system and the convention system .
We conducted survey and asked them to score the operability. Five is the best score and one is the lowest score .
According to describe the system has six with five point , four with ten and three with three , three people and two points with one. And the conventional system , one person with five people , and eight people with four points , eight people with three points and three people with two points .
So as a result , we see the distribution of high score with this system . On average , this system scored four , and the conventional , 4.05 and conventional system scored 3.35. As a result , we can see the better result for this system .
Conclusion , we we implemented a spoken dialogue MP3 player based on the keyword analysis processing and we carried out evaluation experiment and we confirmed the effectiveness of voice operation and retrieval .
Thank you very much .
Ladies and gentlemen , today I 'd like to talk about generating Japanese polite expressions in Japanese-English spoken language translation . Recently also in Japan we have had more opportunities to listen to English .
Therefore , the translation from English to Japanese of spoken English is now highly expected . For example , when English speaker and a Japanese speaker talks with each other , this is one situation , or if for the Japanese audience a lecture is given in English , that 's another example of the situation , we 're this kind of translation might be useful .
Since this is translation of spoken language , the generated Japanese translation should be very spoken spoken Japanese , it would be more desirable . For example , if one thing , is repeated , you can change it in the pronoun by the system , or the unnecessary subjects are omitted , so this kind of redundancy or lengthiness should be omitted in the Japanese spoken language . And also the relationship between person who appears in the talk or the speakers ' relation should be taken into consideration . And depending on that , Japanese people use honorific or modest or polite language depending on it and it happens quite often in the Japanese language .
I 'd like to mention some characteristic of the Japanese polite expressions . First , it is impossible to express the meaning by the direct translation .
let 's take a look at this example , I prepare this room for you . For this English sentence the direct translation in Japanese would be watashi wa anata ni kono heya wo youi suru . This is Japanese translation . Possible translation , however , since this is spoken language , it should be translated , for example , if the speaker is somebody who engages in the service industry , dealing with a client or a customer , the person might say that watashi wa anata ni kono heya wo go youi itashi masu .
This might be more suitable Japanese . An d the second characteristic , there are various expressions in Japanese polite expressions . So this phrase youi itashi masu go youi itashi masu youi itashi masu youi shi masu go youi shi masu are possible here . So there are various expressions in this case .
Therefore , from among that many polite expressions , we have to choose a good one . And we have to make rules for the selection of the good expression . to realize it with the translation system , this rules for selection are necessary . And in the traditional study , these rules are created by human hand .
For example , in the travel conversation , the standard translation for prepare is youi suru in Japanese , but if the speaker is somebody at a reception desk , under this condition , it should be translated as go youi itasu .
That 's the rule made by the human hand . However , since the polite expressions are very complicated , and the way they are used , if they are analyzed by humans to produce the translation for each case , but this is very difficult by human capacities alone to make rules .
Therefore , in this study , I 'd like to propose that we can create automatically the rules for selection for polite expressions , and measures for that will be from the bilingual corpus , we can pick out examples of the polite expressions , and then the rules are made .
I talked about bilingual corpus , this is the collection of the dialogues and the translations .
Let me give you some examples . For example , if the English speaker says I can prepare this room for you , the interpreter will say that kono heya wo goyoui deki masu .
It 's Japanese . And responding to this in translation , the Japanese speaker will say mou sukoshi yasui heya wa ari masen ka , and the interpretation would be this one do you have cheaper rooms ? This is also an example we have .
This bilingual corpus should be the source for learning the rules for selection of the polite expressions .
Here in this example the Japanese is the go youi deki masu , o shirabe itashi masu or o machi kudasai , these are all polite expressions . So what 's the characteristic or features of these expressions and the sentences ?
Here , I paid attention to three points , what is the verb , who is the speaker , and what is the type of the sentence . And , here in the first example , Japanese in the Japanese translation , we use polite expressions as go or masu , but for this to be selected , we have to check that the verb is prepare the speaker is at the reception , and sentence is the declarative sentence , these are the conditions that lead to the selection of the polite expression , such as go or masu in Japanese .
And the same thing can be said to other examples . We pay attention to verbs , speakers and the types of sentences . And by picking them out , we can acquire the rules for the selection .
Now , I 'd like to summarize my point today . Today , I I propose some rules to the automatic creation the mechanical creation of the rules for selection in the Japanese polite expressions in Japanese English spoken language translation .
And I explained how to make it , and this should be based on the corpus . I 'd like to end my speech. Thank you .
Today I would like to talk about the on theme of the generating Japanese polite expressions in English-Japanese spoken language . In recent years in Japan there are more opportunities to hear English language .
For that reason , translation from English language to Japanese language is expected more and an d the need is increasing. For example , in case the English speaker and the Japanese speakers are talking to each other or if a speech is made in English for Japanese language Such English-Japanese spoken language translation would be quite useful .
For example , something that is said once , when it is mentioned for the second time , it will be replaced with the pronoun or sometimes the subject is omitted if it is unnecessary . Such lengthy language is often seen in Japanese language . And also , the characters appear in the dialogue and the speaker speaker 's age or the human relationship is sometimes reflected as the honorific or modest or the polite expressions . Such a polite expression is often used in Japanese language .
Now let me talk about the characteristic of the Japanese polite expressions . And such such expressions can not be expressed enough just by translating directly .
For example , the translation of the English sentence I prepared this room for you is , if it is a direct translation , the translation would be watashi wa anata ni kono heya wo youi suru . However , if this is the spoken language and if the speaker is someone engaging in the service business , watashi wa anata ni kono heya wo go youi itashi masu would be a better and a more appropriate translation .
And other than this translation go youi itashi masu there are other expressions , such as youi itashi masu youi shi masu go youi shi masu Therefore , out of all these choices we need to establish a rule to choose the best option . And if we are to realize this this translation system , we need to establish it , such kind of a choosing rule , but in the conventional studies , such rules were established or made manually .
For example , if it is a dialogue in case of traveling , the standard translation for the English word prepare should be youi suru . However , if the speaker is a receptionist , if such conditions were made , then the appropriate translation word would be go youi itasu . So such rules were made in the conventional studies manually .
However , because a polite expression is so complicated and complex , to analyze such usage of a polite expressions and to choose this expression for this word is very difficult if we were to do it manually . This is why in our study we aimed at creating such choosing rules automatically .
And let me explain about the method . How we do it is to extract cases where polite expressions are used from bilingual corpus and create rules .
And what I mean by bilingual corpus is the collection of a dialogue and its translation . And I would like to show you the example .
Here , for example , the English speaker said I can prepare this room for you and the translator said kono heya wo go youi deki masu . And from this translation result the Japanese speaker says mou sukoshi yasui heya wa ari masen ka ? , and then the translator says do you have cheaper rooms ?
Out of such bilingual corpus , the system learns learns and creates the choosing rules .
And let me show you the example . In this case , there were several polite expressions , such as go youi shi masu , etcetera , but what is the characteristic of the polite expressions ?
And in this time we studied based on the used verb and the speaker and the sentence pattern . And for as the polite expressions go or masu are used . And in that case the verb is prepare and the speaker was a receptionist and the sentence pattern is the declarative sentence , so under such conditions go and masu are used .
Similarly , the polite expressions are used out of these conditions , such as used verb , speaker , and sentence pattern . And this is how the choosing rules has been obtained or established .
Okay Let me conclude .
Today , I have explained a method to automatically create rules to decide properly polite expressions in English-Japanese spoken language in translation . And the concrete method was to extract and establish the rules using the corpus .
Today , I 'll be speaking the generation of the Japanese polite expressions in Japanese to English spoken language translation . In recent years , in Japan , the many occasions that you listen to English .
And therefore , there there 's a need for the spoken language translation from English to Japanese and there is a great expectation given to it .
For instance , the occasions that English speakers and Japanese speakers have a dialogue . That is one circumstance and other the occasions is such as that there is a lecture given by the English speaking speaker to the Japanese audience .
In such a case , English to Japanese spoken language translation is going to be useful In a spoken language translation the Japanese generated should be spoken language shape . It is desirable that way . For instance , the one word once said and next time the same words are repeated it will be eliminated and then be replaced by the pronoun , so redundancy can be omitted in a Japanese sentence and also the relationship between the persons in the dialogue and the speaker plays an important role in selecting the words when it comes to the respect words , humble words or courtesy words .
These are the examples of the polite expressions used in a spoken Japanese translation .
The features of the Japanese polite expressions are such that direct translation from English to Japanese does n't count much For instance , there is this sentence like prepare this room for you and if the direct translation is made , it will be sound like watashi wa anata ni kono heya wo youi suru and such a translation will be made . But in a spoken language , the , if the speaker is , for instance , in a customer service or something , better translation should be , watashi wa anata ni kono heya wo go youi itashi masu , and also in polite expressions there 're varieties of expressions possible For instance , a part from go youi itashi masu , youi itashi masu or youi shi masu or go youi shi masu are also possible alterations of the expressions .
And therefore , there 're many polite expressions existing and to choose one expression out of the multiple number of the polite expressions is quite difficult . And so , in a translation , system to make that happen , we need some kind of selection rules , but in the conventional study this kind of a selection rule had been prepared by human hand .
For instance , in a trouble dialogue situation , for the word prepare , the standard translation will be youi suru , but in case that speaker is a receptionist , at at trouble . In that case , the translation will be go youi itasu .
So , these things had been prepared by manually . But the polite expressions are very complicated and therefore , to analyze all kind of possibilities for the usage by human hand to make the selection rules for each case . To cover all situations is going to be very difficult .
And therefore , in this study , we are suggesting that we generate this selection rules automatically for the polite expressions .
And a methods are as follows . From the bilingual corpus , the examples of the polite expressions are taken out as examples and based upon those examples the selection rules are prepared .
And the word bilingual corpus means that dialogue sentences and translated sentences , for instance , such things like this . For instance , English speaker says , I can prepare this room for you and the translation would be kono heya wo go youi deki masu .
And the result of this translation the Japanese speaker says , mou sukoshi yasui heya wa ari masen ka ? And the translator translates responds such English like this .
So , in this way , the bilingual corpus provides the opportunity to learn the polite expressions and I will explain this learning method .
And according to this examples , go youi deki masu or o shirabe itashi masu or omachi kudasai , those are the examples of polite expressions . And features of these sentences are such things .
In this case , the verb or speakers or sentence type the three features that we checked .
As a result of that , the first example is case the go or masu is used for the polite expressions and for the selection of such polite expressions the verb should be such word as prepare and the speaker should be the receptionist and the sentence should be the declarative sentence . So , under these conditions , go or masu are used as expression .
Similarly , the other examples also show that depending upon the verb or speaker or the sentence pattern determines the type of the polite expressions . And that 's the way that we can obtain the selection rules for the polite expressions .
The summary , in a English to Japanese spoken language translation , I propose the automatic selection rules , generation of the Japanese polite expressions using the corpus , bilingual corpus .
And that 's all for my presentation .
Today , I would like to talk about generation of Japanese polite expressions in English-Japanese spoken language translation .
These days in Japan as well the opportunity to listen to English has been increasing . For that the English-Japanese spoken language translation has been expected increasingly .
For example , the English-speaking person Japanese and Japanese-speaking person communicate each other and English lecture targeting Japanese has been held . In these circumstances English-Japanese spoken language translation has been very useful .
It is most desirable case . For example , the already spoken language should be changed to pronoun and unnecessary subject must be omitted which is the omission of redundant words . It is often seen in Japanese sentences . And the person in the spoken sentences and speakers , so that this kind of personal relations must be taken account into .
Then what is the characteristic of Japanese polite expression ? Direct translation can not convey messages . That is the characteristic of Japanese polite expression .
For example , when I say I prepare this room for you , the direct translation is watashi wa anata ni kono heya wo youi suru . However , in the spoken language if speaker is a receptionist , the translation would be watashi wa anata ni kono heya wo go youi itashi masu . This is the better translation .
And also in the polite expression , there are various kinds of expression . In Japanese go youi itashi masu youi shi masu youi itashi masu . Those are various kinds of translation .
Therefore , among these various kinds of polite expression we have to create the selection rules which expression must be used in a particular situation . If we try to create this in the translation system , we have to have the selection rules . In a conventional research these selection rules of polite expression was made by human .
For example , in travel language the English word prepare is translated into Japanese in standard way as youi suru , but if a spea ker is the receptionist that translation changes to go youi itasu . So this is the rule of selection .
And this is made by human beings . However , the polite expression is very complicated , so how to use the polite expression is analyzed by human beings based on that analysis . Various kinds of selection rules of polite expression is very difficult by human beings .
Therefore , this research is tried to create automatically the selection rules of polite expression .
Let 's point out the method . There is the bilingual corpus so from bilingual corpus , cases with polite expression are taken out and rules are to be made .
What is bilingual corpus ? That is , corpus consists of spoken English sentences and translation just like this .
And this sentence , the English speaker says I can prepare this room for you . Then translator says kono heya wo go youi deki masu .
Then after listening to the translation , Japanese speaker says , mou sukoshi yasui heya wa ari masen ka ? And then translator says Do you have cheaper rooms ? So those are the bilingual corpus .
From this bilingual corpus we learn the selection rules of polite expression . Now let 's talk about how to learn the selection rules .
Please look at this example . go youi dekimasu , o shirabe itashi masu , those are Japanese polite expressions . Then what is the characteristic of those polite expressions ?
We have to find out what is verb , who is the speaker , what is the sentence pattern ? So those are three targets we have to find out .
After analyzing those those , we understand that go and masu are used in this first sentence . If we select this polite expression , we have to think about the prepare is the verb , and the speaker is the receptionist and sentence pattern is declarative sentence .
Therefore go and masu are used . So in other cases , we have to think about verb , speaker and sentence patterns , then find out the polite expression . So this is the rule of the polite expression .
Now I would like to summarize .
Today , I propose the method to automatically create decision rules , or selection rules , of polite expression in English-Japanese spoken language translation . And the basis is the corpus .
So I explained the method of of the automatically create discussion based on corpus .
Ladies and gentlemen , today I 'd like to give you a presentation on theme of increasing the efficiency of incremental parsing using statistical information .
For start , let me give you my background for this study , for this presentation . The objective of our study is to realize the real time on dialog processing system .
This system , real time dialog processing system receives and reacts to the utterance by the user immediately , and then understands it , and then responds to it immediately . This is the example of this real time dialog processing system .
This English sentence is Ken studied English at school yesterday . If the user utters this sentence , if the user says , Ken studied up to this point , this system must react to the input , the utterance .
And for that purpose , the two words , Ken studied are input and it has to be determined that Ken is the subject of this sentence , and the word , studied is the predicate of this sentence . That 's what system has to judge .
, As you can see this example , up to the point , that has been uttered the input sentence must be understood by the system . And we call this method the incremental parsing .
And this is the same example as the one we had before the input sentence is Ken studied English at school . , In this example depending on the utterance of the user if the input is up to this point , Ken studied English at , in this case , even if the input is the same , there are two ways to understand the sentence , interpret the sentence .
, In the above case at should lead to some name of some geographical name . And this should be interpreted as Ken studied English somewhere . This is one way to interpret . And another way to interpret is Ken studied English that exists somewhere .
So the two ways of interpretation become possible here . So , if it should be responded real time in order to realize this kind of system , this kind of utterance of the user must be interpreted in one particular way , in one specific way .
Therefore , for the two interpretations , one of them should be selected as the right interpretation that reflects the real intention of the user . And that 's what a system should should do .
So the objective of our sturdy is to increase the efficiency of this incremental parsing , and as you saw in the previous example from among several possible interpretations one should be selected as right .
Well Here this time we selected this approach . , For the incremental parsing we we are going to introduce the semantic information in the incremental parsing system .
, This is also the same example we have had , Ken studied English at , this this is the input . In the above example at modifies the word , studied .
This is the two interpretations of the sentence , the possible interpretations of the sentence and from among the two we have to choose one if you want to do that . At this point if we have some semantic information on our hand like , if the modification of a word , two another is possible . , In this case this is the word , at never modifies the word , English . And if we have this semantic information , naturally , the interpretation for the example sentence the second interpretation can be judged as wrong .
By this the utterance of the user can be interpreted in one way among the two possible interpretations .
, At this case two judge the right interpretation s . We decided to use semantic information . This semantic information , I 'd like to explain what the semantic information is .
, Before the incremental parsing is done , we will prepare the large-scale text data called corpus . This is the collection of many , many English sentences . By using this corpus We we acquired the semantic information by learning from this corpus . And these semantic information acquired before hand can be applied to incremental parsing .
So that 's the process we make this system possible . Now let me summarize my presentation today .
, To realize the real time dialog processing system , we realize the increasing of the efficiency of the incremental parsing , and the effectiveness of this method was confirmed by the experiment .
Today , I would like to speak under the title of increasing the efficiency of incremental parsing using statistical information .
And first of all , let me explain about the background of this study . Our purpose of the study is to realize the real time dialog processing system .
And this system is when user speaks , the system is supposed to receive the speech and understand and immediately respond to the user speech .
And I have given you the example to show the such system . For example , if the user said Ken studied English at school yesterday and when the user said Ken studied , and in the middle of the speech this system must respond to such user speech .
And for that purpose , when the words , Ken studied have been input , the system must understand that this word , Ken is the subject of the sentence and this word , studied is the predicate of this sentence . The system must judge and understand such things immediately .
So as you saw here , this system , in the middle of the speech must understand such things in the sentence . This is what we call the incremental parsing .
And I would like to use the same example sentence here , in other words , the sentence saying Ken studied English at school yesterday . And at the point where the Ken studied English at has been input , there are two ways of understanding this sentence .
So if I use this example , and in the upper example , maybe it could be understood that this at wants to mention the place where Ken studied English . This is one way of interpretation and the other interpretation is as is shown below , to say that Ken studied English where is located at someplace . So , depending on what this at modifies , there are different ways of modification when understanding .
But in order to realize the system that I have already mentioned , the system must understand the sentence , and choose the right interpretation . And which of the two interpretations really reflects and understands the speaker 's intention , the system must understand correctly .
So , this is why we intended to increase the efficiency of incremental parsing in our study . And as you saw in the previous example , there are several choices of interpretation , but a system must choose one correct option .
And as its approach , we have introduced the semantic information in the incremental parsing .
Let me use the same example again . It says Ken studied English .
And in the upper sentence , at modifies the word , studied , but in the below example , this word , at modifies the word , English . There are such two interpretations . And if where we were to choose the right interpretation , and in this case the , semantic information shall be whether it is possible for this word , at to modify the certain word . So in this case , the information that the word , at would never modify the word English , if that , such information was obtained as the semantic information , then the lower sentence or the lower interpretation proves to be wrong .
So with such a semantic information the system can judge that lower interpretation is wrong . So , this is how the system is able to choose the right interpretation .
And in order to choose the correct interpretation , we considered using the semantic information . So before performing the incremental parsing , we should use corpus which is the collection large collection of example sentences . The system shall obtain the semantic information through learning . And using such semantic information that is previously obtained , the system chooses the correct interpretation in order to perform the incremental parsing .
So let me summarize and my presentation . So in order to realize the real time dialog processing system , we have actually increased the efficiency of incremental parsing .
And in order to evaluate the effectiveness of this method we have performed several experiments to prove this this effectiveness . I would like to conclude my presentation here .
Today , I 'd like to present the increasing the efficiency of a incremental parsing using statistical information .
First , I 'll explain the background of this study and objective of this study is as follows , That is the realization of the real time dialog processing . And this real time dialog processing means that when the user against utterance of the user , the system by accepting the utterance and make understanding and make a response to the utterance immediately .
And examples of the real time dialog processing such things , such sentence like Ken studied English at school yesterday . And supposed that if this is the utterance of the speaker when the user mentioned Ken studied up to this point , The real time dialog processing system per against this input must make a response .
So , when up to this point Ken studied was made input , the Ken is the subject of the sentence or or the next word studied is the verb of this sentence . Such a thing should be understood by the system .
In this way , in in between the input of the user , the input sentence should be understood by the system .
And this method is called incremental parsing . The same , input sentence , Ken studied English at school , when we think about this sentence , by the utterance of the user , Ken studied English at when the input was made up to this point , even though the same input there 're two interpretations possible .
In this case , the first example is that after at , there is a some geographical name coming that is the judgment of the sentence Ken studied English at somewhere . That is the judgment or interpretation of the sentence of the system or the other interpretation is that Ken studied English at somewhere , located somewhere . So , after at or the at modifies two possible words and hence two possible interpretations .
So , real time dialog processing , realization should be made in this way . When the utterance is made by the user the choices has to be made out of these interpretations so , for these two interpretations which interpretation is the right interpretation to interpret right for user 's intention .
And therefore , objective of this study , is that the efficiency improvement of the incremental parsing , so like in that example , there 're possible interpretations and then we have to focus in one interpretation out of many interpretations and that is the objective of the study this time .
And the approach that we used is that for this incremental parsing . We decided to introduce the semantic information .
In a same method used in this sentence , Ken studied English at such a such a word at modifies studied and in the latter case , at word modifies English .
So , there 're two interpretations possible . But , out of these two possibilities which one is correct and we 'd like to focus narrow down to one choice . In this case , at this point , if we have a prior semantic information included , we can know that it 's possible to modify such a word . For instance , in this case , the at word at modifies English or not .
So , by this way for the utterance of the word of the user out of the two interpretations , one interpretation can be interpretation can be narrow down into sentence one translation . So , for narrowing down this interpretation we use the semantic information .
Semantic information happens before the incremental parsing , there is a corpus , that is a large scale text data , this is a collection of a many English sentences . So , by using this corpus , previous to the action the semantic information is obtained by learning in advance . So , such a prior semantic information obtained is utilized for incremental parsing .
So , the summary of the study , We realize the efficiency improvement of the incremental parsing .
And this proposed method and validity was proved to be effective by the experiment . That 's all for my presentation .
Today , I would like to talk about the increasing the efficiency of incremental parsing using statistical information .
Now let 's talk about background of my presentation . The purpose of our study is the realization of real time dialog processing system .
This What is this system ? That is the system instantly respond to the speech of users .
Please look at this example . For example , when speaker said , Ken studied English at school yesterday when the speaker said , Ken studied , and this middle of the sentence this real time dialog processing system should respond to the words .
In this case , when speaker said , Ken studied , the system has to recognize Ken is subject , and studied , the next word studied is the verb . So this is the necessary information system has to realize .
In the middle of the inputting of the words , the system has to instantly respond to and recognize the word . So this is called incremental parsing .
So please look at the similar or same example . The input sentence is Ken studied English at school . When we think about this sentence , the speaker said Ken studied English at . There are two interpretations by listening to the sentence Ken studied English at .
As for upper sentence the system interprets that some place will follow at which means Ken studied English at somewhere . This is one interpretation . And there is another interpretation as shown by the bottom line Ken studied English at . So Ken studied English , placed at somewhere , so there are two interpretations .
Based on the real time dialog process system such words made by speaker has to be limited to one interpretation out of two interpretations .
Therefore , which interpretation is appropriate in order to convey the message of speaker ? The system has to judge which interpretation is appropriate .
So the purpose of this research is the improvement of incremental parsing . So among several interpretations , as I explained , we would like to limit only one interpretation .
So that 's our purpose . So what is approached ? We introduce semantic information into incremental parsing .
So those two sentences are exactly the same sentence as shown before . The input is Ken studied English at . In the upper sentence at modifies studied and the bottom sentence at modifies English .
So there are two interpretations as shown . So among two interpretations we have to limit the only one interpretation . So in order to get the limitation , we have to use the semantic information which is , one one word should modify one word . And the sentence the word at modifies English .
Therefore , among two interpretations , the system can appropriately select one interpretation . In order to limit interpretation , we use the semantic information .
Before having the incremental parsing , we have corpus which has large-scale data . So we use corpus . We obtain the semantic information through learning . Already obtained semantic information is utilized in incremental parsing .
Now I would like to summarize my study . In order to realize real time dialog process system , we realize the efficiency of the incremental parsing .
In order to evaluate the effectiveness of this application , we were able to recognize the availability of this application .
Ladies and Gentleman , today I 'd like to talk about the mobile agent system for supporting adhoc communication . The background of the study is the Internet has developed and has spread .
And the wireless LAN or the mobile phones and other other wireless infrastructure has been improved , so you can do the telecommunication anywhere .
And mobile computing has also spread , you can carry the personal small personal computers which retains personal information .
And you can carry the portable such portable terminals and you can always have access to anywhere , anytime , to information , freely , casually . However , for these the mobile environmental telecommunication has been based on mobility .
You can not find a source for electricity or however , in this system you want to feel that you have never moved although you are not in front of the desk you want have the same environment as in your desktop and portable phones and a wireless system is used for the purpose .
For example , if you 're in front of a refrigerator or , in TV or in a conference room , and this kind of telecommunication is done basically like periodically as in the meeting or accidentally or meeting somebody .
And we define it as adhoc communication and we want to support this communication .
A person comes here , and here sit his friends and they accidentally meet and talk but in addition to the usual dialog they can make communication with the terminal .
And in addition to , there 're exchange towards , they can exchange data . For example , the schedule or the photos in their portable terminal , so the personal communication can be enriched by the system .
So , the adhoc communication should be supported through the portable information system and we want to realize this and we want support first a dialog between people .
And we 'd like to support encounter among people even if they meet for the first time , they might have the same friend or they might have graduated from the same high school .
And if that information is in the terminal , they can find this kind of information which is not realized in the usual dialog sometimes .
So , we can match individual info . And also we 'd like to support dialog between a person and a information system .
For example , if a person moves around , if person goes to the station and there 'll be something like information kiosk .
If the person has a portable terminal with his personal information , he can use the information kiosk easily .
And not just this kind of portable terminal , but you can use various terminals , at office , at home , or somewhere else you go . And it should be used freely .
The adhoc communication is basically dialog between people when they meet and we 'd like to enrich this . And basically , the number of participants dynamically changes .
Sometimes you speak with one person , sometimes you need to speak to hundreds of people at a lecture , or sometimes you have a panel discussion with several people and sometimes you can get the advance preparation for that , but it 's usually impossible .
So , you have to change information on the spot . And it should the information should be shared , by such application .
Then how you can share this application ? For example , if meeting you distribute paper , but you can utilize the terminal for that purpose .
And this also depends on the condition and depending on the type of the communication or the place , the objectives will be different .
If in the meeting room or on the streets when you meet some people , the terminal has to support this kind of different condition .
So , it has to be understood and then the information can be shred .
The dynamic aspect is the changing the number of the participants . The studied adhoc network is studied recently studied these years .
And it should be constructed according to needs even if they 're not prepared .
The network is wireless network is used and there is no server to run network .
And since there 's no advance preparation the server can not exist and there 're several propositions and implementations of this we also have the infrared ray adhoc network , we 've been studying that .
And next , how we can share the application ? When you meet someone casually , it is impossible to prepare the share the application .
You can not decide which one to use beforehand . You can not prepare all the software beforehand . So we have to dynamically distribute it . We have to distribute application .
And for that we want to use mobile agent this is system or program that can autonomically moves on the network .
And the method to adopt to the condition is we we do n't want to order the objective each time , so we 'd like to use the intelligent agent to perceive the situation which autonomically decides or judges the situation .
So we intelligent agent , mobile application and the agent network to construct the adhoc network and this will lead to the realization of the adhoc communication .
This is a specific example . This person is in the office and he 's going to their meeting room and if he says , I 'm going to the meeting , this mobile agent moves to the his portable terminal .
And if he goes to the meeting room , he will say that I 'm going to distribute it to you and the intelligent agent reacts to it and distribute it to all the participants or if there 's a presentation , the information is transferred to the terminals .
And so it acknowledges the situation and distribute it . This is realized through the system .
So , we would like to do the adhoc communication the system to support communication between people and people or people and computer .
And to support it the adhoc communication system is realized based on mobile agent and by using this adhoc communication can be possible anywhere anytime casually . And it is supported intelligently .
Thank you very much .
Today , I would like to speak about mobile agent system for supporting adhoc communication. And background of the study is for one thing the development and diffusion of the Internet .
And recently , the wireless LAN , mobile phones , and other wireless devices have been diffused to enable everyone to communicate anywhere .
And the third thing is the mobile computing by carrying the small computer , which contains the personal information , is being spread .
And by using such a system we would like to use information freely and easily anytime , anywhere .
However , communication in mobile environment , we were thinking of the mobile permeation and there were many restraints , such as lack of power source or the network .
But what we mean by mobile permeation is that even if we are traveling , we can assume ourselves as if we are not moving , that we have the same environment as if we were sitting in front of our desktop at home .
But what we are intending instead of the mobile permeation is the dependence on the mobility and the communication is significant because we are traveling . This is what we are intending for .
And how such communication depending on the mobility is made is that , for example , it can be made regularly or can be communication made accidentally , for example , meeting someone by chance and we define this as the adhoc communication and we intend to support it .
And I would like to show you the easy example . For example , this person is walking in town and he meets a friend of his in the town .
And of course , they talk to each other , but they also use their PDA , and exchange some information .
And other than just speaking , this we can use this information contained in the mobile phone , the PDA for example , the schedule or the photographs . So , by using such devices , we would like to enrich the dialog or the confirmation with more information .
So , in such this is why we want to realize the mobile information system supporting adhoc communication . And the communication can be at dialog between the humans .
For example , someone meets someone for the first time , but they might have the common friends , and or we might want to match their personal information , for example , the high school that they have graduated from .
And they , two people might have graduated from the same high school , but they might have find out that they had common friends and by then using such a computer , they can find out such information .
And the second is the supporting the dialog between human and the information system .
So , for example , if someone went to the train station and if there was an information kiosk in the station , the person can use such a kiosk .
And if that person had the PDA , through the communication with the information kiosk he can obtain more information , so he , that person can freely use many information at terminal anywhere . And usually people use this , the fixed network at home , but we want to make it so that people can use such network and system anywhere .
And what we mean by the adhoc communication is the dialog between humans , but our intention is to enrich it , make it even richer .
And usually , the participants of the conversation changes , it might be three or four people if it is the normal conversation , but if it is the speech , the audience might be more than two hundred or three hundred , and can be a panel discussion or the conference .
And in many cases there is no prior preparation , people have n't prepared previously what you talk . And they exchange information at that instance .
And now , we are presuming that information this is the communication the computer using a computer and if it is a conference , people usually hand out the materials , but we can do this with the system .
And it is also necessary to have the communication matching the circumstances . And depending on the place of the communication , the purpose of the communication is different .
For example , if it is taking place in the conference room , it is the conference . But if someone meets someone in the town , it is just the personal talk .
So , this system must have the application that is applicable to each circumstances .
Okay , then let us discuss about each element one by one .
The first thing is , that this is a mobile network technology . And what we mean by adhoc network is the network constructed depending on the necessity and usually it is created through wireless devices .
And the characteristic of such adhoc network is that it has no no no server to control the network .
And we already have several implementation . And we also are studying the infrared adhoc network .
And , and the second topic is the sharing of the application . If someone meets someone by chance , it is not always the case that they have the same application .
So , it is impossible to prepare the application beforehand . It is impossible to prepare the common the common communication software , so it it is necessary to have a system to distribute the application and we use mobile agent for this purpose .
And this mobile agent means the program that moves around the network .
And third thing is the application method for each circumstances . And we want to system to understand without any instructions .
And for this purpose , we would use the intelligent agent .
And this agent is the program to understand each circumstances . So , using this intelligent agent and the application and the agent network , we would like to realize the adhoc communication .
And let me show you the concrete example . For example , if someone is going to have the conference at the office , and if there is the intelligent mobile agent , this , intelligent mobile agent will transfer all the materials to the PDA .
And if that person goes to the conference room , this mobile intelligent mobile agent will distribute these materials to all the participants of the conference , and at the same time , if there was a presentation board , this agent will transfer the material to the board .
But the person needs not give instruction to the mobile agent , but the mobile agent itself would judge the circumstance . And this is where the system supports such communication .
So , we are thinking about the characteristic of the adhoc communication .
And we have also realized adhoc communication system based on the mobile agent system which enables the intelligent support to the adhoc communication easily anywhere anytime , anywhere .
Today , I will make a presentation on the mobile agent system for supporting adhoc communication . First , the background of the study , the Internet has been used very widely these days .
And these days the radio infrastructure has shown an improvement to the satisfactory level that anybody can make the communication anywhere , anytime .
And the mobile computing that 's a small scale of the computer has been broad in a portable state , and in which that personal information is is kept .
Such portable terminals are carried around so that people can get information anytime , anywhere very freely and casually . But the communication under this mobile circumstance had been so far placed importance on the mobile permeability .
What it means is that in the mobile situation there is no power and there is some restrictions . But the mobile permeability means that just like to show that as if that in a sitting situation that even if you are in a mobile situation .
So that 's why that the cellular phones or the radio have been used . But what we 'd like to do here is that mobile dependence .
That means , there is a meaning in mobility , that there is a meaning because I 'm here in front of this TV or in front of the refrigerator or in the meeting room . That kind of communication is what we are talking about .
So this is the communication depending upon the mobility . This is the communication that made in regular meetings or in accidental meetings .
So , in this kind of accidental communication we will like to define this as adhoc communication and I 'd like to support this adhoc communication . Here is an example of the adhoc communication .
For instance , a man is walking in the street and he meets eyes friends and they just happen to meet , and then they talk , and in addition to that , they have this portable computer and they directly communicate and then exchange information in this terminal , and in this terminal they have their schedule or picture information and those information can be exchanged .
And by exchanging those information you can make the normal dialog richer or more information can be exchanged .
So in this sense this is the mobile information system to support the adhoc communication . And we what we 're trying to support is the dialog between the man and man .
For instance , supporting the encounter they meet the first time , but maybe they have some common friends .
So , by using the matching of the individual information like , for instance , my high school and then his high school can be matched , and then just happens to be that we went to the same high school or something .
So , in a normal conversation you do n't know those things , but by exchanging the information through the terminal they find out about it .
And the other way of the support is that men and information systems dialog , that for instance , if you go to the station there is a information Kiosk for the use by pressing the button , if this person has this portable terminal with this personal information , by exchanging information with the Kiosk terminal you can use this Kiosk terminal more easily .
You can use all of those terminals freely and easily . And then , this terminal is connected to the office and home or a mobile location .
So , the meaning of the adhoc communication is as follows .
As in the case of the dialog between man and man , when man meets another man , and we 'd like to support such a dialog . That means that the feature is that the number of the participants to this dialog changes dynamically .
There 're sometimes two people , sometimes three people . In the lecture case there 're one hundred audiences . In the panel discussions case or in some meetings there 're specific number of the people .
And in many cases there is no prior preparation .
They do n't prepare something to talk about . They do n't know what kind of information to exchange .
It just happens that information necessary to exchange . And so that 's why that the should be shared .
For instance , in the meeting room you distribute a paper and take a note . And this is one way of the information sharing and so how we can support this in a portable terminal 's case .
And the last case is that necessary , the dialog should be circumstantial dependence . That means that it depends upon the circumstance or the places , their objective differs .
If it 's the meeting room , the paper should be distributed . If it 's the meeting in a street corner , it 's not a meeting , it 's personal information you need to exchange .
So , how a portable terminal should support ?
And the understanding of that situation is necessary to provide than necessary information . First , the dynamic network technology , as for that adhoc network system is recently researched .
Adhoc network system means that network that is being constructed on a necessary basis , network that is being instantly established . Many cases it 's a radio network system .
And the feature here is that there is no server existing to control the network , because there is no prior preparation , we can not set particular server for control .
And for this there are multiple number of the mounting or proposals existing . We have introduced and researched infra red adhoc network .
And next , talking about this application , , when they meet in adhoc manner , there is no application common .
So , there is no way to set the application beforehand . So , that means that it 's impossible to prepare any arbitrary application beforehand . So it has to be the distribution in a dynamic manner .
And that dynamic application is a system called mobile agent . This mobile agent is the program that moves autonomously on the network .
And the last one is the adaptiveness to the circumstance without indicating the objective . We want system to make understanding .
So , for that we need the intelligent system for the understanding of the situation . This intelligent agent makes a judgment by itself .
By doing so , intelligent agent , mobile application , agent network are used , we can make the adhoc communication system . And a concrete example , for instance , is like in this way. In an office situation they are just about to have the meeting and here this is a intelligent agent. When he says that we are going to the meeting , then intelligent agent moves that information to his cellular phones , portable terminals .
And he goes to the meeting room , and then to the participants this mobile agent distributes to all the participating members the documents .
At the same time , if there is a presentation board in the meeting room , that information is transmitted to that board . So , this man dose not indicate to the terminal that I am in the boarding room , but mobile agent acknowledges , understands and realizes it by itself .
So the summary .
We would like to make a feature of the adhoc communication which is the communication made for the portable terminals on a necessary basis . And for that , we realize the adhoc communication system based upon the mobile agent .
By this adhoc communication can be supported intelligent manner anytime , anywhere in a very casual manner .
Today I would like to talk about Mobile Agent System for Supporting Adhoc Communication .
First , the background of the study . The Internet has been developing and diffusing , many people are using the Internet .
And these days wireless LAN and mobile telephone has been diffusing as well as wireless . So whenever you can communicate each other .
And next mobile computing has been expanding . A small calculator is carried by many people .
And in the small calculator personal information is held . So those mobile terminal has been carried by many people .
So by those infrastructure you can use the information anywhere anytime at your will . So the communication and the mobile environment in the past we were thinking about mobile permeable communication .
What is it ? Usually we do n't have the consent outlet , if we do n't have the outlet of wire , we can not do that .
However , in the mobile permeable communication can , you would like to use the desktop computer even if you do n't have it . Therefore we use the mobile telephone and wireless mobile infrastructure .
But this time I would like to think about mobile-oriented communication which means that communication has the significance in moving . So this is what we are thinking thinking at the moment .
So mobile-oriented communication is carried out routinely at the conference or accidentally when you encounter other people on the street or other places . So this accidental communication is defined as the adhoc communication .
So we would like to support this adhoc communication . This is one of the examples of the adhoc communication .
The man is coming to those two ladies and they encounter each other , they start talking but all of them have small terminal devices . So among those devices they exchange their information .
In addition to the communication by speech , they can exchange the information including picture , photo and other personal information within those terminals . So in this case they can exchange more information each other .
So this is the adhoc communication . So we would like to realize the mobile information system to support adhoc communication .
What we would like to do ?
To support the dialog between people , if the people meet each other first and they have the common friends , those two persons can use the mobile terminal in order to get the personal information like graduated school name , like that .
So by the support of the calculator mobile calculator , they can enrich the information .
Also we would like to support dialog between people and information system . When you go to the station , there is a information kiosk .
If has the terminal with personal information , they can use the kiosk terminal freely by the support of their own personal terminal . So people use those kiosk terminal or other terminal with their own supporting terminals .
Then what is adhoc communication ? It 's the dialog at the encounter of people .
So we would like to enrich the dialog . Basically the number of participants is kinetically moved .
Sometimes we talk among two people , and we talk in front of about a hundred people , and in a panel discussion we talk among limited number of people . And usually there is no prior preparation .
We have n't had any information or preparation for what we would like to talk at the encounterment .
Therefore shared application should be shared . So how to share the shared application ?
In the conference materials are distributed to the participant .
But how to support that shared information by the mobile terminal ? So where the communication takes place is important to think about adhoc adhoc communication .
At the conference we distribute the materials , but this is on the street we would like to exchange information personal information .
How to support ?
So it is necessary to realize in what sort of situation they are .
Now let 's think about kinetic network . Add hoc network is used .
This network is built as the needs arise . Usually it is a wireless network .
The characteristic of this is that there is no server to control network because there was no preparation .
So we can not decide which thing should be controlled by server .
So as for this , there are several mounting . Also I studied infrared rays adhoc network .
Next is the application sharing . At the encounterment We do n't have the shared application or common application .
It is impossible to prepare the common application at the encounterment . So it is impossible to prepare all application . So how can we do that ?
, application distribution is carried out kinetically , so we in this case we use mobile agent . Mobile agent is that yourself can move on the network autonomously .
We do n't want to instruct exactly what we we would like to do . So acknowledgement without instruction of purpose is important .
So in order to do that , intelligent agent is necessary to recognize the situation . So mobile application and intelligent agent and agent network , those the combination of those three is the method to realize adhoc communication system .
Actual example is that at the office you will have the conference and this is the agent intelligent agent . So this intelligent agent can gather the information by itself and transmit that information .
And if you would like to distribute information to every participant , and this intelligent agent distribute that the information to participant by itself . So you can also transmit the information on the board .
So this intelligent agent recognizes or judges situation and then distribute all necessary information to participant autonomously .
So , the person person-to-person communication and person-to-system communication is supported by adhoc communication .
And we realize adhoc communication , and by using it whenever , wherever you can support adhoc communication .
