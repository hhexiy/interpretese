The simultaneous translation system of English lecture is going to be elaborated .
The spoken language translation is the first point in translating spoken language . When two persons converse with each other in different languages , this translation of spoken language will be very useful .
For example , she and he will converse together and through dialogue translation system between the two people . They can converse with each other .
For example , he  when he speaks , system the system will translate what he utters into into the language she understands and she will understand what he is saying .
conventionally , the dialogue translation system was developed in the past , but the systems thus developed so far usually do do translation based upon the unit of one sentence , one sentence by one sentence. So after he speaks , then the system will translate into other language .
And system will create speech . so , actually , the users and system will have to utter or speak alternatively alternatively .
Meanwhile , we talked about the dialogue in the previous side , but when it comes to monologue , what will be the possibility of translating one-way lecture ?
So in that situation , the system will support one-way communication . for example , in international conferences , actually there are a number of international conferences held recent days , and there will be a great demand for translating one-way lecture .
In case of translating one-way lecture or one-way communication , the lecturer talks , the lecture translation system will recognize and transla te  will translate it into the language . But in this case the lecturer will be continuously talking and also the lecturer will show some gestures that .
There will be some behavioral communication by the lecturer , so the translation has to be synchronized with the gestures or pose or behavioral expressions of the speaker .
and by combining all those elements , simultaneous interpretation system could be implemented . And what are the objectives of researchers ? then first , we would like to implement the simultaneous machine translation system for lectures .
More specifically , the simul taneous machine translation from the English lecture to Japanese speech , the form is a speech in Japanese . And in terms of processing design , approach will be based upon the incremental spoken language processing .
there is experimental system called LINAS . And we have already implemented those experimental system called LINAS .
Through the performance of this system , LINAS , we would like to pursue the feasibility of translation  or machine translation into the speech of the other language . Let me briefly explain what this LINAS is all about .
And outlines of the system , the features of the system are as follows . In case of two different languages with two different word orders , the system will be characterized by the accomplishment of the simultaneity between input and output of the two different languages with different word orders . This is the first point .
Second point , the system will have acquired the knowledge on the language and knowledge on the expert area including technical terms , such will be expected in lecture . This is what we will acquire language knowledge and expert knowledge related to the lecture . And a presentation sheet and resume , summary will be utilized for the system to acquired those knowledge in advance .
The third feature is to generate natural Japanese spoken language , so these are the features of the system . when it comes to the design of the system , actually the the Sync Trans , which is the simultaneous written translation system of dialogue , is already there .
As so the system will utilize rather simple design based on the technology of think tank . I would like to elaborate on the system configuration of LINAS .
Basically , there will be two processing modules , first one for simultaneous analysis of English , and second , simultaneous generation of the Japanese . The English speech comes , that English speech will recognize , speech recognition will be made onto the spoken English .
And the simultaneous analysis of English is done and simultaneous generation of the corresponded language will be made and through speech synthesis translated Japanese will be transformed into the spoken language of Japan , so this will be how the translation speech translation is done .
And actually , we implemented the LINAS or Japanese-English simultaneous machine translation system . The system is implemented on UNIX workstation .
For the recognition of English speech , human will do on behalf of a machine , so an English speech will be recognized by people . For Japanese speech output , the output will be made through speech synthesis on Windows PC .
And also people will be involved in preparing language data from the lecture speech in advance . Thus the system utilizes already acquired grammar and other language related data .
And actually we confirm a test of performance of the system using at the English lecture speech input and we actually evaluate feasibility of the simultaneous machine translation of lecture . And we see relatively high feasibility of the system either way .
This is actually display of the results of speech simultaneous translation . The transla ted speech will be output to the audience and for the sake of enhancing audience understanding , we created this type of a window .
This export of the speech as English input is fed into the system . Correspondingly , Japanese translation will come up .
This lecture happens to be on the topic of the IT , Information Technology and the resultant display of the translated speech . And design and implementation of the LINAS , the simultaneous translation system of the English lecture was given .
Basically it consists of the analysis and synthesis and I 'm just trying to summarize what I mentioned , then the prepared language data based upon the lecture speech and system was implemented on a workstation to confirm the performance .
Still the system is on experimental basis . But in the future we trying to implement the simultaneous machine translation system in the scientific meetings with the minimum delay of ten minutes or so . This completes my lecture .
Thank you .
